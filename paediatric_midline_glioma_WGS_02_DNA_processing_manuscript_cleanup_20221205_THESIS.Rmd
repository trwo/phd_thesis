---
  title: "Paediatric autopsy project - WGS data"
author: "Thomas R W Oliver"
output: 
  html_document:
  toc: true
toc_depth: 2
number_sections: true
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Review of code/clean up complete - TO3 21/12/22

#00_supplementary_data

```{r}

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20221015.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')

#manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')

#correct germ layer mislabelling
#table(manifest[manifest$predominant_germ_layer == "Endoderm",]$histo) #3 mislabelled skeletal muscle cuts
#table(manifest[manifest$predominant_germ_layer == "Mesoderm",]$histo)
#table(manifest[manifest$predominant_germ_layer == "Ectoderm",]$histo)

#manifest[manifest$predominant_germ_layer == "Endoderm" & manifest$histo == "Skeletal muscle",]$predominant_germ_layer = "Mesoderm"

#write.table(manifest, '/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt', sep = '\t', quote = F, col.names = T, row.names = F)

```

#02_DNA_processing

##SUBSTITUTIONS

When originally running this, for a reason I am still unsure of, PD51122g_lo0017 fails LCM filtering due to a segmentation error during the annotate bam statistics step. The sample has been removed from the final cohort.

```{r}

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')

manifest[manifest$sample == "PD51122g_lo0017",]$keep = "N"

table(manifest$keep)
#N   Y 
#3 911 

write.table(manifest, '/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt', sep = '\t', quote = F, col.names = T, row.names = F)

```

###Plot mutational spectra functions

```{r}

library(lsa)
library(VariantAnnotation)
library("GenomicRanges")
library("Rsamtools")
library("MASS")

genomeFile_38 <- "/lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa"

count_trinuc_context_38 <- function(input){
  mutations = data.frame(matrix(unlist(strsplit(input, "_")), ncol = 4, byrow= T))
  names(mutations) = c("chr", "pos", "ref", "mut")
  mutations = mutations[(mutations$ref %in% c("A","C","G","T")) & (mutations$mut %in% c("A","C","G","T")) & mutations$chr %in% paste0("chr", c(1:22,"X","Y")),]
  mutations$trinuc_ref = as.vector(scanFa(genomeFile_38, GRanges(mutations$chr, IRanges(as.numeric(mutations$pos)-1,
                                                                                     as.numeric(mutations$pos)+1))))

  # 2. Annotating the mutation from the pyrimidine base
  ntcomp = c(T="A",G="C",C="G",A="T")
  mutations$sub = paste(mutations$ref,mutations$mut,sep=">")
  mutations$trinuc_ref_py = mutations$trinuc_ref
  for (j in 1:nrow(mutations)) {
    if (mutations$ref[j] %in% c("A","G")) { # Purine base
      mutations$sub[j] = paste(ntcomp[mutations$ref[j]],ntcomp[mutations$mut[j]],sep=">")
      mutations$trinuc_ref_py[j] = paste(ntcomp[rev(strsplit(mutations$trinuc_ref[j],split="")[[1]])],collapse="")
    }
  }
  freqs = table(paste(mutations$sub,paste(substr(mutations$trinuc_ref_py,1,1),substr(mutations$trinuc_ref_py,3,3),sep="-"),sep=","))
  sub_vec = c("C>A","C>G","C>T","T>A","T>C","T>G")
  ctx_vec = paste(rep(c("A","C","G","T"),each=4),rep(c("A","C","G","T"),times=4),sep="-")
  full_vec = paste(rep(sub_vec,each=16),rep(ctx_vec,times=6),sep=",")
  freqs_full = freqs[full_vec]; freqs_full[is.na(freqs_full)] = 0; names(freqs_full) = full_vec
  
  #3. plot
  xstr = paste(substr(full_vec,5,5), substr(full_vec,1,1), substr(full_vec,7,7), sep="")

  colvec = rep(c("dodgerblue","black","red","grey70","olivedrab3","plum2"),each=16)
  y = freqs_full; maxy = max(y)
  h = barplot(y, las=2, col=colvec, border=NA, ylim=c(0,maxy*1.5), space=1, cex.names=0.6, names.arg=xstr, ylab="Number of mutations")
  for (j in 1:length(sub_vec)) {
    xpos = h[c((j-1)*16+1,j*16)]
    rect(xpos[1]-0.5, maxy*1.2, xpos[2]+0.5, maxy*1.3, border=NA, col=colvec[j*16])
    text(x=mean(xpos), y=maxy*1.3, pos=3, label=sub_vec[j])
  } 
  title(sub = paste0("filtered subs = ", nrow(mutations)))
  
  mut.props = freqs_full / sum(freqs_full)
  
  return(mut.props)
}

genomeFile_19 = "/lustre/scratch119/casm/team78pipelines/reference/human/GRCh37d5/genome.fa"

count_trinuc_context_19 <- function(input){
  mutations = data.frame(matrix(unlist(strsplit(input, "_")), ncol = 4, byrow= T))
  names(mutations) = c("chr", "pos", "ref", "mut")
  mutations = mutations[(mutations$ref %in% c("A","C","G","T")) & (mutations$mut %in% c("A","C","G","T")) & mutations$chr %in% c(1:22,"X","Y"),]
  mutations$trinuc_ref = as.vector(scanFa(genomeFile_19, GRanges(mutations$chr, IRanges(as.numeric(mutations$pos)-1,
                                                                                     as.numeric(mutations$pos)+1))))

  # 2. Annotating the mutation from the pyrimidine base
  ntcomp = c(T="A",G="C",C="G",A="T")
  mutations$sub = paste(mutations$ref,mutations$mut,sep=">")
  mutations$trinuc_ref_py = mutations$trinuc_ref
  for (j in 1:nrow(mutations)) {
    if (mutations$ref[j] %in% c("A","G")) { # Purine base
      mutations$sub[j] = paste(ntcomp[mutations$ref[j]],ntcomp[mutations$mut[j]],sep=">")
      mutations$trinuc_ref_py[j] = paste(ntcomp[rev(strsplit(mutations$trinuc_ref[j],split="")[[1]])],collapse="")
    }
  }
  freqs = table(paste(mutations$sub,paste(substr(mutations$trinuc_ref_py,1,1),substr(mutations$trinuc_ref_py,3,3),sep="-"),sep=","))
  sub_vec = c("C>A","C>G","C>T","T>A","T>C","T>G")
  ctx_vec = paste(rep(c("A","C","G","T"),each=4),rep(c("A","C","G","T"),times=4),sep="-")
  full_vec = paste(rep(sub_vec,each=16),rep(ctx_vec,times=6),sep=",")
  freqs_full = freqs[full_vec]; freqs_full[is.na(freqs_full)] = 0; names(freqs_full) = full_vec
  
  #3. plot
  xstr = paste(substr(full_vec,5,5), substr(full_vec,1,1), substr(full_vec,7,7), sep="")

  colvec = rep(c("dodgerblue","black","red","grey70","olivedrab3","plum2"),each=16)
  y = freqs_full; maxy = max(y)
  h = barplot(y, las=2, col=colvec, border=NA, ylim=c(0,maxy*1.5), space=1, cex.names=0.6, names.arg=xstr, ylab="Number of mutations")
  for (j in 1:length(sub_vec)) {
    xpos = h[c((j-1)*16+1,j*16)]
    rect(xpos[1]-0.5, maxy*1.2, xpos[2]+0.5, maxy*1.3, border=NA, col=colvec[j*16])
    text(x=mean(xpos), y=maxy*1.3, pos=3, label=sub_vec[j])
  } 
  title(sub = paste0("filtered subs = ", nrow(mutations)))
  
  mut.props = freqs_full / sum(freqs_full)
  
  return(mut.props)
}

```

###CaVEMan

Run unmatched for all WGS samples

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/01_caveman

infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($26 == "Y") { print $1, $6} }' $infile | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
cp /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.caveman_c.annot.vcf.gz .
done

ls *gz | wc -l #911 all accounted for

for file in $(ls *.caveman_c.annot.vcf.gz);
do
zgrep "SAMPLE=<ID=NORMAL" $file >> matched_samples.txt
done 

wc -l matched_samples.txt #911
grep "PDv38is_wgs" matched_samples.txt | wc -l #911, all run unmatched

```


```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/01_caveman

ls *.caveman_c.annot.vcf.gz | while read FILE ; do zgrep "^#" -v "$FILE" | cut -f1 | uniq -c > ../00_qc_chrom/"$FILE".counts.txt ; done 
wc -l ../00_qc_chrom/*caveman_c.annot.vcf.gz.counts.txt #none truncated 1/8/22

```

###1) Standard filters

####Bulk

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/01_caveman

module load bcftools

for f in $(ls *.caveman_c.annot.vcf.gz | grep -v "lo");
do
filename=$(basename -- "$f")
sample="${filename%.caveman_c.annot.vcf.gz}"
bcftools filter -i 'FILTER = "PASS" & INFO/ASRD >= 0.87 & INFO/CLPM = 0' $f > ../02a_bulk/${sample}.caveman_c.annot.asrd.clpm.pass.filtered.vcf
done

```

####LCM

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/02b_lcm/

#run for all samples, in a screen
infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"

samples=$(grep "WGS_LCM" $infile | awk -F "\t" '{print $1}' | paste -s -d, -)
samples_project=$(grep "WGS_LCM" $infile | awk -F "\t" '{print $6}' | paste -s -d, -)
normals=$(grep "WGS_LCM" $infile | awk -F "\t" '{print $21}' | paste -s -d, -)
grep "WGS_LCM" $infile | awk -F "\t" '{print $21}' | wc -l #843
normals_project=$(yes 2571 | head -n 843 | paste -s -d, -)

./tb14_scripts/runLCMFiltering_GRCh38_220726.sh \
-pt $samples_project \
-st $samples \
-pn $normals_project \
-sn $normals \
-f 4 \
-o ./ \
-anno ./tb14_scripts/

#rm rejected samples
rm PD51122g_lo0017*
rm PD51122t_lo0011*
rm PD51122t_lo0012*

ls *_complete_second_filter.txt | wc -l #840, correct number

#apply final filter
export PATH=/software/R-4.1.0/bin:${PATH}
export R_HOME=$(R RHOME)

for file in $(ls *_complete_second_filter.txt);
do
sample=${file%_complete_second_filter.txt}
#echo $sample
bsub -q small -o ${sample}_ms44_flt.out -e ${sample}_ms44_flt.err -n 4 -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M10000 /software/R-4.1.0/bin/Rscript ~/scripts/final_LCM_filter_20220728.R -f $file
done

#remove failed last step
rm *complete_final_retained_4.vcf
rm *complete_final_removed_4.vcf

ls *second_filter.txt | wc -l #840
ls *final_subs_final_filter.txt | wc -l #840, worked

```

```{r}

#final_LCM_filter_20220728.R

library(VariantAnnotation)
library(optparse)
library(plyr)
library(dplyr)
library(data.table)

option_list = list(
  make_option(c("-f", "--file"), type="character", default=NULL, help="Input file name, ending in *_complete_second_filter.txt", metavar="character"))

opt_parser = OptionParser(option_list=option_list)
opt = parse_args(opt_parser)

file = opt$file

# Function for getting LCM filter info and annotating data
mathWG <- function(x) {
  sample_name <- gsub("_complete_second_filter.txt","", basename(x))
  wg_pass_table = fread(x, header = T, fill = T, sep = "\t")
  colnames(wg_pass_table) <-wg_allinfo_colnames
  wg_pass_table$sampleID <- sample_name
  wg_pass_annot <- dplyr::mutate(wg_pass_table, mathijs_filt_wg = if_else((wg_tumour_sec_HQ_alt_depth >=2 & 
                                                                             Var_reads_unique >=2 & (
                                                                               (is.na(MAD_var_pos_reads)  & SD_var_neg_reads >2 & !is.na(SD_var_neg_reads)) |
                                                                                 (is.na(MAD_var_neg_reads) & SD_var_pos_reads >2 & !is.na(SD_var_pos_reads)) |
                                                                                 ((Var_pos_reads_used_stats >1 & SD_var_pos_reads >2 & !is.na(SD_var_pos_reads)) |
                                                                                    (Var_neg_reads_used_stats >1 & SD_var_neg_reads >2 & !is.na(SD_var_neg_reads))))
                                                                           &
                                                                             ((Var_pos_reads_used_stats <= 1 & Var_neg_reads_used_stats >1 & ((`Var_neg_5_prime_15%_reads`/Var_neg_reads_used_stats) <= 0.9 |
                                                                                                                                                (MAD_var_neg_reads >0 & SD_var_neg_reads >= 4 & !is.na(SD_var_neg_reads)))) |
                                                                                (Var_neg_reads_used_stats <= 1 & Var_pos_reads_used_stats >1 & ((`Var_pos_5_prime_15%_reads`/Var_pos_reads_used_stats) <= 0.9 |(MAD_var_pos_reads > 0 & SD_var_pos_reads >=4))) |
                                                                                (Var_pos_reads_used_stats >1 & Var_neg_reads_used_stats >1 & ((`Var_pos_5_prime_15%_reads`/Var_pos_reads_used_stats) <= 0.9 | (Var_pos_reads_used_stats >2 & MAD_var_pos_reads >2) | (Var_neg_reads_used_stats >1 & SD_var_neg_reads >10)) &
                                                                                   ((`Var_neg_5_prime_15%_reads`/Var_neg_reads_used_stats) <= 0.9 | (Var_neg_reads_used_stats >2 & MAD_var_neg_reads >2) | (Var_pos_reads_used_stats >1 & SD_var_pos_reads >10))))), "WG_PASS", "WG_FAIL"), 
                                 mutID = paste(sampleID, Chr, Start, Ref, Alt, sep = "_"),
                                 posID = paste(Chr, Start, Ref, Alt, sep = "_"),
                                 PD_ID = substr(sampleID, 1, 7),
                                 PD_mutID = paste(PD_ID, mutID, sep = "_"))
  dplyr::select(wg_pass_annot, PD_ID, posID, mutID, PD_mutID, refgene_annot = Func.refGene, exonic_func = ExonicFunc.refGene, AA_Change = AAChange.refGene, SIFT_score, SIFT_pred, MutationAssessor_score, MutationAssessor_pred, avsnp147, cosmic70, wg_tumour_sec_HQ_depth, wg_tumour_sec_HQ_alt_depth,  wg_tumour_sec_HQ_alt_freq, wg_normal_sec_HQ_depth,	wg_normal_sec_HQ_alt_depth,	wg_normal_sec_HQ_alt_freq, mathijs_filt_wg)
}

# correct column names for data frame
wg_allinfo_colnames <- c("Chr", "Start", "End", "Ref", "Alt", "Func.refGene", "Gene.refGene", "GeneDetail.refGene", "ExonicFunc.refGene", "AAChange.refGene", "SIFT_score", "SIFT_pred", "Polyphen2_HDIV_score", "Polyphen2_HDIV_pred", "Polyphen2_HVAR_score", "Polyphen2_HVAR_pred", "LRT_score", "LRT_pred", "MutationTaster_score", "MutationTaster_pred", "MutationAssessor_score", "MutationAssessor_pred", "FATHMM_score", "FATHMM_pred", "RadialSVM_score", "RadialSVM_pred", "LR_score", "LR_pred", "VEST3_score", "CADD_raw", "CADD_phred", "GERP++_RS", "phyloP46way_placental", "phyloP100way_vertebrate", "SiPhy_29way_logOdds",  "avsnp147", "cosmic70", "wg_tumour_", "wg_tumour_sec_depth", "wg_tumour_sec_alt_depth", "wg_tumour_sec_alt_freq", "wg_tumour_sec_alt_bias", "wg_tumour_sec_HQ_depth", "wg_tumour_sec_HQ_alt_depth", "wg_tumour_sec_HQ_alt_freq", "wg_tumour_sec_HQ_alt_bias", "wg_tumour_sec_HQ_ratio", "wg_tumour_depth", "wg_tumour_alt_depth", "wg_tumour_alt_freq", "wg_tumour_alt_bias", "wg_tumour_HQ_depth", "wg_tumour_HQ_alt_depth", "wg_tumour_HQ_alt_freq", "wg_tumour_HQ_alt_bias", "wg_tumour_HQ_ratio", "wg_tumour_XA_depth", "wg_tumour_XA_alt_depth", "wg_normal_", "wg_normal_sec_depth", "wg_normal_sec_alt_depth", "wg_normal_sec_alt_freq", "wg_normal_sec_alt_bias", "wg_normal_sec_HQ_depth", "wg_normal_sec_HQ_alt_depth", "wg_normal_sec_HQ_alt_freq", "wg_normal_sec_HQ_alt_bias", "wg_normal_sec_HQ_ratio", "wg_normal_depth", "wg_normal_alt_depth", "wg_normal_alt_freq", "wg_normal_alt_bias", "wg_normal_HQ_depth", "wg_normal_HQ_alt_depth", "wg_normal_HQ_alt_freq", "wg_normal_HQ_alt_bias", "wg_normal_HQ_ratio", "wg_normal_XA_depth", "wg_normal_XA_alt_depth", "Alternative_alignment", "Alternative_alignment_var", "Sub_Exceed_Align", "Sub_Exceed_Align_var", "Sub_Small_Edit", "Sub_Small_Edit_var", "Clipped", "Clipped_var", "NonSNP_variants", "NonSNP_variants_var", "Var_pos_reads", "Var_pos_reads_used_stats", "Var_pos_5_prime_15%_reads", "MAD_var_pos_reads", "SD_var_pos_reads", "Var_neg_reads", "Var_neg_reads_used_stats", "Var_neg_5_prime_15%_reads", "MAD_var_neg_reads", "SD_var_neg_reads", "Var_reads", "Var_reads_unique", "Var_reads_unique_pos", "Var_reads_unique_neg", "Var_reads_somatic_variants", "Var_reads_somatic_variants_measurable")

sample = unlist(strsplit(file, "_complete_second_filter.txt"))
flt_file = mathWG(file)
write.table(flt_file[flt_file$mathijs_filt_wg == "WG_PASS",], paste0(sample, "_final_subs_final_filter.txt"), col.names = T, row.names = F, quote = F, sep = '\t')

```

Filter original VCFs

Remove problematic line that prevents us writing out the vcf

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/02b_lcm

for f in $(ls *_complete.vcf);
do
filename=$(basename -- "$f")
sample="${filename%_complete.vcf}"
#echo $f
#echo $sample
grep -v "##vcfProcessLog=" $f > ${sample}.edited.vcf
done

export PATH=/software/R-4.1.0/bin:${PATH}
export R_HOME=$(R RHOME)

for file in $(ls *.edited.vcf);
do
sample=${file%.edited.vcf}
#echo $sample
bsub -q small -o ${sample}_vcf_lcm_flt.out -e ${sample}_vcf_lcm_flt.err -n 4 -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M10000 /software/R-4.1.0/bin/Rscript ~/scripts/apply_lcm_flt_vcf.R -f $file
done

ls *_complete.vcf | wc -l #840
ls *.standard.filtered.vcf | wc -l #840

for file in $(ls *_complete.vcf);
do
sample=${file%_complete.vcf} 
echo $sample >> all_samples.txt
done

for file in $(ls *.standard.filtered.vcf);
do
sample=${file%.standard.filtered.vcf} 
echo $sample >> passed_samples.txt
done

```

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/02b_lcm")

all = read.table("all_samples.txt", header = F,  sep = '\t', stringsAsFactors = F)[,1]
passed = read.table("passed_samples.txt", header = F,  sep = '\t', stringsAsFactors = F)[,1]

all[!all %in% passed] #"PD51122ad_lo0006" "PD51122e_lo0056"  "PD51122f_lo0002"  "PD51122f_lo0003"  "PD51122g_lo0017"  "PD51122i_lo0012"  "PD51122i_lo0013"  "PD51122i_lo0014"  "PD51122t_lo0011" "PD51122u_lo0019" these took longer than 30 minutes to do

```

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/02b_lcm

export PATH=/software/R-4.1.0/bin:${PATH}
export R_HOME=$(R RHOME)

for sample in PD51122ad_lo0006 PD51122e_lo0056 PD51122f_lo0002 PD51122f_lo0003 PD51122i_lo0012 PD51122i_lo0013 PD51122i_lo0014 PD51122t_lo0011 PD51122u_lo0019;
do
bsub -q normal -o ${sample}_vcf_lcm_flt.out -e ${sample}_vcf_lcm_flt.err -n 4 -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M10000 /software/R-4.1.0/bin/Rscript ~/scripts/apply_lcm_flt_vcf.R -f ${sample}.edited.vcf
done

for sample in PD51122f_lo0001; #reportedly didn't successfully complete despite generating vcf, see R code chunk below
do
bsub -q normal -o ${sample}_vcf_lcm_flt.out -e ${sample}_vcf_lcm_flt.err -n 4 -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M10000 /software/R-4.1.0/bin/Rscript ~/scripts/apply_lcm_flt_vcf.R -f ${sample}.edited.vcf
done

ls *.standard.filtered.vcf | wc -l #841

grep "Successfully" *_vcf_lcm_flt.out >> successful_samples.txt

```

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/02b_lcm")

all = read.table("all_samples.txt", header = F,  sep = '\t', stringsAsFactors = F)[,1]
success = read.table("successful_samples.txt", header = F,  sep = '\t', stringsAsFactors = F)[,1]
success = unlist(strsplit(success, "_vcf_lcm_flt.out:Successfully completed."))

all[!all %in% success] #"PD51122f_lo0001" "PD51122g_lo0017" 

#grep -v "#" PD51122f_lo0001.standard.filtered.vcf | wc -l #90619
#wc -l PD51122f_lo0001_final_subs_final_filter.txt #90620

```

```{r}

#apply_lcm_flt_vcf.R

library(VariantAnnotation)
library(optparse)

option_list = list(
  make_option(c("-f", "--file"), type="character", default=NULL, help="File name, ending in .edited.vcf", metavar="character"))

opt_parser = OptionParser(option_list=option_list)
opt = parse_args(opt_parser)

vcf = opt$file

sample = strsplit(vcf, '\\.')[[1]][1]
data = VariantAnnotation::readVcf(vcf)
chr = as.character(seqnames(rowRanges(data)))
pos = start(ranges(rowRanges(data)))
ref = as.character(ref(data))
alt = unlist(CharacterList(alt(data)))

txt_file = read.table(paste0(sample, "_final_subs_final_filter.txt"), header = T, sep = '\t', stringsAsFactors = F)

info(data)$mut_ID = paste(chr, pos, ref, alt, sep = '_')
info(header(data)) = rbind(info(header(data)), DataFrame(Number = '.', Type = 'String', Description = 'Unique mutation ID', row.names = 'mut_ID'))
filtered_data = data[info(data)$mut_ID %in% txt_file$posID]
    
alt = unlist(CharacterList(alt(filtered_data)))
fs = vector()
rs = vector()
for(i in 1:length(alt)){
  fs_count = geno(filtered_data)[[paste0("F", alt[i], "Z")]][i,"TUMOUR"]
  rs_count = geno(filtered_data)[[paste0("R", alt[i], "Z")]][i,"TUMOUR"]
  fs = c(fs, fs_count)
  rs = c(rs, rs_count)
}
  
info(filtered_data)$FS = fs
info(filtered_data)$RS = rs
info(header(filtered_data)) = rbind(info(header(filtered_data)), DataFrame(Number = '1', Type = 'Integer', Description = 'Forward strand mutant allele count', row.names = 'FS'))
info(header(filtered_data)) = rbind(info(header(filtered_data)), DataFrame(Number = '1', Type = 'Integer', Description = 'Reverse strand mutant allele count', row.names = 'RS'))
    
writeVcf(filtered_data, filename = paste0(sample, '.standard.filtered.vcf'))

```

###2) gnomAD AF >0.001 filtering

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/99_reference_data/gnomAD

#bulk
for file in $(ls /lustre/scratch119/realdata/mdt1/team274/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/02a_bulk/*.caveman_c.annot.asrd.clpm.pass.filtered.vcf);
do
filename=$(basename -- "$file")
sample="${filename%.caveman_c.annot.asrd.clpm.pass.filtered.vcf}"
#echo $sample
bsub -q normal -o /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/03_gnomAD/${sample}.out -e /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/03_gnomAD/${sample}.err -n 4 -R 'select[mem>=50000] rusage[mem=50000] span[hosts=1]' -M50000 ~/scripts/gnomAD_AF_filter_bulk_20220728.sh $file /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/03_gnomAD/
done

#lcm
file="/lustre/scratch119/realdata/mdt1/team274/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/02b_lcm/PD50297ab_lo0001.standard.filtered.vcf"

for file in $(ls /lustre/scratch119/realdata/mdt1/team274/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/02b_lcm/*.standard.filtered.vcf);
do
filename=$(basename -- "$file")
sample="${filename%.standard.filtered.vcf}"
#echo $sample
bsub -q normal -o /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/03_gnomAD/${sample}.out -e /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/03_gnomAD/${sample}.err -n 2 -R 'select[mem>=30000] rusage[mem=30000] span[hosts=1]' -M30000 ~/scripts/gnomAD_AF_filter_lcm_20220728.sh $file /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/03_gnomAD/
done

#check it has worked
ls *.standard.gnomAD.AF.0.001.filtered.vcf | wc -l #911, all accounted for

```

```{bash}

#!/bin/bash
#gnomAD_AF_filter_bulk_20220728.sh

module load bedtools

FILE=$1
OUTDIR=$2

filename=$(basename -- "$FILE")
sample=${filename%.caveman_c.annot.asrd.clpm.pass.filtered.vcf}
echo $filename
echo $sample
bedtools intersect -header -v -a $FILE -b gnomad.genomes.v3.1.1.snps.filtered.chr10.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr18.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr4.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr11.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr19.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr5.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr12.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr1.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr6.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr13.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr20.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr7.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr14.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr21.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr8.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr15.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr22.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr9.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr16.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr2.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chrX.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr17.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr3.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chrY.af.0.001.vcf > $OUTDIR/${sample}.standard.gnomAD.AF.0.001.filtered.vcf

```

```{bash}

#!/bin/bash
#gnomAD_AF_filter_lcm_20220728.sh

module load bedtools

FILE=$1
OUTDIR=$2

filename=$(basename -- "$FILE")
sample=${filename%.standard.filtered.vcf}
echo $filename
echo $sample
bedtools intersect -header -v -a $FILE -b gnomad.genomes.v3.1.1.snps.filtered.chr10.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr18.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr4.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr11.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr19.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr5.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr12.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr1.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr6.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr13.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr20.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr7.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr14.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr21.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr8.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr15.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr22.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr9.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr16.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr2.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chrX.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr17.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chr3.af.0.001.vcf gnomad.genomes.v3.1.1.snps.filtered.chrY.af.0.001.vcf > $OUTDIR/${sample}.standard.gnomAD.AF.0.001.filtered.vcf

```

###3) BSMN PON mask

```{bash}

#index fasta file
samtools faidx /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/99_reference_data/bsmn/PON.q20q20.05.5.fa --fai-idx /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/99_reference_data/bsmn/PON.q20q20.05.5.fa.fai

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/03_gnomAD

for f in $(ls *.standard.gnomAD.AF.0.001.filtered.vcf);
do
sample=${f%.standard.gnomAD.AF.0.001.filtered.vcf}
grep -v "#" $f | cut -f1,2,4,5 | awk '{print $1"\t"$2-1"\t"$2"\t"$3"\t"$4}' > ${sample}.standard.gnomAD.AF.0.001.filtered.bed
done

module load bedtools

for f in $(ls *.standard.gnomAD.AF.0.001.filtered.bed);
do
sample=${f%.standard.gnomAD.AF.0.001.filtered.bed}
bedtools getfasta -bedOut -fi /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/99_reference_data/bsmn/PON.q20q20.05.5.fa -bed ${sample}.standard.gnomAD.AF.0.001.filtered.bed > ${sample}.standard.gnomAD.AF.0.001.PON.annot.filtered.bed
done

```

Filter out all variants determine to be poor by the PON

```{r}

#bsmn key
pon_key = list()

pon_key[["A"]] = "A"
pon_key[["C"]] = "C"
pon_key[["G"]] = "G"
pon_key[["T"]] = "T"
pon_key[["R"]] = c("A", "G")
pon_key[["Y"]] = c("C", "T")
pon_key[["S"]] = c("G", "C")
pon_key[["W"]] = c("A", "T")
pon_key[["K"]] = c("G", "T")
pon_key[["M"]] = c("A", "C")
pon_key[["B"]] = c("C", "G", "T")
pon_key[["D"]] = c("A", "G", "T")
pon_key[["H"]] = c("A", "C", "T")
pon_key[["V"]] = c("A", "C", "G")

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/03_gnomAD")

bed_files = list.files(".", ".standard.gnomAD.AF.0.001.PON.annot.filtered.bed")

for(file in bed_files){
  sample = unlist(strsplit(file, ".standard.gnomAD.AF.0.001.PON.annot.filtered.bed"))
  if(file.size(file) != 0){ #exclude empty files where no variants are called
    data = read.table(file, header =F, sep = '\t', stringsAsFactors = F)
    data$keep = "Y"
    for(i in 1:nrow(data)){
      if(data$V6[i] != "*"){
        if(data$V5[i] %in% pon_key[[data$V6[i]]]){
          data$keep[i] = "N"
        }
      }
    }
    data = data[data$keep == "Y",]
    write.table(data[, c(1:6)], paste0(sample, ".standard.gnomAD.AF.0.001.PON.filtered.bed"), col.names = F, row.names = F, sep = '\t', quote = F)
  }
}

```

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/03_gnomAD

module load bedtools

for f in $(ls *.standard.gnomAD.AF.0.001.filtered.vcf);
do
sample=${f%.standard.gnomAD.AF.0.001.filtered.vcf}
bedtools intersect -header -a $f -b ${sample}.standard.gnomAD.AF.0.001.PON.filtered.bed > ../04_1000G_PON/${sample}.standard.gnomAD.AF.0.001.PON.filtered.vcf
done

#what fails the filter?
for f in $(ls *.standard.gnomAD.AF.0.001.filtered.vcf);
do
sample=${f%.standard.gnomAD.AF.0.001.filtered.vcf}
bedtools intersect -header -v -a $f -b ${sample}.standard.gnomAD.AF.0.001.PON.filtered.bed > ../04_1000G_PON/${sample}.standard.gnomAD.AF.0.001.PON.fails.filter.vcf
done

```

```{r}

library(VariantAnnotation)
library("GenomicRanges")
library("Rsamtools")
library("MASS")

genomeFile <- "/lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa"

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/04_1000G_PON")

removed_vars = list.files(".", ".standard.gnomAD.AF.0.001.PON.fails.filter.vcf")

for(file in removed_vars){
  
  data = readVcf(file)
  
  if(nrow(data) > 0){
    
    sample = unlist(strsplit(file, ".standard.gnomAD.AF.0.001.PON.fails.filter.vcf"))
  
    chr = as.character(seqnames(rowRanges(data)))
    pos = start(ranges(rowRanges(data)))
    ref = as.character(ref(data))
    alt = unlist(CharacterList(alt(data)))
  
    mutations = data.frame(chr = chr, pos = pos, ref = ref, mut = alt)
  
    mutations = mutations[(mutations$ref %in% c("A","C","G","T")) & (mutations$mut %in% c("A","C","G","T")) & mutations$chr %in% paste0("chr", c(1:22,"X","Y")),]
    mutations$trinuc_ref = as.vector(scanFa(genomeFile, GRanges(mutations$chr, IRanges(as.numeric(mutations$pos)-1,
                                                                                     as.numeric(mutations$pos)+1))))

    # 2. Annotating the mutation from the pyrimidine base
    ntcomp = c(T="A",G="C",C="G",A="T")
    mutations$sub = paste(mutations$ref,mutations$mut,sep=">")
    mutations$trinuc_ref_py = mutations$trinuc_ref
    for (j in 1:nrow(mutations)) {
      if (mutations$ref[j] %in% c("A","G")) { # Purine base
        mutations$sub[j] = paste(ntcomp[mutations$ref[j]],ntcomp[mutations$mut[j]],sep=">")
        mutations$trinuc_ref_py[j] = paste(ntcomp[rev(strsplit(mutations$trinuc_ref[j],split="")[[1]])],collapse="")
      }
    }
    freqs = table(paste(mutations$sub,paste(substr(mutations$trinuc_ref_py,1,1),substr(mutations$trinuc_ref_py,3,3),sep="-"),sep=","))
    sub_vec = c("C>A","C>G","C>T","T>A","T>C","T>G")
    ctx_vec = paste(rep(c("A","C","G","T"),each=4),rep(c("A","C","G","T"),times=4),sep="-")
    full_vec = paste(rep(sub_vec,each=16),rep(ctx_vec,times=6),sep=",")
    freqs_full = freqs[full_vec]; freqs_full[is.na(freqs_full)] = 0; names(freqs_full) = full_vec
  
    #3. plot
    pdf(paste0(sample, "_trinuc_failed_pon_plot.pdf"), width = 12, height = 6)
    xstr = paste(substr(full_vec,5,5), substr(full_vec,1,1), substr(full_vec,7,7), sep="")

    colvec = rep(c("dodgerblue","black","red","grey70","olivedrab3","plum2"),each=16)
    y = freqs_full; maxy = max(y)
    h = barplot(y, las=2, col=colvec, border=NA, ylim=c(0,maxy*1.5), space=1, cex.names=0.6, names.arg=xstr, ylab="Number of mutations")
    for (j in 1:length(sub_vec)) {
      xpos = h[c((j-1)*16+1,j*16)]
      rect(xpos[1]-0.5, maxy*1.2, xpos[2]+0.5, maxy*1.3, border=NA, col=colvec[j*16])
      text(x=mean(xpos), y=maxy*1.3, pos=3, label=sub_vec[j])
    }
    dev.off()
  }
      
}

```

###4) Read direction filter

Annotate number of reads supporting variant in either direction. Already done in LCM samples so this step for bulk only.

Remove problematic line that prevents us writing out the vcf

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/04_1000G_PON

for f in $(ls *.standard.gnomAD.AF.0.001.PON.filtered.vcf | grep -v "lo");
do
filename=$(basename -- "$f")
sample="${filename%.standard.gnomAD.AF.0.001.PON.filtered.vcf}"
#echo $f
#echo $sample
grep -v "##vcfProcessLog=" $f > ${sample}.edited.vcf
done

export PATH=/software/R-4.1.0/bin:${PATH}
export R_HOME=$(R RHOME)

for file in $(ls *.edited.vcf);
do
sample=${file%.edited.vcf}
#echo $sample
bsub -q normal -o ${sample}_rd_annot.out -e ${sample}_rd_annot.err -n 4 -R 'select[mem>=20000] rusage[mem=20000] span[hosts=1]' -M20000 /software/R-4.1.0/bin/Rscript ~/scripts/annot_CaVEMan_read_direction.R -f $file
done

ls *.standard.gnomAD.AF.0.001.PON.filtered.vcf | wc -l #911, correct

```

```{r}

#annot_CaVEMan_read_direction.R

library(VariantAnnotation)
library(optparse)

option_list = list(
  make_option(c("-f", "--file"), type="character", default=NULL, help="File name, ending in .edited.vcf", metavar="character"))

opt_parser = OptionParser(option_list=option_list)
opt = parse_args(opt_parser)

vcf = opt$file

sample = strsplit(vcf, '\\.')[[1]][1]
data = VariantAnnotation::readVcf(vcf)
chr = as.character(seqnames(rowRanges(data)))
pos = start(ranges(rowRanges(data)))
ref = as.character(ref(data))
alt = unlist(CharacterList(alt(data)))
    
info(data)$mut_ID = paste(chr, pos, ref, alt, sep = '_')
info(header(data)) = rbind(info(header(data)), DataFrame(Number = '.', Type = 'String', Description = 'Unique mutation ID', row.names = 'mut_ID'))
filtered_data = data
    
alt = unlist(CharacterList(alt(filtered_data)))
fs = vector()
rs = vector()
for(i in 1:length(alt)){
  fs_count = geno(filtered_data)[[paste0("F", alt[i], "Z")]][i,"TUMOUR"]
  rs_count = geno(filtered_data)[[paste0("R", alt[i], "Z")]][i,"TUMOUR"]
  fs = c(fs, fs_count)
  rs = c(rs, rs_count)
}
  
info(filtered_data)$FS = fs
info(filtered_data)$RS = rs
info(header(filtered_data)) = rbind(info(header(filtered_data)), DataFrame(Number = '1', Type = 'Integer', Description = 'Forward strand mutant allele count', row.names = 'FS'))
info(header(filtered_data)) = rbind(info(header(filtered_data)), DataFrame(Number = '1', Type = 'Integer', Description = 'Reverse strand mutant allele count', row.names = 'RS'))
    
writeVcf(filtered_data, filename = paste0(sample, '.standard.gnomAD.AF.0.001.PON.filtered.vcf'))

```

```{bash}

module load bcftools

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/04_1000G_PON

for f in $(ls *.standard.gnomAD.AF.0.001.PON.filtered.vcf);
do
filename=$(basename -- "$f")
sample="${filename%.standard.gnomAD.AF.0.001.PON.filtered.vcf}"
bcftools filter -e '(((INFO/FS) / (INFO/FS + INFO/RS) < 0.15) | ((INFO/RS) / (INFO/FS + INFO/RS) < 0.15)) & (INFO/FS + INFO/RS) > 10' $f > ${sample}.standard.gnomAD.AF.0.001.PON.read.direction.1.filtered.vcf
bcftools filter -e 'INFO/FS = 0 | INFO/RS = 0' ${sample}.standard.gnomAD.AF.0.001.PON.read.direction.1.filtered.vcf > ../05_read_direction/${sample}.standard.gnomAD.AF.0.001.PON.read.direction.filtered.vcf
rm ${sample}.standard.gnomAD.AF.0.001.PON.read.direction.1.filtered.vcf
done

#check variants that fail
for f in $(ls *.standard.gnomAD.AF.0.001.PON.filtered.vcf);
do
filename=$(basename -- "$f")
sample="${filename%.standard.gnomAD.AF.0.001.PON.filtered.vcf}"
bcftools filter -i 'INFO/FS = 0 | INFO/RS = 0' ${f} > ../05_read_direction/${sample}.standard.gnomAD.AF.0.001.PON.read.direction.fails.filter.vcf
done

#check number of variants
cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/05_read_direction

for file in $(ls *.standard.gnomAD.AF.0.001.PON.read.direction.filtered.vcf);
do
echo $file
grep -v "#" $file | wc -l
done

```

```{r}

library(VariantAnnotation)
library("GenomicRanges")
library("Rsamtools")
library("MASS")

genomeFile <- "/lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa"

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/05_read_direction")
setwd("/lustre/scratch126/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/05_read_direction")

removed_vars = list.files(".", ".standard.gnomAD.AF.0.001.PON.read.direction.fails.filter.vcf")

for(file in removed_vars){
  
  data = readVcf(file)
  
  if(nrow(data) > 0){
    
    sample = unlist(strsplit(file, ".standard.gnomAD.AF.0.001.PON.read.direction.fails.filter.vcf"))
  
    chr = as.character(seqnames(rowRanges(data)))
    pos = start(ranges(rowRanges(data)))
    ref = as.character(ref(data))
    alt = unlist(CharacterList(alt(data)))
  
    mutations = data.frame(chr = chr, pos = pos, ref = ref, mut = alt)
  
    mutations = mutations[(mutations$ref %in% c("A","C","G","T")) & (mutations$mut %in% c("A","C","G","T")) & mutations$chr %in% paste0("chr", c(1:22,"X","Y")),]
    mutations$trinuc_ref = as.vector(scanFa(genomeFile, GRanges(mutations$chr, IRanges(as.numeric(mutations$pos)-1,
                                                                                     as.numeric(mutations$pos)+1))))

    # 2. Annotating the mutation from the pyrimidine base
    ntcomp = c(T="A",G="C",C="G",A="T")
    mutations$sub = paste(mutations$ref,mutations$mut,sep=">")
    mutations$trinuc_ref_py = mutations$trinuc_ref
    for (j in 1:nrow(mutations)) {
      if (mutations$ref[j] %in% c("A","G")) { # Purine base
        mutations$sub[j] = paste(ntcomp[mutations$ref[j]],ntcomp[mutations$mut[j]],sep=">")
        mutations$trinuc_ref_py[j] = paste(ntcomp[rev(strsplit(mutations$trinuc_ref[j],split="")[[1]])],collapse="")
      }
    }
    freqs = table(paste(mutations$sub,paste(substr(mutations$trinuc_ref_py,1,1),substr(mutations$trinuc_ref_py,3,3),sep="-"),sep=","))
    sub_vec = c("C>A","C>G","C>T","T>A","T>C","T>G")
    ctx_vec = paste(rep(c("A","C","G","T"),each=4),rep(c("A","C","G","T"),times=4),sep="-")
    full_vec = paste(rep(sub_vec,each=16),rep(ctx_vec,times=6),sep=",")
    freqs_full = freqs[full_vec]; freqs_full[is.na(freqs_full)] = 0; names(freqs_full) = full_vec
  
    #3. plot
    pdf(paste0(sample, "_trinuc_failed_read_direction_plot.pdf"), width = 12, height = 6)
    xstr = paste(substr(full_vec,5,5), substr(full_vec,1,1), substr(full_vec,7,7), sep="")

    colvec = rep(c("dodgerblue","black","red","grey70","olivedrab3","plum2"),each=16)
    y = freqs_full; maxy = max(y)
    h = barplot(y, las=2, col=colvec, border=NA, ylim=c(0,maxy*1.5), space=1, cex.names=0.6, names.arg=xstr, ylab="Number of mutations")
    for (j in 1:length(sub_vec)) {
      xpos = h[c((j-1)*16+1,j*16)]
      rect(xpos[1]-0.5, maxy*1.2, xpos[2]+0.5, maxy*1.3, border=NA, col=colvec[j*16])
      text(x=mean(xpos), y=maxy*1.3, pos=3, label=sub_vec[j])
    }
    dev.off()
  }
      
}

```

###Convert to txt files

####Function

```{r}

#sub_vcf_to_txt_file_20220814.R

library(VariantAnnotation)
library(optparse)

option_list = list(
  make_option(c("-f", "--file"), type="character", default=NULL, help="File name, ending in .standard.gnomAD.AF.0.001.PON.read.direction.filtered.vcf", metavar="character"))

opt_parser = OptionParser(option_list=option_list)
opt = parse_args(opt_parser)

vcf.input = opt$file

annotated_subs_text_file = function(vcf_file){
    vcf = readVcf(vcf_file)
    
    if(nrow(vcf) > 0){
      sample = unlist(strsplit(vcf_file, '.standard.gnomAD.AF.0.001.PON.read.direction.filtered.vcf'))
      case = substr(sample, 0, 7)
      reads = cbind((geno(vcf)$FAZ)[,2]+(geno(vcf)$RAZ)[,2],(geno(vcf)$FCZ)[,2]+(geno(vcf)$RCZ)[,2],
                (geno(vcf)$FGZ)[,2]+(geno(vcf)$RGZ)[,2],(geno(vcf)$FTZ)[,2]+(geno(vcf)$RTZ)[,2])
      var.df = data.frame(Chr = as.character(seqnames(rowRanges(vcf))),
                    Position = start(ranges(rowRanges(vcf))),
                    Wildtype = as.character(ref(vcf)),
                    Mutant = unlist(CharacterList(alt(vcf))))
      var.df$Total_read_depth=rowSums(reads)
      var.df$Variant_read_depth=NA
      var.df$Case_ID = case
      var.df$Sample = sample
      var.df = var.df[, c(7, 8, 1:6)]
      colnames(reads)=c("A","C","G","T")
      for (k in c("A","C","G","T")){
        var.df$Variant_read_depth[var.df$Mutant==k] = reads[var.df$Mutant==k,k]
      }
  
      var.df$VAF = var.df$Variant_read_depth/ var.df$Total_read_depth
      var.df$Mutation = info(vcf)$VT
      vagrent_annots = lapply(strsplit(info(vcf)$VW, '\\|'), `length<-`, max(lengths(strsplit(info(vcf)$VW, '\\|')))) #make all elements in list the same length for subsetting purposes
      
      vagrent_annots = lapply(strsplit(info(vcf)$VW, '\\|'), `length<-`, max(lengths(strsplit(info(vcf)$VW, '\\|')))) #make all elements in list the same length for subsetting purposes
      
      if(max(unlist(lapply(vagrent_annots, function(x) length(x)))) == 1){ #where none land in gene footprints and single NA values are found in each case
        var.df$Gene = NA
        var.df$Transcript = NA
        var.df$Codon = NA
        var.df$Protein = NA
      } else {
        var.df$Gene = sapply(vagrent_annots, '[[', 1)
        var.df$Transcript = sapply(vagrent_annots, '[[', 3)
        var.df$Codon = sapply(vagrent_annots, '[[', 4)
        var.df$Protein = sapply(vagrent_annots, '[[', 5)
      }

      conseq_list = lapply(info(vcf)$VC, function(x) if(identical(x, character(0))) NA_character_ else x)
      conseq_vec = c()
      for(i in 1:length(conseq_list)){
        conseq_vec = c(conseq_vec, paste(unlist(conseq_list[i]), collapse = ';'))
      }
  
      var.df$Consequence = conseq_vec
      
      write.table(var.df, paste0(sample, '.standard.gnomAD.AF.0.001.PON.read.direction.filtered.txt'), col.names = T, row.names = F, quote = F, sep = '\t')
    
    }
}

annotated_subs_text_file(vcf.input)

```

####Run

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/05_read_direction

export PATH=/software/R-4.1.0/bin:${PATH}
#export R_HOME=$(R RHOME)

for file in $(ls *.standard.gnomAD.AF.0.001.PON.read.direction.filtered.vcf);
do
sample=${file%.standard.gnomAD.AF.0.001.PON.read.direction.filtered.vcf}
#echo $sample
bsub -q small -o ${sample}_txt_convert.out -e ${sample}_txt_convert.err -n 4 -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M10000 /software/R-4.1.0/bin/Rscript ~/scripts/sub_vcf_to_txt_file_20220814.R -f $file
done

ls *txt | wc -l #911

```

##Binom filtering #2

###5) 6) 7) 8) 9) Binom filtering

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/05_read_direction

ls *.standard.gnomAD.AF.0.001.PON.read.direction.filtered.vcf | wc -l #911, correct number

```


####Symlink bam files to directory

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/cgpvaf/subs

infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($26 == "Y") { print $1, $6} }' $infile | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bas .
done

ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bas .

```

####Generate bed files

Done per patient

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/cgpvaf/subs

for f in PD50297 PD51122 PD51123;
do

for file in $(ls /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/05_read_direction/${f}*.standard.gnomAD.AF.0.001.PON.read.direction.filtered.vcf);
do
grep -v "#" $file | cut -f 1,2,4,5 >> ${f}_subs.bed
done

cat ${f}_subs.bed | sort -k1,1 -k2,2n -k3,4 | uniq > ${f}_subs_unique.bed
mv ${f}_subs_unique.bed ${f}_subs.bed

done

```

####Run cgpvaf

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/cgpvaf/subs

module load cgpVAFcommand

for patient in PD50297 PD51122 PD51123;
do

declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

mkdir -p ${patient}

#run per chromosome, need to change out and err files to specify chr 1/8/22
for chr in chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY;
do
bsub -q long -o ${patient}/%J.${patient}_${chr}_snp.out -e ${patient}/%J.${patient}_${chr}_snp.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl -d ./ -o ${patient} -a snp -mq 30 -bq 25 -g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa -be .sample.dupmarked.bam -hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz -bo 1 -b ${patient}_subs.bed -nn PDv38is_wgs -tn ${sampleArray[@]} -chr $chr
done

done

```

Check all jobs completely successfully

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/cgpvaf/subs

grep "Successfully" PD*/*chr*_snp.out | wc -l #72, all accounted for!

```

Concatenate per chromosome output

```{bash}

module load cgpVAFcommand

#PD50297
cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/cgpvaf/subs

patient="PD50297"
tmpdir=${patient}/"tmpvaf_"${patient}"ab_lo0001"

##get list of samples from patient
declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

cd $tmpdir

##for unclear reasons the bam files need to be in the same directory as the tmp files
infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($26 == "Y") { print $1, $6} }' $infile | grep $patient | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bas .
done

ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bas .

##submit concatenate job
bsub -q long -o ../%J.${patient}_concat.out -e ../%J.${patient}_concat.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl \
-d ./ \
-o ../ \
-a snp \
-g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa \
-hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz \
-bo 1 \
-b ../../${patient}_subs.bed \
-be .sample.dupmarked.bam \
-nn PDv38is_wgs \
-tn ${sampleArray[@]} \
-ct 1

#PD51122
cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/cgpvaf/subs

patient="PD51122"
tmpdir=${patient}/"tmpvaf_"${patient}"ab_lo0001"

##get list of samples from patient
declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

cd $tmpdir

##for unclear reasons the bam files need to be in the same directory as the tmp files
infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($26 == "Y") { print $1, $6} }' $infile | grep $patient | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bas .
done

ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bas .

##submit concatenate job
bsub -q long -o ../%J.${patient}_concat.out -e ../%J.${patient}_concat.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl \
-d ./ \
-o ../ \
-a snp \
-g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa \
-hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz \
-bo 1 \
-b ../../${patient}_subs.bed \
-be .sample.dupmarked.bam \
-nn PDv38is_wgs \
-tn ${sampleArray[@]} \
-ct 1

#PD51123
cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/cgpvaf/subs

patient="PD51123"
tmpdir=${patient}/"tmpvaf_"${patient}"aa3"

##get list of samples from patient
declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

cd $tmpdir

##for unclear reasons the bam files need to be in the same directory as the tmp files
infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($26 == "Y") { print $1, $6} }' $infile | grep $patient | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bas .
done

ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bas .

##submit concatenate job
bsub -q long -o ../%J.${patient}_concat.out -e ../%J.${patient}_concat.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl \
-d ./ \
-o ../ \
-a snp \
-g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa \
-hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz \
-bo 1 \
-b ../../${patient}_subs.bed \
-be .sample.dupmarked.bam \
-nn PDv38is_wgs \
-tn ${sampleArray[@]} \
-ct 1

```

####Run the binomial and beta-binomial filters

Copy over the per case pileup files
```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_filtering

cp /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/cgpvaf/subs/PD*/*_snp_vaf.tsv .

#remove header info
for f in $(ls *_snp_vaf.tsv);
do
filename=$(basename -- "$f")
filename="${filename%_snp_vaf.tsv}"
#echo $filename
grep -v "##" $f > ${filename}_snp_vaf_nohash.tsv
done

```

```{r}

#binom_beta_binom_paed_autopsy_wgs_mut_filter_20220923_2.R
#Pipeline to filter out germline and artefactual variants from output of cgpvaf for subs and indels

#setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_filtering")
#txt_file = "PDv38is_wgs_PD51122ab_lo0001_snp_vaf_nohash.tsv"
#mut_type = "snp"
#txt_file = "PDv38is_wgs_PD51122ab_lo0001_indel_vaf_nohash.tsv"
#mut_type = "indel"

#read in library and extra functions
library(VariantAnnotation)
library(optparse)

source("/nfs/users/nfs_t/to3/scripts/germline_exact_binom.R")
source("/nfs/users/nfs_t/to3/scripts/beta_binom_flt.R")

option_list = list(
  make_option(c("-t", "--text_file"), type="character", default=NULL, help="Text file containing patient putative calls", metavar="character"),
  make_option(c("-m", "--mut_type"), type="character", default=NULL, help="snp or indel", metavar="character"))

opt_parser = OptionParser(option_list=option_list)
opt = parse_args(opt_parser)

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')
manifest = manifest[manifest$keep == "Y", ]

txt_file = opt$text_file
mut_type = opt$mut_type

#read in relevant files
data = read.table(txt_file, comment.char = "", header = T)
patient = substr(unlist(strsplit(txt_file, 'PDv38is_wgs_'))[2], 0, 7)
samples_with_poss_CNVs = manifest[manifest$case.id == patient & manifest$CNS == 'Y',]$sample #remove all CNS samples from germline filtering to eliminate risk of tumour contamination affecting calls
epithelial_samples = manifest[manifest$case.id == patient & manifest$epithelium == "Y",]$sample
all_samples = manifest[manifest$case.id == patient,]$sample
lcm_samples = manifest[manifest$case.id == patient & manifest$experimental_arm == "WGS_LCM",]$sample
bulk_samples = manifest[manifest$case.id == patient & manifest$experimental_arm == "WGS_bulk",]$sample

#extract data frames of interest
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts

if(mut_type == "indel"){
  amb = data[,grepl("AMB",colnames(data))&colnames(data)!="PDv38is_wgs_AMB"]
  unk = data[,grepl("UNK",colnames(data))&colnames(data)!="PDv38is_wgs_UNK"]
  colnames(amb)=colnames(unk)=colnames(Genotype)
  rownames(amb)=rownames(unk)=rownames(Genotype)
  
}

#establish depth of sequencing across autosomal and sex chromosomes
XY_chromosomal = grepl("X|Y",Muts)
autosomal = !XY_chromosomal
xy_depth=mean(rowMeans(NR[XY_chromosomal,]))
autosomal_depth=mean(rowMeans(NR[autosomal,]))

#establish gender based on the relative coverage of X|Y vs autosomal chromosomes
gender='male'
if(xy_depth>0.8*autosomal_depth) gender='female'

#list of samples
samples = colnames(NR)

#samples without a copy number change
noCNVs=!samples%in%samples_with_poss_CNVs

#depth filter
Depth_filter = rowMeans(NR[,noCNVs]) > 10

#mixture of samples sequenced to varying depths, keep minimum
#if(gender=="male") Depth_filter = (rowMeans(NR[,noCNVs]) > 10 & rowMeans(NR[,noCNVs]) < 100 & autosomal) | (rowMeans(NR[,noCNVs]) > 10 & rowMeans(NR[,noCNVs]) < 50 & XY_chromosomal)
#if(gender=="female") Depth_filter = (rowMeans(NR[,noCNVs]) > 10 & rowMeans(NR[,noCNVs]) < 100)

write.table(row.names(NR)[rowMeans(NR[,noCNVs]) <= 10], paste0(patient, "_universal_low_coverage_", mut_type, ".txt"), col.names = F, row.names = F, quote = F, sep = "\t")

#apply depth filter to data frames
NR = NR[Depth_filter,]
NV = NV[Depth_filter,]
Muts = Muts[Depth_filter]
Genotype = Genotype[Depth_filter,]

#run germline filter
germline = exact.binomial(gender = gender, NV = NV[,noCNVs], NR = NR[,noCNVs], cutoff = -5) #determine which variants are germline

#write out germline and putative somatic variants
write.table(row.names(NR)[germline], paste0(patient,"_germline_", mut_type, "_variants.txt"), row.names = F, col.names = F, quote=F, sep = '\t')
write.table(row.names(NR)[!germline], paste0(patient,"_somatic_", mut_type, "_variants.txt"), row.names = F, col.names = F, quote=F, sep = '\t')

#remove germline variants from dataframes
NR_flt=NR[!germline,]
NV_flt=NV[!germline,]

#filter without minimum HQ read support
if(mut_type == "snp") minNV_filter = rowSums(NV_flt > 3) == 0 # at least one sample with four HQ supporting reads
if(mut_type == "indel") minNV_filter = rowSums(NV_flt > 4) == 0 # at least one sample with five HQ supporting reads

write.table(row.names(NR_flt)[minNV_filter], paste0(patient,"_low_quality_", mut_type, "_variants.txt"), row.names = F, col.names = F, quote=F, sep = '\t')
write.table(row.names(NR_flt)[!minNV_filter], paste0(patient,"_high_quality_", mut_type, "_variants.txt"), row.names = F, col.names = F, quote=F, sep = '\t')

NR_flt_2 = NR_flt[!minNV_filter,]
NV_flt_2 = NV_flt[!minNV_filter,]

#average supporting NV
#if(mut_type == "snp") low_avg_NV = row.names(NV_flt_2)[apply(NV_flt_2, 1, function(x) mean(x[x != 0])) <= 1.5]
#if(mut_type == "indel") low_avg_NV = row.names(NV_flt_2)[apply(NV_flt_2, 1, function(x) mean(x[x != 0])) <= 2]

#write.table(low_avg_NV, paste0(patient,"_low_average_quality_", mut_type, "_variants.txt"), row.names = F, col.names = F, quote=F, sep = '\t')

#NR_flt_3 = NR_flt_2[!row.names(NR_flt_2) %in% low_avg_NV,]
#NV_flt_3 = NV_flt_2[!row.names(NV_flt_2) %in% low_avg_NV,]

NR_flt_3 = NR_flt_2
NV_flt_3 = NV_flt_2

#turn sites with no coverage in a sample to a depth of 1 read to prevent NA values downstream in beta binomial
NR_flt_3_nonzero = NR_flt_3
NR_flt_3_nonzero[NR_flt_3_nonzero == 0] = 1

#identify shared variants for beta binomial filtering
bulk_vars = names(rowSums(NV_flt_3[, bulk_samples] > 3))[rowSums(NV_flt_3[, bulk_samples] > 3) > 0] #4+ reads in any bulk sample 
lcm_shared_vars = names(rowSums(NV_flt_3[, lcm_samples] > 0))[rowSums(NV_flt_3[, lcm_samples] > 0) > 1] #any supporting reads in 2 or more LCM samples
epithelial_vars = names(rowSums(NV_flt_3[, epithelial_samples] > 0))[rowSums(NV_flt_3[, epithelial_samples] > 0) > 1] #any supporting reads in 2 or more samples

##beta binomial filter for lcm samples to remove low input sequencing artefact
rho_est_lcm = beta.binom.filter(NR = NR_flt_3_nonzero[lcm_shared_vars, lcm_samples], NV = NV_flt_3[lcm_shared_vars, lcm_samples])

if(mut_type == "snp") flt_rho = rho_est_lcm < 0.1
if(mut_type == "indel") flt_rho = rho_est_lcm < 0.2

rho_filtered_out = lcm_shared_vars[flt_rho]
if(mut_type == "snp") rho_filtered_out = rho_filtered_out[!rho_filtered_out %in% bulk_vars] #remove variants called in bulk samples to give some a chance to pass in more clonal epithelial samples

write.table(rho_filtered_out, paste0(patient, "_bbinom_filtered_", mut_type, ".txt"), col.names = F, row.names = F, sep = '\t', quote = F)
write.table(rho_est_lcm, paste0(patient, "_rho_est_lcm_shared_", mut_type, ".txt"), col.names = F, row.names = F, sep = '\t', quote = F)

epithelial_vars = epithelial_vars[!epithelial_vars %in% rho_filtered_out] #already removed

#beta binomial filter to epithelial samples to remove remaining germline events
rho_est2 = beta.binom.filter(NR = NR_flt_3_nonzero[epithelial_vars, epithelial_samples], NV = NV_flt_3[epithelial_vars, epithelial_samples])
 
if(mut_type == "snp") flt_rho2 = rho_est2 < 0.1
if(mut_type == "indel") flt_rho2 = rho_est2 < 0.2

rho_filtered_out_2 = rownames(NR_flt_3_nonzero[epithelial_vars,])[flt_rho2]

write.table(rho_filtered_out_2, paste0(patient, "_bbinom_filtered_2", mut_type, ".txt"), col.names = F, row.names = F, sep = '\t', quote = F)
write.table(rho_est2, paste0(patient, "_rho_est_shared_2", mut_type, ".txt"), col.names = F, row.names = F, sep = '\t', quote = F)

#filtered data frames
NR_flt_4 = NR_flt_3[!rownames(NR_flt_3) %in% c(rho_filtered_out, rho_filtered_out_2), ]
NV_flt_4 = NV_flt_3[!rownames(NV_flt_3) %in% c(rho_filtered_out, rho_filtered_out_2), ]

NR_flt_4_nonzero = NR_flt_4
NR_flt_4_nonzero[NR_flt_4_nonzero == 0] = 1

VAF_flt_4 = NV_flt_4 / NR_flt_4_nonzero

#amb + unk filtering, vaf, min depth filtering
if(mut_type == "indel"){
  
  bad_reads_vaf = (amb[row.names(VAF_flt_4),] + unk[row.names(VAF_flt_4),]) / NR_flt_4_nonzero[row.names(VAF_flt_4),] #estimate fraction of reads at locus that are unknown or ambiguous status
  bad_sites = row.names(bad_reads_vaf[rowMeans(bad_reads_vaf) > 0.1,]) #where more than 10% of the reads are ambiguous or unknown
  NR_flt_4 = NR_flt_4[!row.names(NR_flt_4) %in% bad_sites,]
  NV_flt_4 = NV_flt_4[!row.names(NV_flt_4) %in% bad_sites,]
  VAF_flt_4 = VAF_flt_4[!row.names(VAF_flt_4) %in% bad_sites,]
  
}

write.table(NR_flt_4, paste0(patient,"_NR_filtered_all_", mut_type, ".txt"), col.names = T, row.names = T, sep = '\t', quote = F)
write.table(NV_flt_4, paste0(patient,"_NV_filtered_all_", mut_type, ".txt"), col.names = T, row.names = T, sep = '\t', quote = F)
write.table(VAF_flt_4, paste0(patient,"_VAF_filtered_all_", mut_type, ".txt"), col.names = T, row.names = T, sep = '\t', quote = F)
write.table(row.names(VAF_flt_4), paste0(patient, "_filtered_remaining_all_", mut_type, ".txt"), col.names = F, quote = F, row.names = F)

write.table(data.frame(chr = unlist(lapply(strsplit(row.names(VAF_flt_4), '_'), '[[', 1)), start = as.numeric(unlist(lapply(strsplit(row.names(VAF_flt_4), '_'), '[[', 2))) - 1, end =  as.numeric(unlist(lapply(strsplit(row.names(VAF_flt_4), '_'), '[[', 2)))), paste0(patient, "_filtered_remaining_all_", mut_type, ".bed"), col.names = F, quote = F, row.names = F, sep = '\t')

#run cgpvaf once more for those removed with beta-binomial
if(length(rho_filtered_out) > 0){
  screening_muts = as.data.frame(matrix(unlist(strsplit(rho_filtered_out, "_")), ncol = 4, byrow = T))
write.table(screening_muts, paste0(patient,"_bbinom_filtered_", mut_type, "_df.txt"), col.names = F, row.names = F, sep = '\t', quote = F)
}

if(length(rho_filtered_out_2) > 0){
screening_muts_2 = as.data.frame(matrix(unlist(strsplit(rho_filtered_out_2, "_")), ncol = 4, byrow = T))
write.table(screening_muts_2, paste0(patient,"_bbinom_filtered_2_", mut_type, "_df.txt"), col.names = F, row.names = F, sep = '\t', quote = F)
}

```


```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_filtering

export PATH=/software/R-3.6.1/bin:${PATH}
export R_HOME=$(R RHOME)
export R_LIBS_USER="~/custom_libraries/R/x86_64-pc-linux-gnu-library/3.6_dw"

for f in $(ls *_snp_vaf_nohash.tsv);
do
bsub -q normal -o $f.out -e $f.err -n 4 -R 'select[mem>=60000] rusage[mem=60000] span[hosts=1]' -M60000 "/software/R-3.6.1/bin/Rscript ~/scripts/binom_beta_binom_paed_autopsy_wgs_mut_filter_20220923_2.R -t $f -m snp"
done

```

####Plot mutational spectra of variants that are filtered out

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_filtering")

library("GenomicRanges")
library("Rsamtools")
library("MASS")

genomeFile <- "/lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa"

patients = c("PD50297", "PD51122", "PD51123")

plot_trinuc_context <- function(input){
  mutations = data.frame(matrix(unlist(strsplit(input, "_")), ncol = 4, byrow= T))
  names(mutations) = c("chr", "pos", "ref", "mut")
  mutations = mutations[(mutations$ref %in% c("A","C","G","T")) & (mutations$mut %in% c("A","C","G","T")) & mutations$chr %in% paste0("chr", c(1:22,"X","Y")),]
  mutations$trinuc_ref = as.vector(scanFa(genomeFile, GRanges(mutations$chr, IRanges(as.numeric(mutations$pos)-1,
                                                                                     as.numeric(mutations$pos)+1))))

  # 2. Annotating the mutation from the pyrimidine base
  ntcomp = c(T="A",G="C",C="G",A="T")
  mutations$sub = paste(mutations$ref,mutations$mut,sep=">")
  mutations$trinuc_ref_py = mutations$trinuc_ref
  for (j in 1:nrow(mutations)) {
    if (mutations$ref[j] %in% c("A","G")) { # Purine base
      mutations$sub[j] = paste(ntcomp[mutations$ref[j]],ntcomp[mutations$mut[j]],sep=">")
      mutations$trinuc_ref_py[j] = paste(ntcomp[rev(strsplit(mutations$trinuc_ref[j],split="")[[1]])],collapse="")
    }
  }
  freqs = table(paste(mutations$sub,paste(substr(mutations$trinuc_ref_py,1,1),substr(mutations$trinuc_ref_py,3,3),sep="-"),sep=","))
  sub_vec = c("C>A","C>G","C>T","T>A","T>C","T>G")
  ctx_vec = paste(rep(c("A","C","G","T"),each=4),rep(c("A","C","G","T"),times=4),sep="-")
  full_vec = paste(rep(sub_vec,each=16),rep(ctx_vec,times=6),sep=",")
  freqs_full = freqs[full_vec]; freqs_full[is.na(freqs_full)] = 0; names(freqs_full) = full_vec
  
  #3. plot
  xstr = paste(substr(full_vec,5,5), substr(full_vec,1,1), substr(full_vec,7,7), sep="")

  colvec = rep(c("dodgerblue","black","red","grey70","olivedrab3","plum2"),each=16)
  y = freqs_full; maxy = max(y)
  h = barplot(y, las=2, col=colvec, border=NA, ylim=c(0,maxy*1.5), space=1, cex.names=0.6, names.arg=xstr, ylab="Number of mutations")
  for (j in 1:length(sub_vec)) {
    xpos = h[c((j-1)*16+1,j*16)]
    rect(xpos[1]-0.5, maxy*1.2, xpos[2]+0.5, maxy*1.3, border=NA, col=colvec[j*16])
    text(x=mean(xpos), y=maxy*1.3, pos=3, label=sub_vec[j])
  } 
  title(main = paste0(patient), sub = paste0("filtered subs = ", length(input)))
}

for(patient in patients){
  low_cov_vars = read.table(paste0(patient, "_universal_low_coverage_snp.txt"), header = F, sep = '\t', stringsAsFactors = F)[,1]
  germline_vars = read.table(paste0(patient, "_germline_snp_variants.txt"), header = F, sep = '\t', stringsAsFactors = F)[,1]
  low_quality_vars = read.table(paste0(patient, "_low_quality_snp_variants.txt"), header = F, sep = '\t', stringsAsFactors = F)[,1]
  bbinom_vars = read.table(paste0(patient, "_bbinom_filtered_snp.txt"), header = F, sep = '\t', stringsAsFactors = F)[,1]
  bbinom2_vars = read.table(paste0(patient, "_bbinom_filtered_2snp.txt"), header = F, sep = '\t', stringsAsFactors = F)[,1]
  
  pdf(paste0(patient, "_universal_low_coverage_snp_mut_spec.pdf"), height = 5, width = 12)
  plot_trinuc_context(low_cov_vars)
  dev.off()
  pdf(paste0(patient, "_germline_snp_variants_mut_spec.pdf"), height = 5, width = 12)
  plot_trinuc_context(germline_vars)
  dev.off()
  pdf(paste0(patient, "_low_quality_snp_variants_mut_spec.pdf"), height = 5, width = 12)
  plot_trinuc_context(low_quality_vars)
  dev.off()
  pdf(paste0(patient, "_bbinom_filtered_snp_mut_spec.pdf"), height = 5, width = 12)
  plot_trinuc_context(bbinom_vars)
  dev.off()
  pdf(paste0(patient, "_bbinom_filtered_2snp.pdf"), height = 5, width = 12)
  plot_trinuc_context(bbinom2_vars)
  dev.off()
}

```

####EDF 11 - combined plot of mutational spectra of filtered variants

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_filtering")

library(MutationalPatterns)
library(GenomeInfoDb)
library("BSgenome.Hsapiens.UCSC.hg38")

patients = c("PD50297", "PD51122", "PD51123")

subs_input = data.frame()
for(patient in patients){
  low_cov_vars = read.table(paste0(patient, "_universal_low_coverage_snp.txt"), header = F, sep = '\t', stringsAsFactors = F)[,1]
  germline_vars = read.table(paste0(patient, "_germline_snp_variants.txt"), header = F, sep = '\t', stringsAsFactors = F)[,1]
  low_quality_vars = read.table(paste0(patient, "_low_quality_snp_variants.txt"), header = F, sep = '\t', stringsAsFactors = F)[,1]
  bbinom_vars = read.table(paste0(patient, "_bbinom_filtered_snp.txt"), header = F, sep = '\t', stringsAsFactors = F)[,1]
  bbinom2_vars = read.table(paste0(patient, "_bbinom_filtered_2snp.txt"), header = F, sep = '\t', stringsAsFactors = F)[,1]
  
  low_cov_vars_df = data.frame(matrix(unlist(strsplit(low_cov_vars, "_")), ncol = 4, byrow = T))
  germline_vars_df = data.frame(matrix(unlist(strsplit(germline_vars, "_")), ncol = 4, byrow = T))
  low_quality_vars_df = data.frame(matrix(unlist(strsplit(low_quality_vars, "_")), ncol = 4, byrow = T))
  bbinom_vars_df = data.frame(matrix(unlist(strsplit(bbinom_vars, "_")), ncol = 4, byrow = T))
  bbinom2_vars_df = data.frame(matrix(unlist(strsplit(bbinom2_vars, "_")), ncol = 4, byrow = T))
  
  low_cov_vars_df$patient = patient
  germline_vars_df$patient = patient
  low_quality_vars_df$patient = patient
  bbinom_vars_df$patient = patient
  bbinom2_vars_df$patient = patient
  
  low_cov_vars_df$filter = "Low coverage"
  germline_vars_df$filter = "Germline exact binomial"
  low_quality_vars_df$filter = "Low quality"
  bbinom_vars_df$filter = "Beta binomial 1"
  bbinom2_vars_df$filter = "Beta binomial 2"
  
  subs_input = rbind(subs_input, low_cov_vars_df, germline_vars_df, low_quality_vars_df, bbinom_vars_df, bbinom2_vars_df)
  
}

names(subs_input) = c("Chr", "Position", "Ref", "Alt", "patient", "filter")
subs_input$patient.filter = paste0(subs_input$patient, " ", subs_input$filter)

grange_obj = makeGRangesListFromDataFrame(subs_input, 
                                          split.field = "patient.filter", 
                                          keep.extra.columns = T, 
                                          ignore.strand = T, 
                                          seqnames.field = "Chr",
                                          start.field = "Position", 
                                          end.field = "Position")
GenomeInfoDb::genome(grange_obj) = "hg38"
seqlengths(grange_obj) <- seqlengths(BSgenome.Hsapiens.UCSC.hg38@seqinfo)[1:24]

type_occurrences <- mut_type_occurrences(grange_obj, "hg38")
mut_mat <- mut_matrix(vcf_list = grange_obj, ref_genome = "hg38")

library(cowplot)

p1 = plot_96_profile(mut_mat[, grepl("Low coverage", colnames(mut_mat))], ymax = 0.1) +
  theme_bw() +
  theme(strip.text.y = element_text(angle = 0),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
        axis.title.x = element_blank())
p2 = plot_96_profile(mut_mat[, grepl("Germline", colnames(mut_mat))], ymax = 0.1) +
  theme_bw() +
  theme(strip.text.y = element_text(angle = 0),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
        axis.title.x = element_blank())
p3 = plot_96_profile(mut_mat[, grepl("Low quality", colnames(mut_mat))], ymax = 0.15) +
  theme_bw() +
  theme(strip.text.y = element_text(angle = 0),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
        axis.title.x = element_blank())
p4 = plot_96_profile(mut_mat[, grepl("Beta binomial 1", colnames(mut_mat))], ymax = 0.3) +
  theme_bw() +
  theme(strip.text.y = element_text(angle = 0),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
        axis.title.x = element_blank())
p5 = plot_96_profile(mut_mat[, grepl("Beta binomial 2", colnames(mut_mat))], ymax = 0.2) +
  theme_bw() +
  theme(strip.text.y = element_text(angle = 0),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
        axis.title.x = element_blank())

pdf("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/03_DNA_analyses/draft_figures/major_sub_filter_mutational_spectra_20221214.pdf", height = 10, width = 9, useDingbats = F)
plot_grid(p1, p2, p3, p4, p5, ncol = 1, align = "v")
dev.off()

```

###Salvage from second beta binomial step

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_filtering

export PATH=/software/R-3.6.1/bin:${PATH}
export R_HOME=$(R RHOME)
export R_LIBS_USER="~/custom_libraries/R/x86_64-pc-linux-gnu-library/3.6_dw"
bsub -q yesterday -Is -n 4 -R 'select[mem>=80000] rusage[mem=80000] span[hosts=1]' -M80000 R

```

```{r}

library(ComplexHeatmap)

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_filtering")

snp_files = list.files(".", "_snp_vaf_nohash.tsv$")

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')
manifest = manifest[manifest$keep == "Y", ]

source("/nfs/users/nfs_t/to3/scripts/beta_binom_flt.R")

#PD51122
patient = "PD51122"
txt_file = snp_files[grepl(patient, snp_files)]
  
lcm_samples = manifest[manifest$case.id == patient & manifest$experimental_arm == "WGS_LCM",]$sample
bulk_samples = manifest[manifest$case.id == patient & manifest$experimental_arm == "WGS_bulk",]$sample
bbinom2_vars = read.table(paste0(patient, "_bbinom_filtered_2snp.txt"), header = F, sep = '\t', stringsAsFactors = F)[,1]
data = read.table(txt_file, comment.char = "", header = T)
  
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
NV_flt = NV[bbinom2_vars,]
NR_flt = NR[bbinom2_vars,]

bulk_vars = row.names(NV_flt)[rowSums(NV_flt[, bulk_samples] > 3) > 0]

NV_flt = NV_flt[bulk_vars,]
NR_flt = NR_flt[bulk_vars,]

NR_flt_nonzero = NR_flt
NR_flt_nonzero[NR_flt_nonzero == 0] = 1

VAF_flt = NV_flt / NR_flt_nonzero

write.table(VAF_flt, paste0(patient, "_VAF_bbinom2_snps.txt"), col.names = T, row.names = T, sep = "\t", quote = F)

VAF_flt = read.table(paste0(patient, "_VAF_bbinom2_snps.txt"), header = T, sep = "\t", stringsAsFactors = F)

#use hierarchical clustering to identify mutations that are germline not found VAF 0.5/1
Heatmap(t(VAF_flt[, lcm_samples])) #real variants called in tumour that are removed by second beta-binomial

hc = hclust(dist(VAF_flt[, lcm_samples], method = "euclidean"), method = "complete")
plot(hc)
rect.hclust(hc, k = 2, border = 3:4)
clusters = cutree(hc, k = 2) 
table(clusters) #keep 1

hierarchy_pass_vars = names(clusters[clusters == 1])

NV_flt_2 = NV_flt[hierarchy_pass_vars,]
NR_flt_2 = NR_flt[hierarchy_pass_vars,]
NR_flt_2_nonzero = NR_flt_nonzero[hierarchy_pass_vars,]

##beta binomial filter for all samples to remove sequencing artefact
rho_est = beta.binom.filter(NR = NR_flt_2_nonzero[, lcm_samples], NV = NV_flt_2[, lcm_samples])

flt_rho = rho_est < 0.1
rho_filtered_out = row.names(NR_flt_2_nonzero)[flt_rho]

count_trinuc_context_38(rho_filtered_out)

NV_flt_3 = NV_flt_2[!row.names(NV_flt_2) %in% rho_filtered_out,]
NR_flt_3 = NR_flt_2[!row.names(NR_flt_2) %in% rho_filtered_out,]
NR_flt_3_nonzero = NR_flt_2_nonzero[!row.names(NR_flt_2_nonzero) %in% rho_filtered_out,]

count_trinuc_context_38(row.names(NR_flt_3_nonzero))

VAF_flt_3 = (NV_flt_3 / NR_flt_3_nonzero)

row.names(VAF_flt_3)[rowMeans(NV_flt_3 / NR_flt_3_nonzero) > 0.15]
 #"chr11_25836356_C_G"  "chr11_59621717_G_A"  "chr12_91984934_C_T"  "chr15_101789383_C_T" "chr15_101789384_A_G" "chr15_67591293_T_C"  "chr15_67591297_C_A" "chr15_67591302_A_G"  "chr15_91186873_T_A"  "chr16_16077581_T_C"  "chr16_74372963_A_G"  "chr16_74613300_G_A"  "chr17_50151013_C_T"  "chr19_1506360_G_A" "chr19_45498694_C_A"  "chr19_47158410_C_T"  "chr22_15549105_G_T"  "chr3_144563268_G_A"  "chr3_164958713_G_T"  "chr3_38156785_C_T"   "chr3_45795319_C_T" "chr4_155503239_C_T"  "chr4_156300815_G_A"  "chr4_178386347_G_A"  "chr4_91787390_C_G"   "chr5_13290358_G_T"   "chr5_145288966_C_T"  "chr5_26134169_G_T" "chr5_39310548_C_T"   "chr5_59635722_A_T"   "chr5_8283137_A_G"    "chr6_26289071_G_A"   "chr8_109396707_C_A"  "chr8_50088987_A_G"   "chr9_12107171_C_T"  "chr9_23029234_T_G"   "chr9_25061770_C_A"   "chr9_98506043_T_C" 

good_vars = c("chr12_91984934_C_T", 
              "chr16_74372963_A_G", 
              "chr16_74613300_G_A", 
              "chr19_1506360_G_A", 
              "chr19_47158410_C_T", 
              "chr3_164958713_G_T", 
              "chr3_38156785_C_T", 
              "chr3_45795319_C_T", 
              "chr4_155503239_C_T", 
              "chr4_156300815_G_A", 
              "chr4_178386347_G_A", 
              "chr5_145288966_C_T", 
              "chr5_26134169_G_T", 
              "chr5_39310548_C_T", 
              "chr5_59635722_A_T", 
              "chr5_8283137_A_G", 
              "chr6_26289071_G_A", 
              "chr8_109396707_C_A", 
              "chr9_25061770_C_A", 
              "chr9_98506043_T_C")

remove_vars = c("chr11_25836356_C_G", 
                "chr11_59621717_G_A", 
                "chr15_101789383_C_T", 
                "chr15_101789384_A_G",
                "chr15_67591293_T_C", 
                "chr15_67591297_C_A", 
                "chr15_67591302_A_G", 
                "chr15_91186873_T_A",
                "chr16_16077581_T_C", 
                "chr17_50151013_C_T", 
                "chr19_45498694_C_A", 
                "chr22_15549105_G_T", 
                "chr3_144563268_G_A", 
                "chr4_91787390_C_G", 
                "chr5_13290358_G_T",
                "chr8_50088987_A_G",
                "chr9_12107171_C_T",
                "chr9_23029234_T_G")

NV_flt_4 = NV_flt_3[!row.names(NV_flt_3) %in% remove_vars,]
NR_flt_4 = NR_flt_3[!row.names(NR_flt_3) %in% remove_vars,]
NR_flt_4_nonzero = NR_flt_3_nonzero[!row.names(NR_flt_3_nonzero) %in% remove_vars,]

write.table(row.names(NV_flt_4), paste0(patient, "_bbinom2_salvaged_snps.txt"), col.names = F, row.names = F, sep = "\t", quote = F)

snps = read.table(paste0(patient, "_bbinom2_salvaged_snps.txt"), header = F, sep = "\t", stringsAsFactors = F)[,1]
count_trinuc_context_38(snps) #166

#PD50297
patient = "PD50297"
txt_file = snp_files[grepl(patient, snp_files)]
  
lcm_samples = manifest[manifest$case.id == patient & manifest$experimental_arm == "WGS_LCM",]$sample
bulk_samples = manifest[manifest$case.id == patient & manifest$experimental_arm == "WGS_bulk",]$sample
bbinom2_vars = read.table(paste0(patient, "_bbinom_filtered_2snp.txt"), header = F, sep = '\t', stringsAsFactors = F)[,1]
data = read.table(txt_file, comment.char = "", header = T)
  
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
NV_flt = NV[bbinom2_vars,]
NR_flt = NR[bbinom2_vars,]

bulk_vars = row.names(NV_flt)[rowSums(NV_flt[, bulk_samples] > 3) > 0]

NV_flt = NV_flt[bulk_vars,]
NR_flt = NR_flt[bulk_vars,]

NR_flt_nonzero = NR_flt
NR_flt_nonzero[NR_flt_nonzero == 0] = 1

VAF_flt = NV_flt / NR_flt_nonzero

write.table(VAF_flt, paste0(patient, "_VAF_bbinom2_snps.txt"), col.names = T, row.names = T, sep = "\t", quote = F)

VAF_flt = read.table(paste0(patient, "_VAF_bbinom2_snps.txt"), header = T, sep = "\t", stringsAsFactors = F)

#use hierarchical clustering to identify mutations that are germline not found VAF 0.5/1
Heatmap(t(VAF_flt[, lcm_samples])) #real variants called in tumour that are removed by second beta-binomial

hc = hclust(dist(VAF_flt[, lcm_samples], method = "euclidean"), method = "complete")
plot(hc)

rect.hclust(hc, k = 3, border = 3:5)
clusters = cutree(hc, k = 3) 
table(clusters) #keep 1

hierarchy_pass_vars = names(clusters[clusters == 1])

NV_flt_2 = NV_flt[hierarchy_pass_vars,]
NR_flt_2 = NR_flt[hierarchy_pass_vars,]
NR_flt_2_nonzero = NR_flt_nonzero[hierarchy_pass_vars,]

##beta binomial filter for all samples to remove sequencing artefact
rho_est = beta.binom.filter(NR = NR_flt_2_nonzero[, lcm_samples], NV = NV_flt_2[, lcm_samples])

flt_rho = rho_est < 0.1
rho_filtered_out = row.names(NR_flt_2_nonzero)[flt_rho]

count_trinuc_context_38(rho_filtered_out)

NV_flt_3 = NV_flt_2[!row.names(NV_flt_2) %in% rho_filtered_out,]
NR_flt_3 = NR_flt_2[!row.names(NR_flt_2) %in% rho_filtered_out,]
NR_flt_3_nonzero = NR_flt_2_nonzero[!row.names(NR_flt_2_nonzero) %in% rho_filtered_out,]

count_trinuc_context_38(row.names(NR_flt_3_nonzero))

VAF_flt_3 = (NV_flt_3 / NR_flt_3_nonzero)

row.names(VAF_flt_3)[rowMeans(VAF_flt_3) > 0.15]
 #chr17_812197_G_A 

remove_vars = c("chr17_812197_G_A")

NV_flt_4 = NV_flt_3[!row.names(NV_flt_3) %in% remove_vars,]
NR_flt_4 = NR_flt_3[!row.names(NR_flt_3) %in% remove_vars,]
NR_flt_4_nonzero = NR_flt_3_nonzero[!row.names(NR_flt_3_nonzero) %in% remove_vars,]

count_trinuc_context_38(row.names(NV_flt_4)) #472

write.table(row.names(NV_flt_4), paste0(patient, "_bbinom2_salvaged_snps.txt"), col.names = F, row.names = F, sep = "\t", quote = F)

snps = read.table(paste0(patient, "_bbinom2_salvaged_snps.txt"), header = F, sep = "\t", stringsAsFactors = F)[,1]
count_trinuc_context_38(snps)

#PD51123
patient = "PD51123"
txt_file = snp_files[grepl(patient, snp_files)]
  
lcm_samples = manifest[manifest$case.id == patient & manifest$experimental_arm == "WGS_LCM",]$sample
bulk_samples = manifest[manifest$case.id == patient & manifest$experimental_arm == "WGS_bulk",]$sample
bbinom2_vars = read.table(paste0(patient, "_bbinom_filtered_2snp.txt"), header = F, sep = '\t', stringsAsFactors = F)[,1]
data = read.table(txt_file, comment.char = "", header = T)
  
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
NV_flt = NV[bbinom2_vars,]
NR_flt = NR[bbinom2_vars,]

bulk_vars = row.names(NV_flt)[rowSums(NV_flt[, bulk_samples] > 3) > 0]

NV_flt = NV_flt[bulk_vars,]
NR_flt = NR_flt[bulk_vars,]

NR_flt_nonzero = NR_flt
NR_flt_nonzero[NR_flt_nonzero == 0] = 1

VAF_flt = NV_flt / NR_flt_nonzero

write.table(VAF_flt, paste0(patient, "_VAF_bbinom2_snps.txt"), col.names = T, row.names = T, sep = "\t", quote = F)

VAF_flt = read.table(paste0(patient, "_VAF_bbinom2_snps.txt"), header = T, sep = "\t", stringsAsFactors = F)

#use hierarchical clustering to identify mutations that are germline not found VAF 0.5/1
Heatmap(t(VAF_flt[, lcm_samples])) #real variants called in tumour that are removed by second beta-binomial

hc = hclust(dist(VAF_flt[, lcm_samples], method = "euclidean"), method = "complete")
plot(hc)
rect.hclust(hc, k = 2, border = 3:4)
clusters = cutree(hc, k = 2) 
table(clusters) #keep 1

hierarchy_pass_vars = names(clusters[clusters == 1])

NV_flt_2 = NV_flt[hierarchy_pass_vars,]
NR_flt_2 = NR_flt[hierarchy_pass_vars,]
NR_flt_2_nonzero = NR_flt_nonzero[hierarchy_pass_vars,]

##beta binomial filter for all samples to remove sequencing artefact
rho_est = beta.binom.filter(NR = NR_flt_2_nonzero[, lcm_samples], NV = NV_flt_2[, lcm_samples])

flt_rho = rho_est < 0.1
rho_filtered_out = row.names(NR_flt_2_nonzero)[flt_rho]

count_trinuc_context_38(rho_filtered_out)

NV_flt_3 = NV_flt_2[!row.names(NV_flt_2) %in% rho_filtered_out,]
NR_flt_3 = NR_flt_2[!row.names(NR_flt_2) %in% rho_filtered_out,]
NR_flt_3_nonzero = NR_flt_2_nonzero[!row.names(NR_flt_2_nonzero) %in% rho_filtered_out,]

count_trinuc_context_38(row.names(NR_flt_3_nonzero))

VAF_flt_3 = (NV_flt_3 / NR_flt_3_nonzero)

row.names(VAF_flt_3)[rowMeans(NV_flt_3 / NR_flt_3_nonzero) > 0.15] #none
 
good_vars = c()

remove_vars = c()

NV_flt_4 = NV_flt_3[!row.names(NV_flt_3) %in% remove_vars,]
NR_flt_4 = NR_flt_3[!row.names(NR_flt_3) %in% remove_vars,]
NR_flt_4_nonzero = NR_flt_3_nonzero[!row.names(NR_flt_3_nonzero) %in% remove_vars,]

count_trinuc_context_38(row.names(NV_flt_4)) #13

write.table(row.names(NV_flt_4), paste0(patient, "_bbinom2_salvaged_snps.txt"), col.names = F, row.names = F, sep = "\t", quote = F)

snps = read.table(paste0(patient, "_bbinom2_salvaged_snps.txt"), header = F, sep = "\t", stringsAsFactors = F)[,1]
count_trinuc_context_38(snps)

```

###10) Filter on MQ fraction

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_filtering")

patients = c("PD50297", "PD51122", "PD51123")

for(patient in patients){
  
  data1 = read.table(paste0(patient, "_filtered_remaining_all_snp.txt"), header = F, sep = "\t", stringsAsFactors = F)[,1]
  data2 = read.table(paste0(patient, "_bbinom2_salvaged_snps.txt"), header = F, sep = "\t", stringsAsFactors = F)[,1]
  data = sort(c(data1, data2))
  data_df = data.frame(matrix(unlist(strsplit(data, "_")), ncol = 4 , byrow = T))
  write.table(data_df, paste0(patient, "_filtered_remaining_all_snp_df.txt"), col.names = F, row.names = F, sep = "\t", quote = F)
  
}

```


```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_output_mq0_pileup

infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($27 == "Y") { print $1, $6} }' $infile | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bas .
done

ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bas .

```

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_filtering

cp *_filtered_remaining_all_snp_df.txt /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_output_mq0_pileup

```

####Run cgpvaf MQ0

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_output_mq0_pileup

module load cgpVAFcommand

for patient in PD50297 PD51122 PD51123;
do

declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

mkdir -p ${patient}

#run per chromosome, need to change out and err files to specify chr 1/8/22
for chr in chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY;
do
bsub -q long -o ${patient}/%J.${patient}_${chr}_snp.out -e ${patient}/%J.${patient}_${chr}_snp.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl -d ./ -o ${patient} -a snp -mq 0 -bq 25 -g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa -be .sample.dupmarked.bam -hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz -bo 1 -b ${patient}_filtered_remaining_all_snp_df.txt -nn PDv38is_wgs -tn ${sampleArray[@]} -chr $chr
done

done

```

Check all jobs completely successfully

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_output_mq0_pileup

grep "Successfully" PD*/*chr*_snp.out | wc -l #72, all accounted for!

```

Concatenate per chromosome output

```{bash}

module load cgpVAFcommand

#PD50297
cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_output_mq0_pileup

patient="PD50297"
tmpdir=${patient}/"tmpvaf_"${patient}"ab_lo0001"

##get list of samples from patient
declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

cd $tmpdir

##for unclear reasons the bam files need to be in the same directory as the tmp files
infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($27 == "Y") { print $1, $6} }' $infile | grep $patient | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bas .
done

ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bas .

##submit concatenate job
bsub -q long -o ../%J.${patient}_concat.out -e ../%J.${patient}_concat.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl \
-d ./ \
-o ../ \
-a snp \
-g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa \
-hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz \
-bo 1 \
-b ../../${patient}_filtered_remaining_all_snp_df.txt \
-be .sample.dupmarked.bam \
-nn PDv38is_wgs \
-tn ${sampleArray[@]} \
-ct 1

#PD51122
cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_output_mq0_pileup

patient="PD51122"
tmpdir=${patient}/"tmpvaf_"${patient}"ab_lo0001"

##get list of samples from patient
declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

cd $tmpdir

##for unclear reasons the bam files need to be in the same directory as the tmp files
infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($27 == "Y") { print $1, $6} }' $infile | grep $patient | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bas .
done

ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bas .

##submit concatenate job
bsub -q long -o ../%J.${patient}_concat.out -e ../%J.${patient}_concat.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl \
-d ./ \
-o ../ \
-a snp \
-g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa \
-hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz \
-bo 1 \
-b ../../${patient}_filtered_remaining_all_snp_df.txt \
-be .sample.dupmarked.bam \
-nn PDv38is_wgs \
-tn ${sampleArray[@]} \
-ct 1

#PD51123
cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_output_mq0_pileup

patient="PD51123"
tmpdir=${patient}/"tmpvaf_"${patient}"aa3"

##get list of samples from patient
declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

cd $tmpdir

##for unclear reasons the bam files need to be in the same directory as the tmp files
infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($27 == "Y") { print $1, $6} }' $infile | grep $patient | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bas .
done

ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bas .

##submit concatenate job
bsub -q long -o ../%J.${patient}_concat.out -e ../%J.${patient}_concat.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl \
-d ./ \
-o ../ \
-a snp \
-g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa \
-hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz \
-bo 1 \
-b ../../${patient}_filtered_remaining_all_snp_df.txt \
-be .sample.dupmarked.bam \
-nn PDv38is_wgs \
-tn ${sampleArray[@]} \
-ct 1

```

####Run filtering

Copy over the per case pileup files
```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_mq0_filtering

cp /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_output_mq0_pileup/PD*/*_snp_vaf.tsv .

#remove header info
for f in $(ls *_snp_vaf.tsv);
do
filename=$(basename -- "$f")
filename="${filename%_snp_vaf.tsv}"
#echo $filename
grep -v "##" $f > ${filename}_snp_vaf_nohash.tsv
done

```

Run R code below in interactive job

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_mq0_filtering

export PATH=/software/R-3.6.1/bin:${PATH}
export R_HOME=$(R RHOME)
export R_LIBS_USER="~/custom_libraries/R/x86_64-pc-linux-gnu-library/3.6_dw"
bsub -q yesterday -Is -n 4 -R 'select[mem>=80000] rusage[mem=80000] span[hosts=1]' -M80000 R

```


```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_mq0_filtering")

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')
manifest = manifest[manifest$keep == "Y", ]

#PD50297
txt_file = "PDv38is_wgs_PD50297ab_lo0001_snp_vaf_nohash.tsv"

#read in relevant file for MQ 0 pileup
data = read.table(txt_file, comment.char = "", header = T)
patient = substr(unlist(strsplit(txt_file, 'PDv38is_wgs_'))[2], 0, 7)

#extract data frames of interest
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
NV_mq0 = NV
NR_mq0 = NR
  
#read in relevant file for MQ 30 pileup
data = read.table(paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/binom_filtering/", txt_file), comment.char = "", header = T)

#extract data frames of interest
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
NV_mq30 = NV[row.names(NV_mq0),]
NR_mq30 = NR[row.names(NR_mq0),]

manifest_flt = manifest[manifest$case.id == patient,]

#filter
##high MQ filter
hq_mq_vars = row.names(NR_mq30[,manifest_flt$sample])[rowSums(NR_mq30[,manifest_flt$sample]) / rowSums(NR_mq0[,manifest_flt$sample]) > 0.9]
  
write.table(hq_mq_vars, paste0(patient, "_hq_mq_vars.txt"), col.names = F, row.names = F, sep = '\t', quote = F)

#PD51122
txt_file = "PDv38is_wgs_PD51122ab_lo0001_snp_vaf_nohash.tsv"

#read in relevant file for MQ 0 pileup
data = read.table(txt_file, comment.char = "", header = T)
patient = substr(unlist(strsplit(txt_file, 'PDv38is_wgs_'))[2], 0, 7)

#extract data frames of interest
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
NV_mq0 = NV
NR_mq0 = NR
  
#read in relevant file for MQ 30 pileup
data = read.table(paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/binom_filtering/", txt_file), comment.char = "", header = T)

#extract data frames of interest
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
NV_mq30 = NV[row.names(NV_mq0),]
NR_mq30 = NR[row.names(NR_mq0),]

manifest_flt = manifest[manifest$case.id == patient,]

#filter
##high MQ filter
hq_mq_vars = row.names(NR_mq30[,manifest_flt$sample])[rowSums(NR_mq30[,manifest_flt$sample]) / rowSums(NR_mq0[,manifest_flt$sample]) > 0.9] #"PD51122g_lo0003" was accidentally wiped and re-run by cgpIT, now counts seem to be very slightly lower in 14 variants 

#NR_mq30[names(rowSums(NR_mq30[,manifest_flt$sample]))[rowSums(NR_mq30[,manifest_flt$sample]) / rowSums(NR_mq0[,manifest_flt$sample]) > 1], "PD51122g_lo0003"]
#NR_mq0[names(rowSums(NR_mq30[,manifest_flt$sample]))[rowSums(NR_mq30[,manifest_flt$sample]) / rowSums(NR_mq0[,manifest_flt$sample]) > 1], "PD51122g_lo0003"]

write.table(hq_mq_vars, paste0(patient, "_hq_mq_vars.txt"), col.names = F, row.names = F, sep = '\t', quote = F)
  
#PD51123
txt_file = "PDv38is_wgs_PD51123aa3_snp_vaf_nohash.tsv"

#read in relevant file for MQ 0 pileup
data = read.table(txt_file, comment.char = "", header = T)
patient = substr(unlist(strsplit(txt_file, 'PDv38is_wgs_'))[2], 0, 7)

#extract data frames of interest
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
NV_mq0 = NV
NR_mq0 = NR
  
#read in relevant file for MQ 30 pileup
data = read.table(paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/binom_filtering/", txt_file), comment.char = "", header = T)

#extract data frames of interest
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
NV_mq30 = NV[row.names(NV_mq0),]
NR_mq30 = NR[row.names(NR_mq0),]

manifest_flt = manifest[manifest$case.id == patient,]

#filter
##high MQ filter
hq_mq_vars = row.names(NR_mq30[,manifest_flt$sample])[rowSums(NR_mq30[,manifest_flt$sample]) / rowSums(NR_mq0[,manifest_flt$sample]) > 0.9]
  
write.table(hq_mq_vars, paste0(patient, "_hq_mq_vars.txt"), col.names = F, row.names = F, sep = '\t', quote = F)

```

###Merge final calls from all lists

```{r}

#including MQ filtering on binom filter pass calls

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/merged_final_subs")

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')
manifest = manifest[manifest$keep == "Y", ]

mq30_files = list.files("/lustre/scratch119/realdata/mdt1/team274/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/binom_filtering", "_snp_vaf_nohash.tsv$", full.names = T)
mq_flt_files = list.files("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_mq0_filtering", "_hq_mq_vars.txt", full.names = T) #added 24/9/22

patients = c("PD50297", "PD51122", "PD51123")

salvaged_poss_drivers = list(PD50297 = c("chr1_26771195_T_A", 
                                         "chr1_226064434_A_T", 
                                         "chr10_87957904_C_A", 
                                         "chr17_7673802_C_T", 
                                         "chrX_40062243_C_A"),
                             PD51122 = c("chr17_7675140_G_C", 
                                         "chr17_31200443_C_T", 
                                         "chr17_31214524_A_G", 
                                         "chr3_179218294_G_A", 
                                         "chrX_40062243_C_A"),
                             PD51123 = c("chr1_17648676_G_A", 
                                         "chr1_226064434_A_T", 
                                         "chr17_7675088_C_T", 
                                         "chrX_40062243_C_A")) #variants that are plausible drivers pre-binomial filtering steps

for(patient in patients){
  
  print(patient)
  original_vars = read.table(mq_flt_files[grepl(patient, mq_flt_files)], header = F, sep = "\t", stringsAsFactors = F)[,1]
  driver_vars = salvaged_poss_drivers[[patient]]
  
  all_vars = unique(sort(c(original_vars, driver_vars)))
  
  txt_file = mq30_files[grepl(patient, mq30_files)]
  
  data = read.table(txt_file, comment.char = "", header = T)

  #extract data frames of interest
  Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
  Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
  NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
  NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
  colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
  rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
  NV_flt = NV[all_vars,]
  NR_flt = NR[all_vars,]
  
  NR_flt_nonzero = NR_flt
  NR_flt_nonzero[NR_flt_nonzero == 0] = 1
  
  VAF_flt = NV_flt / NR_flt_nonzero
  
  write.table(NV_flt, paste0(patient, "_NV_merged_snps.txt"), col.names = T, row.names = T, sep = "\t", quote = F)
  write.table(NR_flt, paste0(patient, "_NR_merged_snps.txt"), col.names = T, row.names = T, sep = "\t", quote = F)
  write.table(VAF_flt, paste0(patient, "_VAF_merged_snps.txt"), col.names = T, row.names = T, sep = "\t", quote = F)
  write.table(row.names(VAF_flt), paste0(patient, "_merged_snps_list.txt"), col.names = F, row.names = F, sep = "\t", quote = F)
  
}

```

###Intersect with VCF files

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/04_1000G_PON #rescue those that fail direction filter in one sample but not others

export PATH=/software/R-4.1.0/bin:${PATH}
export R_HOME=$(R RHOME)

for file in $(ls *.standard.gnomAD.AF.0.001.PON.filtered.vcf);
do
sample=${file%.standard.gnomAD.AF.0.001.PON.filtered.vcf}
#echo $sample
bsub -q small -o ../06_bbinom/${sample}_filter.out -e ../06_bbinom/${sample}_filter.err -n 4 -R 'select[mem>=20000] rusage[mem=20000] span[hosts=1]' -M20000 /software/R-4.1.0/bin/Rscript ~/scripts/filter_annotated_CaVEMan_vcfs_20220924.R -f $file
done

#for file in $(ls PD50297*.standard.gnomAD.AF.0.001.PON.filtered.vcf);
#do
#sample=${file%.standard.gnomAD.AF.0.001.PON.filtered.vcf}
#echo $sample
#bsub -q small -o ../06_bbinom/${sample}_filter.out -e ../06_bbinom/${sample}_filter.err -n 4 -R 'select[mem>=20000] rusage[mem=20000] span[hosts=1]' -M20000 /software/R-4.1.0/bin/Rscript ~/scripts/filter_annotated_CaVEMan_vcfs.R -f $file
#done

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/06_bbinom

ls *vcf | wc -l #909, two hit term limit waiting I think

```

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/06_bbinom")

vcf.files = list.files(".", "vcf")
out.files = list.files(".", "out")

vcfs = unlist(strsplit(vcf.files, ".standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.filtered.vcf"))
outs = unlist(strsplit(out.files, "_filter.out"))

outs[!outs %in% vcfs]

```

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/04_1000G_PON #rescue those that fail direction filter in one sample but not others

export PATH=/software/R-4.1.0/bin:${PATH}
export R_HOME=$(R RHOME)

bsub -q small -o ../06_bbinom/PD51122ae_lo0013_filter.out -e ../06_bbinom/PD51122ae_lo0013_filter.err -n 4 -R 'select[mem>=20000] rusage[mem=20000] span[hosts=1]' -M20000 /software/R-4.1.0/bin/Rscript ~/scripts/filter_annotated_CaVEMan_vcfs_20220924.R -f PD51122ae_lo0013.standard.gnomAD.AF.0.001.PON.filtered.vcf
bsub -q small -o ../06_bbinom/PD51122ae_lo0018_filter.out -e ../06_bbinom/PD51122ae_lo0018_filter.err -n 4 -R 'select[mem>=20000] rusage[mem=20000] span[hosts=1]' -M20000 /software/R-4.1.0/bin/Rscript ~/scripts/filter_annotated_CaVEMan_vcfs_20220924.R -f PD51122ae_lo0018.standard.gnomAD.AF.0.001.PON.filtered.vcf

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/06_bbinom

ls *vcf | wc -l #911, all accounted for

```

```{r}

#filter_annotated_CaVEMan_vcfs.R

library(VariantAnnotation)
library(optparse)

option_list = list(
  make_option(c("-f", "--file"), type="character", default=NULL, help="File name, ending in .edited.vcf", metavar="character"))

opt_parser = OptionParser(option_list=option_list)
opt = parse_args(opt_parser)

vcf = opt$file

sample = strsplit(vcf, '\\.')[[1]][1]
patient = substr(sample, 0, 7)

filtered_muts = read.table(paste0('/lustre/scratch119/realdata/mdt1/team274/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/merged_final_subs/', patient, '_final_merged_snps_list.txt'), header = F, sep = '\t', stringsAsFactors = F)[,1]

data = VariantAnnotation::readVcf(vcf)
filtered_data = data[unlist(info(data)$mut_ID) %in% filtered_muts]

writeVcf(filtered_data, filename = paste0("../06_bbinom/", sample, '.standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.filtered.vcf'))

```

```{r}

#filter_annotated_CaVEMan_vcfs_20220924.R

library(VariantAnnotation)
library(optparse)

option_list = list(
  make_option(c("-f", "--file"), type="character", default=NULL, help="File name, ending in .edited.vcf", metavar="character"))

opt_parser = OptionParser(option_list=option_list)
opt = parse_args(opt_parser)

vcf = opt$file

sample = strsplit(vcf, '\\.')[[1]][1]
patient = substr(sample, 0, 7)

filtered_muts = read.table(paste0('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/merged_final_subs/', patient, '_merged_snps_list.txt'), header = F, sep = '\t', stringsAsFactors = F)[,1]

data = VariantAnnotation::readVcf(vcf)
filtered_data = data[unlist(info(data)$mut_ID) %in% filtered_muts]

writeVcf(filtered_data, filename = paste0("../06_bbinom/", sample, '.standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.filtered.vcf'))

```

###11) Remove variants near to indels

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/indels/01_pindel

for f in $(ls *.pindel.annot.vcf.gz);
do
filename=$(basename -- "$f")
sample="${filename%.pindel.annot.vcf.gz}"
bsub -q small -o ${sample}_bed_file_5bp.out -e ${sample}_bed_file_5bp.err -n 4 -R 'select[mem>=20000] rusage[mem=20000] span[hosts=1]' -M20000 bash ../bed_file_5bp_20220907.sh $f
done

#bed_file_5bp_20220907.sh
f=$1
filename=$(basename -- "$f")
sample="${filename%.pindel.annot.vcf.gz}"
#zless ${sample}.pindel.annot.vcf.gz | awk '! /\#/' | awk '{if(length($4) > length($5)) print $1"\t"($2-1)"\t"($2+length($4)-1); else print $1"\t"($2-1)"\t"($2+length($5)-1)}' > ${sample}.all_indels.bed
zless ${sample}.pindel.annot.vcf.gz | awk '! /\#/' | awk '{if(length($4) > length($5)) print $1"\t"($2-6)"\t"($2+length($4)+4); else print $1"\t"($2-6)"\t"($2+length($5)+4)}' > ${sample}.all_indels.5bp.window.bed

```

```{bash}

#now intersect with subs
cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/06_bbinom

module load bedtools

for f in $(ls PD*.standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.filtered.vcf);
do
filename=$(basename -- "$f")
sample="${filename%.standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.filtered.vcf}"
bsub -q small -o ${sample}_bed_file_intersect_5bp.out -e ${sample}_bed_file_intersect_5bp.err -n 4 -R 'select[mem>=20000] rusage[mem=20000] span[hosts=1]' -M20000 bash ../all_5bp_indel_file_intersect_20220924.sh $f
done

#all_5bp_indel_file_intersect_20220924.sh
f=$1
filename=$(basename -- "$f")
sample="${filename%.standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.filtered.vcf}"
bedtools intersect -v -header -a ${sample}.standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.filtered.vcf -b /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/indels/01_pindel/${sample}.all_indels.5bp.window.bed > ../07_indel/${sample}.standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.5bp.indel.filtered.vcf

```

###Convert to txt files

####Function

```{r}

#sub_vcf_to_txt_file_20220924.R

library(VariantAnnotation)
library(optparse)

option_list = list(
  make_option(c("-f", "--file"), type="character", default=NULL, help="File name, ending in .standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.5bp.indel.filtered.vcf", metavar="character"))

opt_parser = OptionParser(option_list=option_list)
opt = parse_args(opt_parser)

vcf = opt$file

annotated_subs_text_file = function(vcf_file){
    vcf = readVcf(vcf_file)
    
    if(nrow(vcf) > 0){
      sample = unlist(strsplit(vcf_file, '.standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.5bp.indel.filtered.vcf'))
      case = substr(sample, 0, 7)
      reads = cbind((geno(vcf)$FAZ)[,2]+(geno(vcf)$RAZ)[,2],(geno(vcf)$FCZ)[,2]+(geno(vcf)$RCZ)[,2],
                (geno(vcf)$FGZ)[,2]+(geno(vcf)$RGZ)[,2],(geno(vcf)$FTZ)[,2]+(geno(vcf)$RTZ)[,2])
      var.df = data.frame(Chr = as.character(seqnames(rowRanges(vcf))),
                    Position = start(ranges(rowRanges(vcf))),
                    Wildtype = as.character(ref(vcf)),
                    Mutant = unlist(CharacterList(alt(vcf))))
      var.df$Total_read_depth=rowSums(reads)
      var.df$Variant_read_depth=NA
      var.df$Case_ID = case
      var.df$Sample = sample
      var.df = var.df[, c(7, 8, 1:6)]
      colnames(reads)=c("A","C","G","T")
      for (k in c("A","C","G","T")){
        var.df$Variant_read_depth[var.df$Mutant==k] = reads[var.df$Mutant==k,k]
      }
  
      var.df$VAF = var.df$Variant_read_depth/ var.df$Total_read_depth
      var.df$Mutation = info(vcf)$VT
      vagrent_annots = lapply(strsplit(info(vcf)$VW, '\\|'), `length<-`, max(lengths(strsplit(info(vcf)$VW, '\\|')))) #make all elements in list the same length for subsetting purposes
      
      vagrent_annots = lapply(strsplit(info(vcf)$VW, '\\|'), `length<-`, max(lengths(strsplit(info(vcf)$VW, '\\|')))) #make all elements in list the same length for subsetting purposes
      
      if(max(unlist(lapply(vagrent_annots, function(x) length(x)))) == 1){ #where none land in gene footprints and single NA values are found in each case
        var.df$Gene = NA
        var.df$Transcript = NA
        var.df$Codon = NA
        var.df$Protein = NA
      } else {
        var.df$Gene = sapply(vagrent_annots, '[[', 1)
        var.df$Transcript = sapply(vagrent_annots, '[[', 3)
        var.df$Codon = sapply(vagrent_annots, '[[', 4)
        var.df$Protein = sapply(vagrent_annots, '[[', 5)
      }

      conseq_list = lapply(info(vcf)$VC, function(x) if(identical(x, character(0))) NA_character_ else x)
      conseq_vec = c()
      for(i in 1:length(conseq_list)){
        conseq_vec = c(conseq_vec, paste(unlist(conseq_list[i]), collapse = ';'))
      }
  
      var.df$Consequence = conseq_vec
      
      write.table(var.df, paste0(sample, '.standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.5bp.indel.filtered.txt'), col.names = T, row.names = F, quote = F, sep = '\t')
    
    }
}

annotated_subs_text_file(vcf)

```

####Run

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/07_indel

export PATH=/software/R-4.1.0/bin:${PATH}
#export R_HOME=$(R RHOME)

for file in $(ls *.standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.5bp.indel.filtered.vcf);
do
sample=${file%.standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.5bp.indel.filtered.vcf}
#echo $sample
bsub -q small -o ${sample}_txt_convert.out -e ${sample}_txt_convert.err -n 4 -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M10000 /software/R-4.1.0/bin/Rscript ~/scripts/sub_vcf_to_txt_file_20220924.R -f $file
done

ls *txt | wc -l #911, variants in all samples called

```

Check a few samples to ensure veracity of calls
PD50297b 18/18

PD51122q 16 good, 4 borderline /20
chr1_169603900_G_T - borderline
chr2_95944503_C_A - borderline
chr21_27930728_C_A - borderline
chr5_112089164_G_A - borderline

PD51122aa3 14 good, 2 borderline /16
chr1_162729402_A_G - borderline
chr8_12019457_A_G - borderline

###Plot mutational spectra per sample

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/07_indel")

library("GenomicRanges")
library("Rsamtools")
library("MASS")
library(VariantAnnotation)

genomeFile <- "/lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa"

patients = c("PD50297", "PD51122", "PD51123")

plot_trinuc_context <- function(input){
  mutations = data.frame(matrix(unlist(strsplit(input, "_")), ncol = 4, byrow= T))
  names(mutations) = c("chr", "pos", "ref", "mut")
  mutations = mutations[(mutations$ref %in% c("A","C","G","T")) & (mutations$mut %in% c("A","C","G","T")) & mutations$chr %in% paste0("chr", c(1:22,"X","Y")),]
  mutations$trinuc_ref = as.vector(scanFa(genomeFile, GRanges(mutations$chr, IRanges(as.numeric(mutations$pos)-1,
                                                                                     as.numeric(mutations$pos)+1))))

  # 2. Annotating the mutation from the pyrimidine base
  ntcomp = c(T="A",G="C",C="G",A="T")
  mutations$sub = paste(mutations$ref,mutations$mut,sep=">")
  mutations$trinuc_ref_py = mutations$trinuc_ref
  for (j in 1:nrow(mutations)) {
    if (mutations$ref[j] %in% c("A","G")) { # Purine base
      mutations$sub[j] = paste(ntcomp[mutations$ref[j]],ntcomp[mutations$mut[j]],sep=">")
      mutations$trinuc_ref_py[j] = paste(ntcomp[rev(strsplit(mutations$trinuc_ref[j],split="")[[1]])],collapse="")
    }
  }
  freqs = table(paste(mutations$sub,paste(substr(mutations$trinuc_ref_py,1,1),substr(mutations$trinuc_ref_py,3,3),sep="-"),sep=","))
  sub_vec = c("C>A","C>G","C>T","T>A","T>C","T>G")
  ctx_vec = paste(rep(c("A","C","G","T"),each=4),rep(c("A","C","G","T"),times=4),sep="-")
  full_vec = paste(rep(sub_vec,each=16),rep(ctx_vec,times=6),sep=",")
  freqs_full = freqs[full_vec]; freqs_full[is.na(freqs_full)] = 0; names(freqs_full) = full_vec
  
  #3. plot
  xstr = paste(substr(full_vec,5,5), substr(full_vec,1,1), substr(full_vec,7,7), sep="")

  colvec = rep(c("dodgerblue","black","red","grey70","olivedrab3","plum2"),each=16)
  y = freqs_full; maxy = max(y)
  h = barplot(y, las=2, col=colvec, border=NA, ylim=c(0,maxy*1.5), space=1, cex.names=0.6, names.arg=xstr, ylab="Number of mutations")
  for (j in 1:length(sub_vec)) {
    xpos = h[c((j-1)*16+1,j*16)]
    rect(xpos[1]-0.5, maxy*1.2, xpos[2]+0.5, maxy*1.3, border=NA, col=colvec[j*16])
    text(x=mean(xpos), y=maxy*1.3, pos=3, label=sub_vec[j])
  } 
  title(main = paste0(patient), sub = paste0("filtered subs = ", length(input)))
}

vcf_files = list.files(".", ".standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.5bp.indel.filtered.vcf")

for(vcf in vcf_files){
  data = readVcf(vcf)
  
  if(nrow(data) > 0){
    
    patient = unlist(strsplit(vcf, ".standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.5bp.indel.filtered.vcf"))
    mut_list = unlist(info(data)$mut_ID)
  
    pdf(paste0(patient, "_final_sub_mutational_spectra.pdf"), height = 5, width = 12)
    plot_trinuc_context(mut_list)
    dev.off()
    
  }
  
}

```

###Generate final list of subs

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/merged_final_subs

for f in PD50297 PD51122 PD51123;
do

for file in $(ls /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/07_indel/${f}*.standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.5bp.indel.filtered.vcf);
do
grep -v "#" $file | cut -f 1,2,4,5 >> ${f}_subs.bed
done

cat ${f}_subs.bed | sort -k1,1 -k2,2n -k3,4 | uniq > ${f}_subs_unique.bed
mv ${f}_subs_unique.bed ${f}_subs.bed

done

```

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/merged_final_subs")

bed.files = list.files(".", "_subs.bed")

for(file in bed.files){
  
  data  = read.table(file, header = F, sep = "\t", stringsAsFactors = F)
  patient = unlist(strsplit(file, "_subs.bed"))
  
  muts = paste(data$V1, data$V2, data$V3, data$V4, sep = "_")
  
  VAF = read.table(paste0(patient, "_VAF_merged_snps.txt"), header = T, sep = "\t", stringsAsFactors = F)
  NR = read.table(paste0(patient, "_NR_merged_snps.txt"), header = T, sep = "\t", stringsAsFactors = F)
  NV = read.table(paste0(patient, "_NV_merged_snps.txt"), header = T, sep = "\t", stringsAsFactors = F)
  
  VAF_flt = VAF[muts,]
  NR_flt = NR[muts,]
  NV_flt = NV[muts,]
  
  write.table(VAF_flt, paste0(patient, "_VAF_final_merged_snps.txt"), col.names = T, row.names = T, sep = "\t", quote = F)
  write.table(NR_flt, paste0(patient, "_NR_final_merged_snps.txt"), col.names = T, row.names = T, sep = "\t", quote = F)
  write.table(NV_flt, paste0(patient, "_NV_final_merged_snps.txt"), col.names = T, row.names = T, sep = "\t", quote = F)
  
}

```

###MQ60 pileup

Occasional samples have outlier burdens with variants characterised by their presence mostly in regions with MQ ~40 rather than 60. We can stratify our variants by those that are MQ == 30-59 and those MQ == 60.

It appears the MQ argument is > $var so we set it to 59, not 60. 60 removes all reads!

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/final_subs_mq60_pileup

infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($27 == "Y") { print $1, $6} }' $infile | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bas .
done

ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bas .

```

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/merged_final_subs

cp *_subs.bed /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/final_subs_mq60_pileup

```

####Run cgpvaf MQ60

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/final_subs_mq60_pileup

module load cgpVAFcommand

for patient in PD50297 PD51122 PD51123;
do

declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

mkdir -p ${patient}

#run per chromosome, need to change out and err files to specify chr 1/8/22
for chr in chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY;
do
bsub -q long -o ${patient}/%J.${patient}_${chr}_snp.out -e ${patient}/%J.${patient}_${chr}_snp.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl -d ./ -o ${patient} -a snp -mq 59 -bq 25 -g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa -be .sample.dupmarked.bam -hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz -bo 1 -b ${patient}_subs.bed -nn PDv38is_wgs -tn ${sampleArray[@]} -chr $chr
done

done

```

Check all jobs completely successfully

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/final_subs_mq60_pileup

grep "Successfully" PD*/*chr*_snp.out | wc -l #72, all accounted for!

```

Concatenate per chromosome output

```{bash}

module load cgpVAFcommand

#PD50297
cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/final_subs_mq60_pileup

patient="PD50297"
tmpdir=${patient}/"tmpvaf_"${patient}"ab_lo0001"

##get list of samples from patient
declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

cd $tmpdir

##for unclear reasons the bam files need to be in the same directory as the tmp files
infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($27 == "Y") { print $1, $6} }' $infile | grep $patient | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bas .
done

ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bas .

##submit concatenate job
bsub -q long -o ../%J.${patient}_concat.out -e ../%J.${patient}_concat.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl \
-d ./ \
-o ../ \
-a snp \
-g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa \
-hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz \
-bo 1 \
-b ../../${patient}_subs.bed \
-be .sample.dupmarked.bam \
-nn PDv38is_wgs \
-tn ${sampleArray[@]} \
-ct 1

#PD51122
cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/final_subs_mq60_pileup

patient="PD51122"
tmpdir=${patient}/"tmpvaf_"${patient}"ab_lo0001"

##get list of samples from patient
declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

cd $tmpdir

##for unclear reasons the bam files need to be in the same directory as the tmp files
infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($27 == "Y") { print $1, $6} }' $infile | grep $patient | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bas .
done

ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bas .

##submit concatenate job
bsub -q long -o ../%J.${patient}_concat.out -e ../%J.${patient}_concat.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl \
-d ./ \
-o ../ \
-a snp \
-g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa \
-hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz \
-bo 1 \
-b ../../${patient}_subs.bed \
-be .sample.dupmarked.bam \
-nn PDv38is_wgs \
-tn ${sampleArray[@]} \
-ct 1

#PD51123
cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/final_subs_mq60_pileup

patient="PD51123"
tmpdir=${patient}/"tmpvaf_"${patient}"aa3"

##get list of samples from patient
declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

cd $tmpdir

##for unclear reasons the bam files need to be in the same directory as the tmp files
infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($27 == "Y") { print $1, $6} }' $infile | grep $patient | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bas .
done

ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bas .

##submit concatenate job
bsub -q long -o ../%J.${patient}_concat.out -e ../%J.${patient}_concat.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl \
-d ./ \
-o ../ \
-a snp \
-g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa \
-hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz \
-bo 1 \
-b ../../${patient}_subs.bed \
-be .sample.dupmarked.bam \
-nn PDv38is_wgs \
-tn ${sampleArray[@]} \
-ct 1

```

####Run filter

Copy over the per case pileup files
```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/final_subs_mq60_filtering

cp /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/final_subs_mq60_pileup/PD*/*_snp_vaf.tsv .

#remove header info
for f in $(ls *_snp_vaf.tsv);
do
filename=$(basename -- "$f")
filename="${filename%_snp_vaf.tsv}"
#echo $filename
grep -v "##" $f > ${filename}_snp_vaf_nohash.tsv
done

```

Run R code below in interactive job

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/final_subs_mq60_filtering

export PATH=/software/R-3.6.1/bin:${PATH}
export R_HOME=$(R RHOME)
export R_LIBS_USER="~/custom_libraries/R/x86_64-pc-linux-gnu-library/3.6_dw"
bsub -q yesterday -Is -n 4 -R 'select[mem>=80000] rusage[mem=80000] span[hosts=1]' -M80000 R

```

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/final_subs_mq60_filtering")

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')
manifest = manifest[manifest$keep == "Y", ]

#PD50297
txt_file = "PDv38is_wgs_PD50297ab_lo0001_snp_vaf_nohash.tsv"

#read in MQ60 pileup
data = read.table(txt_file, comment.char = "", header = T)
patient = substr(unlist(strsplit(txt_file, 'PDv38is_wgs_'))[2], 0, 7)

#extract data frames of interest
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
NV_mq60 = NV
NR_mq60 = NR

#read in relevant file for MQ 0 pileup
data = read.table(paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_mq0_filtering/", txt_file), comment.char = "", header = T)

#extract data frames of interest
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
NV_mq0 = NV[intersect(row.names(NV_mq60), row.names(NV)),]
NR_mq0 = NR[intersect(row.names(NV_mq60), row.names(NV)),]

NV_mq60 = NV_mq60[row.names(NV_mq0),] #putative drivers that failed other filters aren't in mq0 file
NR_mq60 = NR_mq60[row.names(NV_mq0),]

manifest_flt = manifest[manifest$case.id == patient,]

#filter
##high MQ filter
hq_mq_vars = row.names(NR_mq60[,manifest_flt$sample])[rowSums(NR_mq60[,manifest_flt$sample]) / rowSums(NR_mq0[,manifest_flt$sample]) > 0.9]
  
write.table(hq_mq_vars, paste0(patient, "_hq_mq_vars.txt"), col.names = F, row.names = F, sep = '\t', quote = F)

#PD51122
txt_file = "PDv38is_wgs_PD51122ab_lo0001_snp_vaf_nohash.tsv"

#read in MQ60 pileup
data = read.table(txt_file, comment.char = "", header = T)
patient = substr(unlist(strsplit(txt_file, 'PDv38is_wgs_'))[2], 0, 7)

#extract data frames of interest
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
NV_mq60 = NV
NR_mq60 = NR

#read in relevant file for MQ 0 pileup
data = read.table(paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_mq0_filtering/", txt_file), comment.char = "", header = T)

#extract data frames of interest
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
NV_mq0 = NV[intersect(row.names(NV_mq60), row.names(NV)),]
NR_mq0 = NR[intersect(row.names(NV_mq60), row.names(NV)),]

NV_mq60 = NV_mq60[row.names(NV_mq0),] #putative drivers that failed other filters aren't in mq0 file
NR_mq60 = NR_mq60[row.names(NV_mq0),]

manifest_flt = manifest[manifest$case.id == patient,]

#filter
##high MQ filter
hq_mq_vars = row.names(NR_mq60[,manifest_flt$sample])[rowSums(NR_mq60[,manifest_flt$sample]) / rowSums(NR_mq0[,manifest_flt$sample]) > 0.9]
  
write.table(hq_mq_vars, paste0(patient, "_hq_mq_vars.txt"), col.names = F, row.names = F, sep = '\t', quote = F)
  
#PD51123
txt_file = "PDv38is_wgs_PD51123aa3_snp_vaf_nohash.tsv"

#read in MQ60 pileup
data = read.table(txt_file, comment.char = "", header = T)
patient = substr(unlist(strsplit(txt_file, 'PDv38is_wgs_'))[2], 0, 7)

#extract data frames of interest
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
NV_mq60 = NV
NR_mq60 = NR

#read in relevant file for MQ 0 pileup
data = read.table(paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_mq0_filtering/", txt_file), comment.char = "", header = T)

#extract data frames of interest
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
NV_mq0 = NV[intersect(row.names(NV_mq60), row.names(NV)),]
NR_mq0 = NR[intersect(row.names(NV_mq60), row.names(NV)),]

NV_mq60 = NV_mq60[row.names(NV_mq0),] #putative drivers that failed other filters aren't in mq0 file
NR_mq60 = NR_mq60[row.names(NV_mq0),]

manifest_flt = manifest[manifest$case.id == patient,]

#filter
##high MQ filter
hq_mq_vars = row.names(NR_mq60[,manifest_flt$sample])[rowSums(NR_mq60[,manifest_flt$sample]) / rowSums(NR_mq0[,manifest_flt$sample]) > 0.9]
  
write.table(hq_mq_vars, paste0(patient, "_hq_mq_vars.txt"), col.names = F, row.names = F, sep = '\t', quote = F)

```

####Annotate existing text files

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/07_indel")

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')
sub_files = list.files(".", ".standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.5bp.indel.filtered.txt")

PD50297_tier1 = read.table("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/final_subs_mq60_filtering/PD50297_hq_mq_vars.txt", header = F, sep = "\t", stringsAsFactors = F)[,1]
PD51122_tier1 = read.table("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/final_subs_mq60_filtering/PD51122_hq_mq_vars.txt", header = F, sep = "\t", stringsAsFactors = F)[,1]
PD51123_tier1 = read.table("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/final_subs_mq60_filtering/PD51123_hq_mq_vars.txt", header = F, sep = "\t", stringsAsFactors = F)[,1]

tier1_muts = list(`PD50297` = PD50297_tier1, `PD51122` = PD51122_tier1, `PD51123` = PD51123_tier1)

for(file in sub_files){
  
  data = read.table(file, header = T, sep = "\t", stringsAsFactors = F)
  data$mutID = paste(data$Chr, data$Position, data$Wildtype, data$Mutant, sep = "_")
  data$tier = 2
  patient = unique(data$Case_ID)
  data[data$mutID %in% tier1_muts[[patient]],]$tier = 1
  sample = unlist(strsplit(file, ".standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.5bp.indel.filtered.txt"))
  
  write.table(data, paste0(sample, ".standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.5bp.indel.filtered.tier.annot.txt"), col.names = T, row.names = F, sep = "\t", quote = F)
  
}

```

###Calculate locus-specific error rate

Used when examining variants across multiple samples to determine if their presence is above that of the error profile or not.

####alleleCounter

Generate bed files for allele counter

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/shearwater_framework

for patient in PD50297 PD51122 PD51123;
do

cp /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/merged_final_subs/${patient}_subs.bed ${patient}/

done

```

Create list of patient samples and reference panel samples.

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/shearwater_framework")

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20221015.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')
manifest_flt = manifest[manifest$keep == "Y",]

patients = c("PD50297", "PD51122", "PD51123")

for(patient in patients){
  
  non_patient = patients[!grepl(patient, patients)]
  
  non_patient_non_cns_normal_df = manifest_flt[manifest_flt$CNS == "N" &  
                                                manifest_flt$purity_trunk < 0.01 &
                                                manifest_flt$case.id %in% non_patient, c("sample", "canapps_proj")]
  patient_df = manifest_flt[manifest_flt$case.id %in% patient, c("sample", "canapps_proj")]
  
  
  write.table(non_patient_non_cns_normal_df, paste0(patient, "/", patient, "_reference_panel.txt"), col.names = F, row.names = F, sep = "\t", quote = F)
  write.table(patient_df, paste0(patient, "/", patient, "_samples.txt"), col.names = F, row.names = F, sep = "\t", quote = F)
  
}

```

Run allelecounter on cgpfarm.

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/shearwater_framework/

#for patient in PD51122;
for patient in PD50297 PD51122 PD51123;
do

while read line;
do
set $line
#echo $1
#echo $2

bsub -J${patient}_$1 -o ${patient}/${patient}_$1.o -e ${patient}/${patient}_$1.e -q normal -n 5 -R"select[mem>10000] rusage[mem=10000] span[hosts=1]" -M10000 "/nfs/users/nfs_m/my4/bin/alleleCounter -l ${patient}/${patient}_subs.bed -b /nfs/cancer_ref01/nst_links/live/${2}/${1}/${1}.sample.dupmarked.bam -o /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/shearwater_framework/${patient}/${1}_alleleFrequencies.txt -r /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa -m 25 -q 30"

done < ${patient}/${patient}_samples.txt

while read line;
do
set $line
#echo $1
#echo $2

bsub -J${patient}_$1 -o ${patient}/${patient}_$1.o -e ${patient}/${patient}_$1.e -q normal -n 5 -R"select[mem>10000] rusage[mem=10000] span[hosts=1]" -M10000 "/nfs/users/nfs_m/my4/bin/alleleCounter -l ${patient}/${patient}_subs.bed -b /nfs/cancer_ref01/nst_links/live/${2}/${1}/${1}.sample.dupmarked.bam -o /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/shearwater_framework/${patient}/${1}_alleleFrequencies.txt -r /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa -m 25 -q 30"

done < ${patient}/${patient}_reference_panel.txt

done

for f in $(ls -d PD*);
do
echo $f
cat $f/${f}_subs.bed | wc -l

for file in $(ls $f/*_alleleFrequencies.txt);
do
grep -v "#" $file | wc -l
done

done #none look truncated 9/11/22

```

####Run Shearwater-like algorithm

Original code missed some variants found at a universally low depth (just under 1% of calls), likely regions of low mapping quality.

Also removes variants whose average coverage across all tumour samples is less than 10.

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/shearwater_framework/")

patients = c("PD50297", "PD51122", "PD51123")

for(patient in patients){
  
  data = read.table(paste0(patient, "/", patient, "_subs.bed"), header = F, sep = "\t", stringsAsFactors = F)
  muts = paste(data$V1, data$V2, data$V3, data$V4, sep = "_")
  write.table(muts, paste0(patient, "/", patient, "_high_quality_snp_variants.txt"), col.names = F, row.names = F, quote =F, sep = "\t")
  
}

```

#####Function

```{r}

#-------------------------------------------------
# Libraries
#-------------------------------------------------

library("GenomicRanges")
library("deepSNV")
library("Rsamtools")

logbb = deepSNV:::logbb
dbetabinom = VGAM::dbetabinom

#-------------------------------------------------
# Functions
#-------------------------------------------------

estimateRho_gridml = function(x, mu) {
  # Estimate rho by MLE grid approach
  rhovec = 10^seq(-6,-0.5,by=0.05) # rho will be bounded within 1e-6 and 0.32
  mm = x[,2]
  cov = c(x[,1])
  ll = sapply(rhovec, function(rhoj) sum(dbetabinom(x=mm, size=cov, rho=rhoj, prob=mu, log=T)))
  rhovec[ll==max(ll)][1]
}

shearwater_probability=function(patient, save = NULL, path_prefix = '', rho = 10^-3, lcm = T){
  #Function to calculate probability of presence of mutation based on Shearwarer
  #'patient' is the name of the patient-specific subfolder
  #'path_prefix' is any prefix to the path necessary to find that subfolder
  #'rho' is the constant for the overdispersion parameter. If rho=NULL, calculate
  # it from the data (much slower)
  #'save' is path for output. If NULL, returns matrix
  # output of this function will be a matrix (muts by samples) of p values
  
  
  #A file of mutations in patient subdirectory (format: Chr_Ref_Pos_Alt)
  Muts_patient = read.table(paste0(path_prefix,patient,"/", patient, "_high_quality_snp_variants.txt"))[,1] 
  #A file of with the sample names belonging to this patient
  case_samples=read.table(paste0(path_prefix,patient,"/", patient, "_samples.txt"))[,1]
  normal_samples=read.table(paste0(path_prefix,patient,"/", patient, "_reference_panel.txt"))[,1]
  
  if(lcm == T) normal_panel = normal_samples[grepl("lo", normal_samples)]
  if(lcm == F) normal_panel = normal_samples[!grepl("lo", normal_samples)]
  
  norm_all_counts = all_counts[normal_panel,,]
  coords_proj = substr(Muts_patient,1,nchar(Muts_patient)-4)
  case_all_counts = all_counts[case_samples,,]
 
  avg_depth_list = c()

  for (i in coords_proj){
    mean_d = sum(case_all_counts[,i,]) / length(case_samples)
    avg_depth_list = c(avg_depth_list, mean_d)
  }
  
  Muts_patient = Muts_patient[avg_depth_list > 10] #Removes remaining globally low coverage variants which were the result of mapping issues
  coords_proj = coords_proj[avg_depth_list > 10] #40867 good depth

  #Set up pval matrix
  pval_mat = matrix(1,ncol=length(case_samples),nrow=length(Muts_patient))
  rownames(pval_mat)=Muts_patient
  colnames(pval_mat)=case_samples
  
  Alt=substr(Muts_patient,nchar(Muts_patient),nchar(Muts_patient))
  Ref=substr(Muts_patient,nchar(Muts_patient)-2,nchar(Muts_patient)-2)
  
  for (s in case_samples){
    rho_est=rep(NA,length(coords_proj))
    test_counts = all_counts[s,coords_proj,]
    for (k in 1:length(coords_proj)) {
      n = sum(test_counts[coords_proj[k],])
      x = test_counts[coords_proj[k],Alt[k]]
      
      N_indiv = rowSums(norm_all_counts[,coords_proj[k],])
      X_indiv = norm_all_counts[,coords_proj[k],c("A","C","G","T")!=Ref[k]]
      pseudo = .Machine$double.eps    
      N=sum(N_indiv)
      X=sum(X_indiv)
      
      mu = max(X,pseudo)/max(N,pseudo)
      counts = cbind(N,X)
      if(is.null(rho)) rho = estimateRho_gridml(counts,mu)
      rdisp = (1 - rho)/rho
      
      prob0 = (X + x)/(N + n); prob0[prob0==0] = pseudo; prob0[prob0==1] = 1 - pseudo
      prob1s = x/(n + pseudo); prob1s[prob1s==0] = pseudo; prob1s[prob1s==1] = 1 - pseudo
      prob1c = X/(N + pseudo); prob1c[prob1c==0] = pseudo; prob1c[prob1c==1] = 1 - pseudo
      
      prob1s = pmax(prob1s,prob1c) # Min error rate is that of the population (one-sided test)
      nu0 = prob0 * rdisp; nu1s = prob1s * rdisp; nu1c = prob1c * rdisp; 
      
      # Likelihood-Ratio Tests
      LL = logbb(x, n, nu0, rdisp) + logbb(X, N, nu0, rdisp) - logbb(x, n, nu1s, rdisp) - logbb(X, N, nu1c, rdisp)
      pvals = pchisq(-2*LL, df=1, lower.tail=F)/2 # We divide by 2 as we are performing a 1-sided test
      # Saving the result
      pval_mat[k,s] = pvals
    } 
  }
  if(is.null(save)){
    return(pval_mat)
  }else{
    write.table(pval_mat,save)
  }
}

```

#####Run

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/shearwater_framework/

export PATH=/software/R-4.1.0/bin:${PATH}

bsub -q long -o sw_filter.out -e sw_filter.err -n 4 -R 'select[mem>=80000] rusage[mem=80000] span[hosts=1]' -M80000 /software/R-4.1.0/bin/Rscript run_sw_filter_20221110.R

```

```{r}

#run_sw_filter_20221110.R

source("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/shearwater_like_filtering_subs/shearwater_like_functions.R")

setwd('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/shearwater_framework/')
#options(stringsAsFactors = F)

patients = c("PD50297", "PD51122", "PD51123")
#patients = c("PD50297", "PD51123")

for(patient in patients){
  
  # Vector of normal reference samples, taken from a separate cohort of patients
  normal_samples = read.table(paste0(patient,"/", patient, "_reference_panel.txt"))[,1]
  
  # Vector of all samples, including the reference panel and samples of interest
  case_samples=read.table(paste0(patient,"/", patient, "_samples.txt"))[,1]
  samples <- c(case_samples, normal_samples)
  
  # "Bed" file of all mutations to be considered (across all patients)
  # Format: Chr Ref Pos Alt
  muts = read.table(paste0(patient,"/", patient, "_subs.bed")) 
  coords = paste(muts$V1, muts$V2, sep="_")
  
  # Read in data from AlleleCounter
  all_counts = array(0,dim=c(length(samples), length(coords), 4),
                   dimnames = list(samples, coords, c("A","C","G","T")))
  
  print(length(samples)) 
  
  for (k in 1:length(samples)){
  #Read in allele counts per sample
  if(file.exists(paste0(patient, "/", samples[k],"_alleleFrequencies.txt"))){
    data=read.table(paste0(patient, "/", samples[k],"_alleleFrequencies.txt"),comment.char = '',header=T)
    muts_data=paste(data$X.CHR,data$POS,sep="_")
    data=data[!duplicated(muts_data),]
    muts_data=muts_data[!duplicated(muts_data)]
    rownames(data)=muts_data
    all_counts[k,,]=as.matrix(data[coords,3:6])
  }
  print(k)
}
  
 shearwater_probability(patient=patient, save=paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/shearwater_framework/", patient, "/shearwater_lcm_snv_pval_mat.txt"), lcm = T)
  
 shearwater_probability(patient=patient, save=paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/shearwater_framework/", patient, "/shearwater_bulk_snv_pval_mat.txt"), lcm = F)
 
 print(patient) 
  
}

```

#####Adjust p values

Run on farm due to size of files.

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/shearwater_framework/

export PATH=/software/R-3.6.1/bin:${PATH}
export R_HOME=$(R RHOME)
export R_LIBS_USER="~/custom_libraries/R/x86_64-pc-linux-gnu-library/3.6_dw"
bsub -q yesterday -Is -n 4 -R 'select[mem>=80000] rusage[mem=80000] span[hosts=1]' -M80000 R

```

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/shearwater_framework")

patients = c("PD50297", "PD51122", "PD51123")
#patient = "PD50297"
for(patient in patients){
  
  bulk_pval_mat = read.table(paste0(patient, "/shearwater_bulk_snv_pval_mat.txt"), header = T, sep = " ", stringsAsFactors = F)
  lcm_pval_mat = read.table(paste0(patient, "/shearwater_lcm_snv_pval_mat.txt"), header = T, sep = " ", stringsAsFactors = F)
  #bulk_qval_mat = apply(bulk_pval_mat,2,function(x) p.adjust(x,method="BH", n = length(as.matrix(bulk_pval_mat))))
  #lcm_qval_mat = apply(lcm_pval_mat,2,function(x) p.adjust(x,method="BH", n = length(as.matrix(lcm_pval_mat))))
  bulk_qval_mat = apply(bulk_pval_mat,1,function(x) p.adjust(x,method="BH")) #adjust only for number of samples for that variant, not all tests done
  lcm_qval_mat = apply(lcm_pval_mat,1,function(x) p.adjust(x,method="BH")) #adjust only for number of samples for that variant, not all tests done
  
  bulk_qval_mat = t(bulk_qval_mat)
  lcm_qval_mat = t(lcm_qval_mat)
  
  write.table(bulk_qval_mat, paste0(patient, "/shearwater_bulk_snv_qval_mat.txt"), col.names = T, sep = " ", row.names = T, quote = F)
  write.table(lcm_qval_mat, paste0(patient, "/shearwater_lcm_snv_qval_mat.txt"), col.names = T, sep = " ", row.names = T, quote = F)
  
  merged_qval_mat = lcm_qval_mat < 0.001 & bulk_qval_mat < 0.001
  merged_qval_mat2 = apply(merged_qval_mat, 2, function(x) as.integer(x))
  row.names(merged_qval_mat2) =  row.names(merged_qval_mat)
  
  write.table(merged_qval_mat2, paste0(patient, "/shearwater_combined_snv_qval_pass_mat.txt"), col.names = T, sep = " ", row.names = T, quote = F)
  
}

```

##INDELS

###Pindel

Run unmatched for all WGS samples

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/indels/01_pindel

infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($26 == "Y") { print $1, $6} }' $infile | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
cp /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.pindel.annot.vcf.gz .
done

ls *.pindel.annot.vcf.gz | wc -l #911

for file in $(ls *.pindel.annot.vcf.gz);
do
zgrep "SAMPLE=<ID=NORMAL" $file >> matched_samples.txt
done 

#wc -l matched_samples.txt #911
#grep "PDv38is_wgs" matched_samples.txt | wc -l #911, all run matched

```

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/indels/01_pindel

ls *.pindel.annot.vcf.gz | while read FILE ; do zgrep "^#" -v "$FILE" | cut -f1 | uniq -c > ../00_qc_chrom/"$FILE".counts.txt ; done 
wc -l ../00_qc_chrom/*.pindel.annot.vcf.gz.counts.txt #none truncated 1/8/22

```

###1) Homopolymer filtering

Filter original pindel files to only include those that pass pindel and are not 1bp events occurring on homopolymer runs 9bp or greater.

```{bash}

cd /nfs/users/nfs_t/to3/scripts/pindel-filtering

#standard
infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($26 == "Y") { print $1, $6} }' $infile | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
./bsub_homopolymer_filter_args.sh $PROJECT /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/indels/02_hp9 9 PASS $SAMPLE
done

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/indels/02_hp9

ls *.pindel.HP.9.vcf | wc -l #911

```

###2) Read direction filter

Remove variants with huge read direction asymmetry biases.

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/indels/02_hp9

module load bcftools

for f in $(ls *.pindel.HP.9.vcf);
do
filename=$(basename -- "$f")
sample="${filename%.pindel.HP.9.vcf}"
bcftools filter -e '(((FORMAT/PU[1]) / (FORMAT/PU[1] + FORMAT/NU[1]) < 0.15) | ((FORMAT/NU[1]) / (FORMAT/PU[1] + FORMAT/NU[1]) < 0.15)) & (FORMAT/PU[1] + FORMAT/NU[1]) > 10' $f > ${sample}.pindel.HP.9.read.direction.1.filtered.vcf
bcftools filter -i '(FORMAT/PU[1] > 0) & (FORMAT/NU[1] > 0)' ${sample}.pindel.HP.9.read.direction.1.filtered.vcf > ../03_read_direction/${sample}.pindel.HP.9.read.direction.filtered.vcf
rm ${sample}.pindel.HP.9.read.direction.1.filtered.vcf
done

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/indels/03_read_direction

ls *.pindel.HP.9.read.direction.filtered.vcf | wc -l #911

```

###Convert to text files

####Function

```{r}

#pindel_vcf_to_txt_20220814.R

library(VariantAnnotation)
library(optparse)

option_list = list(
  make_option(c("-f", "--file"), type="character", default=NULL, help="File name, ending in .pindel.HP.9.read.direction.filtered.vcf", metavar="character"))

opt_parser = OptionParser(option_list=option_list)
opt = parse_args(opt_parser)

vcf.input = opt$file

pindel_vcf_to_text_file = function(vcf_file){
  vcf = readVcf(vcf_file)
  if(nrow(vcf) > 0){
    sample = unlist(strsplit(vcf_file, '.pindel.HP.9.read.direction.filtered.vcf'))
    var.df = data.frame(Chr=as.character(seqnames(rowRanges(vcf))),
                  Position=start(ranges(rowRanges(vcf))),
                  Wildtype=as.character(ref(vcf)),
                  Mutant=as.character(unlist(CharacterList(alt(vcf)))),
                  Variant_read_depth=geno(vcf)$FC[,2],
                  Total_read_depth=geno(vcf)$FD[,2])
    var.df$VAF = var.df$Variant_read_depth / var.df$Total_read_depth
    var.df$Mutation = info(vcf)$VT
    vagrent_annots = lapply(strsplit(info(vcf)$VW, '\\|'), `length<-`, max(lengths(strsplit(info(vcf)$VW, '\\|')))) #make all elements in list the same length for subsetting purposes
    if(max(unlist(lapply(vagrent_annots, function(x) length(x)))) == 1){ #where none land in gene footprints and single NA values are found in each case
      var.df$Gene = NA
      var.df$Transcript = NA
      var.df$Codon = NA
      var.df$Protein = NA
    } else {
      var.df$Gene = sapply(vagrent_annots, '[[', 1)
      var.df$Transcript = sapply(vagrent_annots, '[[', 3)
      var.df$Codon = sapply(vagrent_annots, '[[', 4)
      var.df$Protein = sapply(vagrent_annots, '[[', 5)
    }

    conseq_list = lapply(info(vcf)$VC, function(x) if(identical(x, character(0))) NA_character_ else x)
    conseq_vec = c()
    for(i in 1:length(conseq_list)){
      conseq_vec = c(conseq_vec, paste(unlist(conseq_list[i]), collapse = ';'))
    }
  
    var.df$Consequence = conseq_vec
    var.df$Case_ID = substr(sample, 0, 7)
    var.df$Sample = sample
  
    write.table(var.df[, c("Case_ID", "Sample", "Chr", "Position", "Wildtype", "Mutant", "Total_read_depth", "Variant_read_depth", "VAF", "Mutation", "Gene",      "Transcript", "Codon", "Protein", "Consequence")], paste0(sample, '.pindel.HP.9.read.direction.filtered.txt'), col.names = T, row.names = F, quote = F, sep = '\t')
  }
}

pindel_vcf_to_text_file(vcf.input)

```

####Run

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/indels/03_read_direction

export PATH=/software/R-4.1.0/bin:${PATH}
#export R_HOME=$(R RHOME)

for file in $(ls *.pindel.HP.9.read.direction.filtered.vcf);
do
sample=${file%.pindel.HP.9.read.direction.filtered.vcf}
#echo $sample
bsub -q small -o ${sample}_txt_convert.out -e ${sample}_txt_convert.err -n 4 -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M10000 /software/R-4.1.0/bin/Rscript ~/scripts/pindel_vcf_to_txt_20220814.R -f $file
done

ls *txt | wc -l #905, no passed variants in 6 samples, see below

```

###3) 4) 5) 6) 7) 8) Binom filtering

####Symlink bam files to directory

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/cgpvaf/indels

infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($26 == "Y") { print $1, $6} }' $infile | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bas .
done

ls *bam | wc -l #911

ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bas .

```

####Generate bed files

Done per patient

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/cgpvaf/indels

for f in PD50297 PD51122 PD51123;
do

for file in $(ls /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/indels/03_read_direction/${f}*.pindel.HP.9.read.direction.filtered.vcf);
do
grep -v "#" $file | cut -f 1,2,4,5 >> ${f}_indels.bed
done

cat ${f}_indels.bed | sort -k1,1 -k2,2n -k3,4 | uniq > ${f}_indels_unique.bed
mv ${f}_indels_unique.bed ${f}_indels.bed

done

```

####Run cgpvaf

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/cgpvaf/indels

module load cgpVAFcommand

for patient in PD50297 PD51122 PD51123;
do

declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

mkdir -p ${patient}

#run per chromosome, need to change out and err files to specify chr 1/8/22
for chr in chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY;
do
bsub -q basement -o ${patient}/%J.${patient}_${chr}_indel.out -e ${patient}/%J.${patient}_${chr}_indel.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl -d ./ -o ${patient} -a indel -mq 30 -bq 25 -g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa -be .sample.dupmarked.bam -hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz -bo 1 -b ${patient}_indels.bed -nn PDv38is_wgs -tn ${sampleArray[@]} -chr $chr
done

done

#failed for chr 1, 2 and 7 for PD51122
cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/cgpvaf/indels

module load cgpVAFcommand

for patient in PD51122;
do

declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

#mkdir -p ${patient}

#run per chromosome, need to change out and err files to specify chr 1/8/22
for chr in chr1 chr2 chr7;
do
bsub -q basement -o ${patient}/%J.${patient}_${chr}_indel.out -e ${patient}/%J.${patient}_${chr}_indel.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl -d ./ -o ${patient} -a indel -mq 30 -bq 25 -g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa -be .sample.dupmarked.bam -hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz -bo 1 -b ${patient}_indels.bed -nn PDv38is_wgs -tn ${sampleArray[@]} -chr $chr
done

done


```

Check all jobs completely successfully

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/cgpvaf/indels

grep "Successfully" PD*/*chr*_indel.out | wc -l #72, all accounted for 31/8/22

```

Concatenate per chromosome output

```{bash}

module load cgpVAFcommand

#PD51122
cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/cgpvaf/indels

patient="PD51122"
tmpdir=${patient}/"tmpvaf_"${patient}"ab_lo0001"

##get list of samples from patient
declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

cd $tmpdir

##for unclear reasons the bam files need to be in the same directory as the tmp files
infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($27 == "Y") { print $1, $6} }' $infile | grep $patient | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bas .
done

ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bas .

##submit concatenate job
bsub -q long -o ../%J.${patient}_concat.out -e ../%J.${patient}_concat.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl \
-d ./ \
-o ../ \
-a indel \
-g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa \
-hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz \
-bo 1 \
-b ../../${patient}_indels.bed \
-be .sample.dupmarked.bam \
-nn PDv38is_wgs \
-tn ${sampleArray[@]} \
-ct 1

#PD51123
cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/cgpvaf/indels

patient="PD51123"
tmpdir=${patient}/"tmpvaf_"${patient}"aa3"

##get list of samples from patient
declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

cd $tmpdir

##for unclear reasons the bam files need to be in the same directory as the tmp files
infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($27 == "Y") { print $1, $6} }' $infile | grep $patient | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bas .
done

ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bas .

##submit concatenate job
bsub -q long -o ../%J.${patient}_concat.out -e ../%J.${patient}_concat.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl \
-d ./ \
-o ../ \
-a indel \
-g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa \
-hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz \
-bo 1 \
-b ../../${patient}_indels.bed \
-be .sample.dupmarked.bam \
-nn PDv38is_wgs \
-tn ${sampleArray[@]} \
-ct 1

#PD50297
cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/cgpvaf/indels

patient="PD50297"
tmpdir=${patient}/"tmpvaf_"${patient}"ab_lo0001"

##get list of samples from patient
declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

cd $tmpdir

##for unclear reasons the bam files need to be in the same directory as the tmp files
infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($27 == "Y") { print $1, $6} }' $infile | grep $patient | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bas .
done

ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bas .

##submit concatenate job
bsub -q long -o ../%J.${patient}_concat.out -e ../%J.${patient}_concat.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl \
-d ./ \
-o ../ \
-a indel \
-g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa \
-hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz \
-bo 1 \
-b ../../${patient}_indels.bed \
-be .sample.dupmarked.bam \
-nn PDv38is_wgs \
-tn ${sampleArray[@]} \
-ct 1


#
#PD51122
cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/cgpvaf/indels

patient="PD51122"
tmpdir=${patient}/"tmpvaf_"${patient}"ab_lo0001"

##get list of samples from patient
declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

cd $tmpdir

##for unclear reasons the bam files need to be in the same directory as the tmp files
infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($26 == "Y") { print $1, $6} }' $infile | grep $patient | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bas .
done

ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bas .

##submit concatenate job
bsub -q long -o ../%J.${patient}_concat.out -e ../%J.${patient}_concat.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl \
-d ./ \
-o ../ \
-a indel \
-g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa \
-hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz \
-bo 1 \
-b ../../${patient}_indels.bed \
-be .sample.dupmarked.bam \
-nn PDv38is_wgs \
-tn ${sampleArray[@]} \
-ct 1

```

####Run the binomial and beta-binomial filters

Copy over the per case pileup files
```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_filtering

cp /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/cgpvaf/indels/PD*/*_indel_vaf.tsv .

#remove header info
for f in $(ls *_indel_vaf.tsv);
do
filename=$(basename -- "$f")
filename="${filename%_indel_vaf.tsv}"
#echo $filename
grep -v "##" $f > ${filename}_indel_vaf_nohash.tsv
done

```

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_filtering

export PATH=/software/R-3.6.1/bin:${PATH}
export R_HOME=$(R RHOME)
export R_LIBS_USER="~/custom_libraries/R/x86_64-pc-linux-gnu-library/3.6_dw"

for f in $(ls *_indel_vaf_nohash.tsv);
do
bsub -q normal -o $f.out -e $f.err -n 4 -R 'select[mem>=60000] rusage[mem=60000] span[hosts=1]' -M60000 "/software/R-3.6.1/bin/Rscript ~/scripts/binom_beta_binom_paed_autopsy_wgs_mut_filter_20220923_2.R -t $f -m indel"
done

```

####Plot mutational spectra of variants that are filtered out

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_filtering")

library(MutationalPatterns)
library(GenomeInfoDb)
library("BSgenome.Hsapiens.UCSC.hg38")

patients = c("PD50297", "PD51122", "PD51123")

for(patient in patients){
  low_cov_vars = read.table(paste0(patient, "_universal_low_coverage_indel.txt"), header = F, sep = '\t', stringsAsFactors = F)[,1]
  germline_vars = read.table(paste0(patient, "_germline_indel_variants.txt"), header = F, sep = '\t', stringsAsFactors = F)[,1]
  low_quality_vars = read.table(paste0(patient, "_low_quality_indel_variants.txt"), header = F, sep = '\t', stringsAsFactors = F)[,1]
  bbinom_vars = read.table(paste0(patient, "_bbinom_filtered_indel.txt"), header = F, sep = '\t', stringsAsFactors = F)[,1]
  bbinom2_vars = read.table(paste0(patient, "_bbinom_filtered_2indel.txt"), header = F, sep = '\t', stringsAsFactors = F)[,1]
  
  indels = data.frame(matrix(unlist(strsplit(c(low_cov_vars, germline_vars, low_quality_vars, bbinom_vars, bbinom2_vars), "_")), ncol = 4, byrow = T))
  names(indels) = c("Chr", "Start", "Ref", "Alt")
  indels$id = c(rep("low_cov", length(low_cov_vars)), rep("germline", length(germline_vars)), rep("low_qual", length(low_quality_vars)), rep("bbinom", length(bbinom_vars)), rep("bbinom2", length(bbinom2_vars)))
  indels_flt = indels[nchar(indels$Ref) != nchar(indels$Alt),] #remove indels where ref and alt are the same length, 950 in PD50297
  indels_flt$End = as.numeric(indels_flt$Start) + (nchar(indels_flt$Ref) - 1)

  grange_obj = makeGRangesListFromDataFrame(indels_flt, split.field = "id", keep.extra.columns = T, ignore.strand = T, seqnames.field = "Chr",
                                                start.field = "Start", end.field = "End")
  GenomeInfoDb::genome(grange_obj) = "hg38"
  seqlengths(grange_obj) <- seqlengths(BSgenome.Hsapiens.UCSC.hg38@seqinfo)[1:25]
  indel_grl <- get_indel_context(grange_obj, "hg38")
  indel_counts <- count_indel_contexts(indel_grl)
  p = plot_indel_contexts(indel_counts, condensed = TRUE)
  pdf(paste0(patient, "_rejected_indels.pdf"), height = 10, width = 12)
  print(p)
  dev.off()
  
}

for(chr in paste0("chr", c(1:22, "X", "Y"))){
  
  print(paste0(chr, " min= ", min(unlist(start(ranges(grange_obj[seqnames(grange_obj) == chr,])))), ", max= ", max(unlist(start(ranges(grange_obj[seqnames(grange_obj) == chr,])))), ", seqlength=", as.numeric(seqlengths(grange_obj)[chr])))
  
}

```

###9) Filter on MQ fraction

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_filtering")

patients = c("PD50297", "PD51122", "PD51123")

for(patient in patients){
  
  data = read.table(paste0(patient, "_filtered_remaining_all_indel.txt"), header = F, sep = "\t", stringsAsFactors = F)[,1]
  data_df = data.frame(matrix(unlist(strsplit(data, "_")), ncol = 4 , byrow = T))
  write.table(data_df, paste0(patient, "_filtered_remaining_all_indel_df.txt"), col.names = F, row.names = F, sep = "\t", quote = F)
  
}

```


```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_output_mq0_indel_pileup

infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($27 == "Y") { print $1, $6} }' $infile | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bas .
done

ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bas .

```

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_filtering

cp *_filtered_remaining_all_indel_df.txt /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_output_mq0_indel_pileup

```

####Run cgpvaf MQ0

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_output_mq0_indel_pileup

module load cgpVAFcommand

for patient in PD50297 PD51122 PD51123;
do

declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

mkdir -p ${patient}

#run per chromosome, need to change out and err files to specify chr 1/8/22
for chr in chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY;
do
bsub -q long -o ${patient}/%J.${patient}_${chr}_snp.out -e ${patient}/%J.${patient}_${chr}_snp.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl -d ./ -o ${patient} -a indel -mq 0 -bq 25 -g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa -be .sample.dupmarked.bam -hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz -bo 1 -b ${patient}_filtered_remaining_all_indel_df.txt -nn PDv38is_wgs -tn ${sampleArray[@]} -chr $chr
done

done

```

Check all jobs completely successfully

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_output_mq0_indel_pileup

grep "Successfully" PD*/*chr*_snp.out | wc -l #72, all accounted for!

```

Concatenate per chromosome output

```{bash}

module load cgpVAFcommand

#PD50297
cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_output_mq0_indel_pileup

patient="PD50297"
tmpdir=${patient}/"tmpvaf_"${patient}"ab_lo0001"

##get list of samples from patient
declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

cd $tmpdir

##for unclear reasons the bam files need to be in the same directory as the tmp files
infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($27 == "Y") { print $1, $6} }' $infile | grep $patient | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bas .
done

ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bas .

##submit concatenate job
bsub -q long -o ../%J.${patient}_concat.out -e ../%J.${patient}_concat.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl \
-d ./ \
-o ../ \
-a indel \
-g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa \
-hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz \
-bo 1 \
-b ../../${patient}_filtered_remaining_all_indel_df.txt \
-be .sample.dupmarked.bam \
-nn PDv38is_wgs \
-tn ${sampleArray[@]} \
-ct 1

#PD51122
cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_output_mq0_indel_pileup

patient="PD51122"
tmpdir=${patient}/"tmpvaf_"${patient}"ab_lo0001"

##get list of samples from patient
declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

cd $tmpdir

##for unclear reasons the bam files need to be in the same directory as the tmp files
infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($27 == "Y") { print $1, $6} }' $infile | grep $patient | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bas .
done

ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bas .

##submit concatenate job
bsub -q long -o ../%J.${patient}_concat.out -e ../%J.${patient}_concat.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl \
-d ./ \
-o ../ \
-a indel \
-g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa \
-hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz \
-bo 1 \
-b ../../${patient}_filtered_remaining_all_indel_df.txt \
-be .sample.dupmarked.bam \
-nn PDv38is_wgs \
-tn ${sampleArray[@]} \
-ct 1

#PD51123
cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_output_mq0_indel_pileup

patient="PD51123"
tmpdir=${patient}/"tmpvaf_"${patient}"aa3"

##get list of samples from patient
declare -a sampleArray=()

for f in $(ls ${patient}*.sample.dupmarked.bam);
do
  filename=$(basename -- "$f")
  sample="${filename%.sample.dupmarked.bam}"
  #echo $sample
  sampleArray+=($sample)
done

#echo ${sampleArray[@]}

cd $tmpdir

##for unclear reasons the bam files need to be in the same directory as the tmp files
infile="/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt"
awk -F "\t" '{ if($27 == "Y") { print $1, $6} }' $infile | grep $patient | while read -r SAMPLE PROJECT;
do
#echo $SAMPLE
#echo $PROJECT
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/$PROJECT/$SAMPLE/$SAMPLE.sample.dupmarked.bam.bas .
done

ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bai .
ln -sf /nfs/cancer_ref01/nst_links/live/2480/PDv38is_wgs/PDv38is_wgs.sample.dupmarked.bam.bas .

##submit concatenate job
bsub -q long -o ../%J.${patient}_concat.out -e ../%J.${patient}_concat.err -n 4 -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 perl /software/CASM/modules/installs/vafcorrect/shim-bin/cgpVaf.pl \
-d ./ \
-o ../ \
-a indel \
-g /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa \
-hdr /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/shared/HiDepth_mrg1000_no_exon_coreChrs_v3.bed.gz \
-bo 1 \
-b ../../${patient}_filtered_remaining_all_indel_df.txt \
-be .sample.dupmarked.bam \
-nn PDv38is_wgs \
-tn ${sampleArray[@]} \
-ct 1

```

####Run filtering

Run R code below in interactive job until hierarchical plotting step

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_mq0_filtering

export PATH=/software/R-3.6.1/bin:${PATH}
export R_HOME=$(R RHOME)
export R_LIBS_USER="~/custom_libraries/R/x86_64-pc-linux-gnu-library/3.6_dw"
bsub -q yesterday -Is -n 4 -R 'select[mem>=80000] rusage[mem=80000] span[hosts=1]' -M80000 R

```


```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_mq0_filtering")

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')
manifest = manifest[manifest$keep == "Y", ]

#PD50297
txt_file = "PDv38is_wgs_PD50297ab_lo0001_indel_vaf_nohash.tsv"

#read in relevant file for MQ 0 pileup
data = read.table(txt_file, comment.char = "", header = T)
patient = substr(unlist(strsplit(txt_file, 'PDv38is_wgs_'))[2], 0, 7)

#extract data frames of interest
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
NV_mq0 = NV
NR_mq0 = NR
  
#read in relevant file for MQ 30 pileup
data = read.table(paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/binom_filtering/", txt_file), comment.char = "", header = T)

#extract data frames of interest
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
NV_mq30 = NV[row.names(NV_mq0),]
NR_mq30 = NR[row.names(NR_mq0),]

manifest_flt = manifest[manifest$case.id == patient,]

#filter
##high MQ filter
hq_mq_vars = row.names(NR_mq30[,manifest_flt$sample])[rowSums(NR_mq30[,manifest_flt$sample]) / rowSums(NR_mq0[,manifest_flt$sample]) > 0.9]
  
write.table(hq_mq_vars, paste0(patient, "_hq_mq_indels.txt"), col.names = F, row.names = F, sep = '\t', quote = F)

#PD51122
txt_file = "PDv38is_wgs_PD51122ab_lo0001_indel_vaf_nohash.tsv"

#read in relevant file for MQ 0 pileup
data = read.table(txt_file, comment.char = "", header = T)
patient = substr(unlist(strsplit(txt_file, 'PDv38is_wgs_'))[2], 0, 7)

#extract data frames of interest
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
NV_mq0 = NV
NR_mq0 = NR
  
#read in relevant file for MQ 30 pileup
data = read.table(paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/binom_filtering/", txt_file), comment.char = "", header = T)

#extract data frames of interest
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
NV_mq30 = NV[row.names(NV_mq0),]
NR_mq30 = NR[row.names(NR_mq0),]

manifest_flt = manifest[manifest$case.id == patient,]

#filter
##high MQ filter
hq_mq_vars = row.names(NR_mq30[,manifest_flt$sample])[rowSums(NR_mq30[,manifest_flt$sample]) / rowSums(NR_mq0[,manifest_flt$sample]) > 0.9]

write.table(hq_mq_vars, paste0(patient, "_hq_mq_indels.txt"), col.names = F, row.names = F, sep = '\t', quote = F)
  
#PD51123
txt_file = "PDv38is_wgs_PD51123aa3_indel_vaf_nohash.tsv"

#read in relevant file for MQ 0 pileup
data = read.table(txt_file, comment.char = "", header = T)
patient = substr(unlist(strsplit(txt_file, 'PDv38is_wgs_'))[2], 0, 7)

#extract data frames of interest
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
NV_mq0 = NV
NR_mq0 = NR
  
#read in relevant file for MQ 30 pileup
data = read.table(paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/binom_filtering/", txt_file), comment.char = "", header = T)

#extract data frames of interest
Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
rownames(Genotype)=rownames(NV)=rownames(NR)=Muts
  
NV_mq30 = NV[row.names(NV_mq0),]
NR_mq30 = NR[row.names(NR_mq0),]

manifest_flt = manifest[manifest$case.id == patient,]

#filter
##high MQ filter
hq_mq_vars = row.names(NR_mq30[,manifest_flt$sample])[rowSums(NR_mq30[,manifest_flt$sample]) / rowSums(NR_mq0[,manifest_flt$sample]) > 0.9]
  
write.table(hq_mq_vars, paste0(patient, "_hq_mq_indels.txt"), col.names = F, row.names = F, sep = '\t', quote = F)

```

###Merge final calls from all lists

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/merged_final_indels")

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')
manifest = manifest[manifest$keep == "Y", ]

mq30_files = list.files("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_filtering", "_indel_vaf_nohash.tsv$", full.names = T)
mq_flt_files = list.files("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/binom_mq0_filtering", "_hq_mq_indels.txt", full.names = T) #added 24/9/22

patients = c("PD50297", "PD51122", "PD51123")

salvaged_poss_drivers = list(PD50297 = c("chr1_198744070_TC_T",
                                        "chr12_132626134_CT_C",
                                        "chr16_3728437_GTTGCTGCTGCTGC_G",
                                        "chr17_31221913_ACATTTTGGGAGATT_A",
                                        "chr19_10830205_GC_G",
                                        "chr3_142497130_TCACCTGGAGAATGC_T",
                                        "chr5_112838883_GA_G",
                                        "chr8_112517086_GCAGGTTATTCTTT_G"),
                             PD51122 = c("chr17_31226459_A_AC", 
                                         "chr2_47803500_AC_A"),
                             PD51123 = c()) #variants that are plausible drivers pre-binomial filtering steps

for(patient in patients){
  
  print(patient)
  
  original_vars = read.table(mq_flt_files[grepl(patient, mq_flt_files)], header = F, sep = "\t", stringsAsFactors = F)[,1]
  driver_vars = salvaged_poss_drivers[[patient]]
  
  all_vars = unique(sort(c(original_vars, driver_vars)))
  
  txt_file = mq30_files[grepl(patient, mq30_files)]
  
  data = read.table(txt_file, comment.char = "", header = T)

  #extract data frames of interest
  Muts = paste(data$Chrom,data$Pos,data$Ref,data$Alt,sep="_")
  Genotype = data[,grepl("VAF",colnames(data))&colnames(data)!="PDv38is_wgs_VAF"]
  NR = data[,grepl("DEP",colnames(data))&colnames(data)!="PDv38is_wgs_DEP"]
  NV = data[,grepl("MTR",colnames(data))&colnames(data)!="PDv38is_wgs_MTR"]
  amb = data[,grepl("AMB",colnames(data))&colnames(data)!="PDv38is_wgs_AMB"]
  unk = data[,grepl("UNK",colnames(data))&colnames(data)!="PDv38is_wgs_UNK"]
  colnames(amb)=colnames(unk)=colnames(Genotype)=colnames(Genotype)=colnames(NR)=colnames(NV)=gsub("_VAF","",colnames(Genotype))
  rownames(amb)=rownames(unk)=rownames(Genotype)=rownames(Genotype)=rownames(NV)=rownames(NR)=Muts

  NV_flt = NV[all_vars, ]
  NR_flt = NR[all_vars, ]
  amb_flt = amb[all_vars, ]
  unk_flt = unk[all_vars, ]
  
  NR_flt_nonzero = NR_flt
  NR_flt_nonzero[NR_flt_nonzero == 0] = 1
  
  VAF_flt = NV_flt / NR_flt_nonzero
  
  write.table(NV_flt, paste0(patient, "_NV_final_merged_indels.txt"), col.names = T, row.names = T, sep = "\t", quote = F)
  write.table(NR_flt, paste0(patient, "_NR_final_merged_indels.txt"), col.names = T, row.names = T, sep = "\t", quote = F)
  write.table(VAF_flt, paste0(patient, "_VAF_final_merged_indels.txt"), col.names = T, row.names = T, sep = "\t", quote = F)
  write.table(row.names(VAF_flt), paste0(patient, "_final_merged_indels_list.txt"), col.names = F, row.names = F, sep = "\t", quote = F)
  
}

```

###Intersect with VCF files

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/indels/02_hp9 #rescue those that fail direction filter in one sample but not others

export PATH=/software/R-4.1.0/bin:${PATH}
#export R_HOME=$(R RHOME)

for file in $(ls *.pindel.HP.9.vcf);
do
sample=${file%.pindel.HP.9.vcf}
#echo $sample
bsub -q small -o ../04_bbinom/${sample}_filter.out -e ../04_bbinom/${sample}_filter.err -n 4 -R 'select[mem>=20000] rusage[mem=20000] span[hosts=1]' -M20000 /software/R-4.1.0/bin/Rscript ~/scripts/filter_annotated_pindel_vcfs_20220923.R -f $file
done

ls *vcf | wc -l #911, all accounted for

```

```{r}

#filter_annotated_pindel_vcfs_20220923.R

library(VariantAnnotation)
library(optparse)

option_list = list(
  make_option(c("-f", "--file"), type="character", default=NULL, help="File name, ending in .pindel.HP.9.vcf", metavar="character"))

opt_parser = OptionParser(option_list=option_list)
opt = parse_args(opt_parser)

vcf = opt$file

sample = strsplit(vcf, '\\.')[[1]][1]
patient = substr(sample, 0, 7)

filtered_muts = read.table(paste0('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data_mk2/merged_final_indels/', patient, '_final_merged_indels_list.txt'), header = F, sep = '\t', stringsAsFactors = F)[,1]

data = VariantAnnotation::readVcf(vcf)
chr=as.character(seqnames(rowRanges(data)))
pos=start(ranges(rowRanges(data)))
ref=as.character(ref(data))
alt=as.character(unlist(CharacterList(alt(data))))
    
info(data)$mut_ID = paste(chr, pos, ref, alt, sep = '_')
info(header(data)) = rbind(info(header(data)), DataFrame(Number = '.', Type = 'String', Description = 'Unique mutation ID', row.names = 'mut_ID'))
filtered_data = data[info(data)$mut_ID %in% filtered_muts]
    
writeVcf(filtered_data, filename = paste0("../04_bbinom/", sample, '.pindel.HP.9.read.direction.germline.beta.binom.unk.amb.min.depth.filtered.vcf'))

```

###Convert to text files

####Function

```{r}

#indel_vcf_to_txt_file_20220907.R

library(VariantAnnotation)
library(optparse)

option_list = list(
  make_option(c("-f", "--file"), type="character", default=NULL, help="File name, ending in .pindel.HP.9.read.direction.germline.beta.binom.unk.amb.min.depth.filtered.vcf", metavar="character"))

opt_parser = OptionParser(option_list=option_list)
opt = parse_args(opt_parser)

vcf = opt$file

pindel_vcf_to_text_file = function(vcf_file){
  vcf = readVcf(vcf_file)
  if(nrow(vcf) > 0){
    sample = unlist(strsplit(vcf_file, '.pindel.HP.9.read.direction.germline.beta.binom.unk.amb.min.depth.filtered.vcf'))
    var.df = data.frame(Chr=as.character(seqnames(rowRanges(vcf))),
                  Position=start(ranges(rowRanges(vcf))),
                  Wildtype=as.character(ref(vcf)),
                  Mutant=as.character(unlist(CharacterList(alt(vcf)))),
                  Variant_read_depth=geno(vcf)$FC[,2],
                  Total_read_depth=geno(vcf)$FD[,2])
    var.df$VAF = var.df$Variant_read_depth / var.df$Total_read_depth
    var.df$Mutation = info(vcf)$VT
    vagrent_annots = lapply(strsplit(info(vcf)$VW, '\\|'), `length<-`, max(lengths(strsplit(info(vcf)$VW, '\\|')))) #make all elements in list the same length for subsetting purposes
    if(max(unlist(lapply(vagrent_annots, function(x) length(x)))) == 1){ #where none land in gene footprints and single NA values are found in each case
      var.df$Gene = NA
      var.df$Transcript = NA
      var.df$Codon = NA
      var.df$Protein = NA
    } else {
      var.df$Gene = sapply(vagrent_annots, '[[', 1)
      var.df$Transcript = sapply(vagrent_annots, '[[', 3)
      var.df$Codon = sapply(vagrent_annots, '[[', 4)
      var.df$Protein = sapply(vagrent_annots, '[[', 5)
    }

    conseq_list = lapply(info(vcf)$VC, function(x) if(identical(x, character(0))) NA_character_ else x)
    conseq_vec = c()
    for(i in 1:length(conseq_list)){
      conseq_vec = c(conseq_vec, paste(unlist(conseq_list[i]), collapse = ';'))
    }
  
    var.df$Consequence = conseq_vec
    var.df$Case_ID = substr(sample, 0, 7)
    var.df$Sample = sample
  
    write.table(var.df[, c("Case_ID", "Sample", "Chr", "Position", "Wildtype", "Mutant", "Total_read_depth", "Variant_read_depth", "VAF", "Mutation", "Gene",      "Transcript", "Codon", "Protein", "Consequence")], paste0(sample, '.pindel.HP.9.read.direction.germline.beta.binom.unk.amb.min.depth.filtered.txt'), col.names = T, row.names = F, quote = F, sep = '\t')
  }
}

pindel_vcf_to_text_file(vcf)

```

####Run

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/indels/04_bbinom

export PATH=/software/R-4.1.0/bin:${PATH}
#export R_HOME=$(R RHOME)

for file in $(ls *.pindel.HP.9.read.direction.germline.beta.binom.unk.amb.min.depth.filtered.vcf);
do
sample=${file%.pindel.HP.9.read.direction.germline.beta.binom.unk.amb.min.depth.filtered.vcf}
#echo $sample
bsub -q small -o ${sample}_txt_convert.out -e ${sample}_txt_convert.err -n 4 -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M10000 /software/R-4.1.0/bin/Rscript ~/scripts/indel_vcf_to_txt_file_20220907.R -f $file
done

ls *txt | wc -l #351, no passed variants in most samples

```

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/indels/04_bbinom")

vcf_files = list.files(".", ".pindel.HP.9.read.direction.germline.beta.binom.unk.amb.min.depth.filtered.vcf")
txt_files = list.files(".", ".pindel.HP.9.read.direction.germline.beta.binom.unk.amb.min.depth.filtered.txt")

vcf_samples = unlist(strsplit(vcf_files, ".pindel.HP.9.read.direction.germline.beta.binom.unk.amb.min.depth.filtered.vcf"))
txt_samples = unlist(strsplit(txt_files, ".pindel.HP.9.read.direction.germline.beta.binom.unk.amb.min.depth.filtered.txt"))

vcf_samples[!vcf_samples %in% txt_samples]

```

##COPY NUMBER ABERRATIONS

###ascatPCA

Original run with segmentation value of 100 results in bad fits for most of the PD51122 tumour samples and there were some false subclonal WGD calls in the PD50297 and PD51123 samples. All were refit with purity from truncal estimate and ploidy of either 3.1 (PD51122) or 2 (PD50297, PD51123). The final purity by ascatPCA still differs from our truncal purity estimates.

####CNAqc

#####Gamma 100

######Original purity scores

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/ascatPCA/seg_100

export PATH=/software/R-4.1.0/bin:${PATH}

for file in $(ls sort_ascat_*);
do
suffix="sort_ascat_"
sample=${file#"$suffix"}
echo $sample
bsub -q small -o ${sample}_peak_qc.out -e ${sample}_peak_qc.err -n 4 -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M10000 /software/R-4.1.0/bin/Rscript ~/scripts/CNAqc_check_seg100_20221019.R -s $sample
done

```

```{r}

#CNAqc_check_seg100_20221019.R

library(CNAqc)
require(dplyr)
library(optparse)

option_list = list(
  make_option(c("-s", "--sample"), type="character", default=NULL, help="Sample name", metavar="character"))

opt_parser = OptionParser(option_list=option_list)
opt = parse_args(opt_parser)

sample = opt$sample
#sample = "PD51122ai_lo0001"

set.seed(42)
input = list()

subs = read.table(paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/07_indel/", sample, ".standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.5bp.indel.filtered.txt"), header = T, sep = "\t", stringsAsFactors = F)
subs$Position2 = as.numeric(subs$Position) - 1
subs_reorder = subs[, c("Chr", "Position2", "Position", "Wildtype", "Mutant", "Total_read_depth", "Variant_read_depth", "VAF")]
names(subs_reorder) = c("chr", "from", "to", "ref", "alt", "DP", "NV", "VAF")

cnas = read.table(paste0("sort_ascat_", sample), header = F, sep = "\t", stringsAsFactors = F)

cnas$major = cnas$V4 - cnas$V5
cnas_reorder = cnas[, c("V1", "V2", "V3", "major", "V5")]
names(cnas_reorder) = c("chr", "from", "to", "Major", "minor")

ascat_stats = read.table("ascatPCA_100_stats.txt", header = T, sep = "\t", stringsAsFactors = F)
purity = ascat_stats[ascat_stats$sample == sample,]$purity

input[["mutations"]] = subs_reorder
input[["cna"]] = cnas_reorder
input[["purity"]] = purity

x = init(
  mutations = input$mutations, 
  cna = input$cna,
  purity = input$purity,
  ref = 'hg38'
  )

#genomewide QC
x = analyze_peaks(x)
print(x)
p1 = plot_peaks_analysis(x, what = "simple")
p2 = plot_peaks_analysis(x, what = "complex")

pdf(paste0(sample, "_peak_simple_segment_analysis.pdf"), width = 10, height = 4)
print(p1)
dev.off()

pdf(paste0(sample, "_peak_complex_segment_analysis.pdf"), width = 10, height = 4)
print(p2)
dev.off()

saveRDS(x, paste0(sample, "_CNAqc_genomewide_peak_detection.rds"))

#x$peaks_analysis$QC

```

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/ascatPCA/seg_100/original_purity")

cnaqc.files = list.files(".", "_CNAqc_genomewide_peak_detection.rds")

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20221015.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')
metadata = manifest[manifest$keep == "Y",]
ascat_metadata = read.table("../ascatPCA_100_stats.txt", header = T, sep = "\t", stringsAsFactors = F)

metadata$CNAqc_check = NA
metadata$CNAqc_purity_adjustment_score = NA
metadata$ascatPCA_gof = NA
metadata$ascatPCA_ploidy = NA
metadata$ascatPCA_purity = NA

for(file in cnaqc.files){
  
  sample = unlist(strsplit(file, "_CNAqc_genomewide_peak_detection.rds"))
  
  if(sample %in% metadata$sample){
    
    x = readRDS(file)
  
    if(!is.null(x$peaks_analysis$QC)) metadata[metadata$sample == sample,]$CNAqc_check = x$peaks_analysis$QC
    if(!is.null(x$peaks_analysis$score)){
    
      metadata[metadata$sample == sample,]$CNAqc_purity_adjustment_score = x$peaks_analysis$score
      metadata[metadata$sample == sample,]$ascatPCA_gof = ascat_metadata[ascat_metadata$sample == sample,]$goodness_of_fitness
      metadata[metadata$sample == sample,]$ascatPCA_ploidy = ascat_metadata[ascat_metadata$sample == sample,]$ploidy
      metadata[metadata$sample == sample,]$ascatPCA_purity = ascat_metadata[ascat_metadata$sample == sample,]$purity
    
    } 
    
  }
  
}

library(ggplot2)

ggplot(metadata[metadata$purity_trunk >= 0.4,]) +
  geom_boxplot(mapping = aes(x = CNAqc_check, ascatPCA_gof))

table(metadata[metadata$purity_trunk >= 0.4,]$CNAqc_check, metadata[metadata$purity_trunk >= 0.4,]$case.id)
#       PD50297 PD51122 PD51123
#FAIL       5      59       5
#PASS      47      29      33

#which samples fail CNAqc but have high gof?
metadata[metadata$purity_trunk >= 0.4 & metadata$CNAqc_check == "FAIL" & metadata$case.id != "PD51122",]

ggplot(metadata[metadata$purity_trunk >= 0.4 & metadata$case.id != "PD51122",]) +
  geom_boxplot(mapping = aes(x = CNAqc_check, ascatPCA_gof))

#would the tumour samples here also benefit from my calculated purity?

```

######Adjusted purity scores

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/ascatPCA/seg_100

export PATH=/software/R-4.1.0/bin:${PATH}

for file in $(ls sort_ascat_*);
do
suffix="sort_ascat_"
sample=${file#"$suffix"}
echo $sample
bsub -q small -o ${sample}_peak_qc.out -e ${sample}_peak_qc.err -n 4 -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M10000 /software/R-4.1.0/bin/Rscript ~/scripts/CNAqc_check_seg100_20221019_2.R -s $sample
done

```

```{r}

#CNAqc_check_seg100_20221019_2.R

library(CNAqc)
require(dplyr)
library(optparse)

option_list = list(
  make_option(c("-s", "--sample"), type="character", default=NULL, help="Sample name", metavar="character"))

opt_parser = OptionParser(option_list=option_list)
opt = parse_args(opt_parser)

sample = opt$sample
#sample = "PD51122ai"

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20221015.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')
ascat_stats = read.table("ascatPCA_100_stats.txt", header = T, sep = "\t", stringsAsFactors = F)

#replace purity for tumour cuts with the one I calculated
for(i in 1:nrow(ascat_stats)){
  
  if(manifest[manifest$sample == ascat_stats$sample[i], ]$purity_trunk >= 0.4 & !is.na(manifest[manifest$sample == ascat_stats$sample[i], ]$purity_trunk)){
    ascat_stats$purity[i] = manifest[manifest$sample == ascat_stats$sample[i], ]$purity_trunk
  }
  
}

set.seed(42)
input = list()

subs = read.table(paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/07_indel/", sample, ".standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.5bp.indel.filtered.txt"), header = T, sep = "\t", stringsAsFactors = F)
subs$Position2 = as.numeric(subs$Position) - 1
subs_reorder = subs[, c("Chr", "Position2", "Position", "Wildtype", "Mutant", "Total_read_depth", "Variant_read_depth", "VAF")]
names(subs_reorder) = c("chr", "from", "to", "ref", "alt", "DP", "NV", "VAF")

cnas = read.table(paste0("sort_ascat_", sample), header = F, sep = "\t", stringsAsFactors = F)

cnas$major = cnas$V4 - cnas$V5
cnas_reorder = cnas[, c("V1", "V2", "V3", "major", "V5")]
names(cnas_reorder) = c("chr", "from", "to", "Major", "minor")

purity = ascat_stats[ascat_stats$sample == sample,]$purity

input[["mutations"]] = subs_reorder
input[["cna"]] = cnas_reorder
input[["purity"]] = purity

x = init(
  mutations = input$mutations, 
  cna = input$cna,
  purity = input$purity,
  ref = 'hg38'
  )

#genomewide QC
x = analyze_peaks(x)
print(x)
p1 = plot_peaks_analysis(x, what = "simple")
p2 = plot_peaks_analysis(x, what = "complex")

pdf(paste0(sample, "_peak_simple_segment_analysis.pdf"), width = 10, height = 4)
print(p1)
dev.off()

pdf(paste0(sample, "_peak_complex_segment_analysis.pdf"), width = 10, height = 4)
print(p2)
dev.off()

saveRDS(x, paste0(sample, "_CNAqc_genomewide_peak_detection.rds"))

#x$peaks_analysis$QC

```

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/ascatPCA/seg_100/adjusted_purity")

cnaqc.files = list.files(".", "_CNAqc_genomewide_peak_detection.rds")

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20221015.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')
metadata = manifest[manifest$keep == "Y",]
ascat_metadata = read.table("../ascatPCA_100_stats.txt", header = T, sep = "\t", stringsAsFactors = F)

metadata$CNAqc_check = NA
metadata$CNAqc_purity_adjustment_score = NA
metadata$ascatPCA_gof = NA
metadata$ascatPCA_ploidy = NA
metadata$ascatPCA_purity = NA

for(file in cnaqc.files){
  
  sample = unlist(strsplit(file, "_CNAqc_genomewide_peak_detection.rds"))
  
  if(sample %in% metadata$sample){
    
    x = readRDS(file)
  
    if(!is.null(x$peaks_analysis$QC)) metadata[metadata$sample == sample,]$CNAqc_check = x$peaks_analysis$QC
    if(!is.null(x$peaks_analysis$score)){
    
      metadata[metadata$sample == sample,]$CNAqc_purity_adjustment_score = x$peaks_analysis$score
      metadata[metadata$sample == sample,]$ascatPCA_gof = ascat_metadata[ascat_metadata$sample == sample,]$goodness_of_fitness
      metadata[metadata$sample == sample,]$ascatPCA_ploidy = ascat_metadata[ascat_metadata$sample == sample,]$ploidy
      metadata[metadata$sample == sample,]$ascatPCA_purity = ascat_metadata[ascat_metadata$sample == sample,]$purity
    
    } 
    
  }
  
}

library(ggplot2)

ggplot(metadata[metadata$purity_trunk >= 0.4,]) +
  geom_boxplot(mapping = aes(x = CNAqc_check, ascatPCA_gof))

table(metadata[metadata$purity_trunk >= 0.4,]$CNAqc_check, metadata[metadata$purity_trunk >= 0.4,]$case.id)
#     PD50297 PD51122 PD51123
#FAIL       4      16       7
#PASS      48      72      31

#looks like the refits at gamma 100 have worked too.
#which samples failed for PD51122?
metadata[metadata$purity_trunk >= 0.4 & metadata$CNAqc_check == "FAIL" & metadata$case.id == "PD51122",] #essentially the same as last time

ggplot(metadata[metadata$purity_trunk >= 0.4 & metadata$case.id != "PD51122",]) +
  geom_boxplot(mapping = aes(x = CNAqc_check, ascatPCA_gof))

```

######Create list of all ascatPCA calls

Re-run 19/12/22 with single.strand.genes.only=FALSE, just to check some of the more obscure drivers haven't been missed

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/ascatPCA/seg_100/

export PATH=/software/R-4.1.0/bin:${PATH}

bsub -q normal -o annot_cnas_20221022.out -e annot_cnas_20221022.err -n 4 -R 'select[mem>=80000] rusage[mem=80000] span[hosts=1]' -M80000 /software/R-4.1.0/bin/Rscript ~/scripts/annot_cnas_20221022.R

bsub -q normal -o annot_cnas_20221219.out -e annot_cnas_20221219.err -n 4 -R 'select[mem>=80000] rusage[mem=80000] span[hosts=1]' -M80000 /software/R-4.1.0/bin/Rscript ~/scripts/annot_cnas_20221219.R

```

```{r}

#annot_cnas_20221219.R

library(GenomicRanges)
library(TxDb.Hsapiens.UCSC.hg38.knownGene)
library(org.Hs.eg.db)

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/ascatPCA/seg_100/")

cosmic_v94 <- read.table('/lustre/scratch119/casm/team294rr/to3/testes/tumour/manuscript/nature_resub/reference_datasets/cosmic_v94_cancer_gene_census.csv', sep = ',', header = T, stringsAsFactors = F)
hgg_genes = c("H3-3A", "H3.3A", "H3F3A", "HIST1H3B", "HIST1H3C", "HIST2H3C", "TP53", "ATRX", "PDGFRA", "ACVR1", "PIK3CA", "CDKN2A", "CDKN2B", "NF1", "KIT", "KDR", "PIK3R1", "MYCN", "PPM1D", "EGFR", "PTEN", "BCOR", "TOP3A", "BRAF", "MET", "FGFR1", "ID2", "ATM", "CDK4", "SETD2", "CCND2", "MYC", "RB1", "TERT", "ASXL1", "CDK6", "KDM6B", "NTRK1", "NTRK2", "NTRK3") #mackay et al. 2017
prc2_genes = c("EZH1", "EZH2", "EED", "SUZ12", "RBBP7", "RBBP4")

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20221015.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')

#annotate with genes found along them
org.Hs.egSYMBOL.df = as.data.frame(org.Hs.egSYMBOL)

#check synonyms present in dataframe
cosmic_v94$Gene.Symbol[!cosmic_v94$Gene.Symbol %in% org.Hs.egSYMBOL.df$symbol] #"CARS"     "FGFR1OP"  "H3F3A"    "H3F3B"    "HIST1H3B" "HIST1H4I" "SEPT5"    "SEPT6"    "SEPT9"
"CARS1" %in% org.Hs.egSYMBOL.df$symbol #T
"CEP43" %in% org.Hs.egSYMBOL.df$symbol #T
"H3-3A" %in% org.Hs.egSYMBOL.df$symbol #T
"H3-3B" %in% org.Hs.egSYMBOL.df$symbol #T
"SEPTIN5" %in% org.Hs.egSYMBOL.df$symbol #T
"SEPTIN6" %in% org.Hs.egSYMBOL.df$symbol #T
"SEPTIN9" %in% org.Hs.egSYMBOL.df$symbol #T

#will look for remaining histones separately, many aliases
cancer_genes <- c(unique(unlist(strsplit(cosmic_v94$Synonyms, ","))), "CARS1", "CEP43", "H3-3A", "H3-3B", "SEPTIN5", "SEPTIN6", "SEPTIN9")

hgg_genes[!hgg_genes %in% org.Hs.egSYMBOL.df$symbol] #"H3.3A"    "H3F3A"    "HIST1H3B" "HIST1H3C" "HIST2H3C"

#will look for remaining histones separately, many aliases

prc2_genes[!prc2_genes %in% org.Hs.egSYMBOL.df$symbol] #nil

#get list of histone genes from database
genes = org.Hs.egSYMBOL.df$symbol
hist_genes = genes[grepl("^H1-", genes) | grepl("^H2", genes) | grepl("^H3", genes) | grepl("^H4", genes) | grepl("^H5", genes) | grepl("^HIST", genes)]

#now annotate
cna_df = data.frame()
for(i in 1:nrow(manifest)){
  
  if(manifest$keep[i] == "Y" &
     !manifest$sample[i] %in% c("PD50297b", "PD51122q", "PD51123aa3") &
     (((manifest$CNAqc_check[i] == "PASS" | manifest$ascatPCA_gof[i] >= 95) & manifest$purity_trunk[i] >= 0.4 & manifest$average.reads.per.chromosome.copy.tumour[i] >= 5) |
     ((manifest$ascatPCA_gof[i] >= 95 & manifest$purity_trunk[i] < 0.4)))){
    
    data = read.table(paste0("sort_ascat_", manifest$sample[i]), header = F, sep = "\t", stringsAsFactors = F)
    data$sample = manifest$sample[i]
    data$est_ploidy = manifest$ascatPCA_ploidy[i]
    data$cosmic_genes = NA
    data$histone_genes = NA
    data$hgg_genes = NA
    data$prc2_genes = NA
    
    for(j in 1:nrow(data)){
      
      coords.gr <- makeGRangesFromDataFrame(data[j, 1:3], start.field = "V2", end.field = "V3", seqnames.field = "V1")
      coords.gr.gene.annot <- subsetByOverlaps(genes(TxDb.Hsapiens.UCSC.hg38.knownGene, single.strand.genes.only=FALSE), coords.gr)
      if(length(org.Hs.egSYMBOL.df[org.Hs.egSYMBOL.df$gene_id %in% as.numeric(coords.gr.gene.annot$gene_id),]$symbol) > 0){
    
        genes = org.Hs.egSYMBOL.df[org.Hs.egSYMBOL.df$gene_id %in% as.numeric(coords.gr.gene.annot$gene_id),]$symbol
        if(length(genes[genes %in% cancer_genes]) > 0) data$cosmic_genes[j] = paste0(genes[genes %in% cancer_genes], collapse = ",")
        if(length(genes[genes %in% hgg_genes]) > 0) data$hgg_genes[j] = paste0(genes[genes %in% hgg_genes], collapse = ",")
        if(length(genes[genes %in% prc2_genes]) > 0) data$prc2_genes[j] = paste0(genes[genes %in% prc2_genes], collapse = ",")
        if(length(genes[genes %in% hist_genes]) > 0) data$histone_genes[j] = paste0(genes[genes %in% hist_genes], collapse = ",")
    
      }
      
    }
    
    cna_df = rbind(cna_df, data)
    
  }
  
}

write.table(cna_df, "ascatPCA_all_segments_20221219.txt", col.names = T, row.names = F, sep = "\t", quote = F)

hq_tumour_samples = manifest[manifest$keep == "Y" & manifest$purity_trunk >= 0.4 & manifest$average.reads.per.chromosome.copy.tumour >= 5 & (manifest$CNAqc_check == "PASS" | manifest$ascatPCA_gof >= 95), ]$sample 

cna_df[cna_df$sample %in% hq_tumour_samples & cna_df$V1 == "chr17" & as.numeric(cna_df$V2) < 8000000 & cna_df$V5 > 0,] #LOH across TP53
cna_df[cna_df$sample %in% hq_tumour_samples & cna_df$V1 == "chr17" & as.numeric(cna_df$V3) > 30000000 & cna_df$V5 > 0 & grepl("PD51122",cna_df$sample),] #NF1 LOH in all tumour regions from PD51122

```

```{r}

#annot_cnas_20221022.R

library(GenomicRanges)
library(TxDb.Hsapiens.UCSC.hg38.knownGene)
library(org.Hs.eg.db)

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/ascatPCA/seg_100/")

cosmic_v94 <- read.table('/lustre/scratch119/casm/team294rr/to3/testes/tumour/manuscript/nature_resub/reference_datasets/cosmic_v94_cancer_gene_census.csv', sep = ',', header = T, stringsAsFactors = F)
hgg_genes = c("H3-3A", "H3.3A", "H3F3A", "HIST1H3B", "HIST1H3C", "HIST2H3C", "TP53", "ATRX", "PDGFRA", "ACVR1", "PIK3CA", "CDKN2A", "CDKN2B", "NF1", "KIT", "KDR", "PIK3R1", "MYCN", "PPM1D", "EGFR", "PTEN", "BCOR", "TOP3A", "BRAF", "MET", "FGFR1", "ID2", "ATM", "CDK4", "SETD2", "CCND2", "MYC", "RB1", "TERT", "ASXL1", "CDK6", "KDM6B", "NTRK1", "NTRK2", "NTRK3") #mackay et al. 2017
prc2_genes = c("EZH1", "EZH2", "EED", "SUZ12", "RBBP7", "RBBP4")

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20221015.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')

#annotate with genes found along them
org.Hs.egSYMBOL.df = as.data.frame(org.Hs.egSYMBOL)

#check synonyms present in dataframe
cosmic_v94$Gene.Symbol[!cosmic_v94$Gene.Symbol %in% org.Hs.egSYMBOL.df$symbol] #"CARS"     "FGFR1OP"  "H3F3A"    "H3F3B"    "HIST1H3B" "HIST1H4I" "SEPT5"    "SEPT6"    "SEPT9"
"CARS1" %in% org.Hs.egSYMBOL.df$symbol #T
"CEP43" %in% org.Hs.egSYMBOL.df$symbol #T
"H3-3A" %in% org.Hs.egSYMBOL.df$symbol #T
"H3-3B" %in% org.Hs.egSYMBOL.df$symbol #T
"SEPTIN5" %in% org.Hs.egSYMBOL.df$symbol #T
"SEPTIN6" %in% org.Hs.egSYMBOL.df$symbol #T
"SEPTIN9" %in% org.Hs.egSYMBOL.df$symbol #T

#will look for remaining histones separately, many aliases
cancer_genes <- c(unique(unlist(strsplit(cosmic_v94$Synonyms, ","))), "CARS1", "CEP43", "H3-3A", "H3-3B", "SEPTIN5", "SEPTIN6", "SEPTIN9")

hgg_genes[!hgg_genes %in% org.Hs.egSYMBOL.df$symbol] #"H3.3A"    "H3F3A"    "HIST1H3B" "HIST1H3C" "HIST2H3C"

#will look for remaining histones separately, many aliases

prc2_genes[!prc2_genes %in% org.Hs.egSYMBOL.df$symbol] #nil

#get list of histone genes from database
genes = org.Hs.egSYMBOL.df$symbol
hist_genes = genes[grepl("^H1-", genes) | grepl("^H2", genes) | grepl("^H3", genes) | grepl("^H4", genes) | grepl("^H5", genes) | grepl("^HIST", genes)]

#now annotate
cna_df = data.frame()
for(i in 1:nrow(manifest)){
  
  if(manifest$keep[i] == "Y" &
     !manifest$sample[i] %in% c("PD50297b", "PD51122q", "PD51123aa3") &
     (((manifest$CNAqc_check[i] == "PASS" | manifest$ascatPCA_gof[i] >= 95) & manifest$purity_trunk[i] >= 0.4 & manifest$average.reads.per.chromosome.copy.tumour[i] >= 5) |
     ((manifest$ascatPCA_gof[i] >= 95 & manifest$purity_trunk[i] < 0.4)))){
    
    data = read.table(paste0("sort_ascat_", manifest$sample[i]), header = F, sep = "\t", stringsAsFactors = F)
    data$sample = manifest$sample[i]
    data$est_ploidy = manifest$ascatPCA_ploidy[i]
    data$cosmic_genes = NA
    data$histone_genes = NA
    data$hgg_genes = NA
    data$prc2_genes = NA
    
    for(j in 1:nrow(data)){
      
      coords.gr <- makeGRangesFromDataFrame(data[j, 1:3], start.field = "V2", end.field = "V3", seqnames.field = "V1")
      coords.gr.gene.annot <- subsetByOverlaps(genes(TxDb.Hsapiens.UCSC.hg38.knownGene), coords.gr)
      if(length(org.Hs.egSYMBOL.df[org.Hs.egSYMBOL.df$gene_id %in% as.numeric(coords.gr.gene.annot$gene_id),]$symbol) > 0){
    
        genes = org.Hs.egSYMBOL.df[org.Hs.egSYMBOL.df$gene_id %in% as.numeric(coords.gr.gene.annot$gene_id),]$symbol
        if(length(genes[genes %in% cancer_genes]) > 0) data$cosmic_genes[j] = paste0(genes[genes %in% cancer_genes], collapse = ",")
        if(length(genes[genes %in% hgg_genes]) > 0) data$hgg_genes[j] = paste0(genes[genes %in% hgg_genes], collapse = ",")
        if(length(genes[genes %in% prc2_genes]) > 0) data$prc2_genes[j] = paste0(genes[genes %in% prc2_genes], collapse = ",")
        if(length(genes[genes %in% hist_genes]) > 0) data$histone_genes[j] = paste0(genes[genes %in% hist_genes], collapse = ",")
    
      }
      
    }
    
    cna_df = rbind(cna_df, data)
    
  }
  
}

write.table(cna_df, "ascatPCA_all_segments_20221022.txt", col.names = T, row.names = F, sep = "\t", quote = F)

```

#####Plot copy number profiles
In all cases

```{r}

library(CNAqc)

plot_cn_profile <- function(directory){
  rds_objs = list.files(directory, "_CNAqc_genomewide_peak_detection.rds")
  
  for(obj in rds_objs){
    
    sample = unlist(strsplit(obj, "_CNAqc_genomewide_peak_detection.rds"))
    x = readRDS(obj)
    
    p <- plot_segments(x) + ggtitle(sample)
    
    pdf(paste0(sample, "_ascatPCA_copy_number_plot.pdf"), width = 10, height = 4)
    print(p)
    dev.off()
    
  }
  
}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/ascatPCA/seg_75/adjusted_purity")
plot_cn_profile(".")

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/ascatPCA/seg_100/adjusted_purity")
plot_cn_profile(".")

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/ascatPCA/seg_100/original_purity")
plot_cn_profile(".")

```

#####Add ascatPCA stats to manifest

Take those from the segmentation 100 run.

```{r}

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20221015.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')

manifest$ascatPCA_gof = NA
manifest$ascatPCA_ploidy = NA
manifest$ascatPCA_purity = NA
manifest$CNAqc_check = NA
manifest$CNAqc_purity_adjustment_score = NA
manifest$average.reads.per.chromosome.copy.tumour = NA

ascat_metadata = read.table("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/ascatPCA/seg_100/ascatPCA_100_stats.txt", header = T, sep = "\t", stringsAsFactors = F)

for(i in 1:nrow(manifest)){
  
  if(manifest$keep[i] == "Y" & !manifest$sample[i] %in% c("PD50297b", "PD51122q", "PD51123aa3")){
    
    manifest$ascatPCA_gof[i] = ascat_metadata[ascat_metadata$sample == manifest$sample[i],]$goodness_of_fitness
    manifest$ascatPCA_purity[i] = ascat_metadata[ascat_metadata$sample == manifest$sample[i],]$purity
    manifest$ascatPCA_ploidy[i] = ascat_metadata[ascat_metadata$sample == manifest$sample[i],]$ploidy
  
    if(manifest$case.id[i] == "PD51122" & manifest$purity_trunk[i] >= 0.4){
      
      x = readRDS(paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/ascatPCA/seg_100/adjusted_purity/", manifest$sample[i], "_CNAqc_genomewide_peak_detection.rds"))
      if(!is.null(x$peaks_analysis$QC)) manifest$CNAqc_check[i] = x$peaks_analysis$QC
      if(!is.null(x$peaks_analysis$score)) manifest$CNAqc_purity_adjustment_score[i] = x$peaks_analysis$score
      
    } else {
      
      x = readRDS(paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/ascatPCA/seg_100/original_purity/", manifest$sample[i], "_CNAqc_genomewide_peak_detection.rds"))
      if(!is.null(x$peaks_analysis$QC)) manifest$CNAqc_check[i] = x$peaks_analysis$QC
      if(!is.null(x$peaks_analysis$score)) manifest$CNAqc_purity_adjustment_score[i] = x$peaks_analysis$score
      
    }
    
  manifest$average.reads.per.chromosome.copy.tumour[i] = manifest$purity_trunk[i] / (manifest$purity_trunk[i] * manifest$ascatPCA_ploidy[i] + (1 - manifest$purity_trunk[i]) * 2) * manifest$picard_median_coverage[i] 
  
  }
  
}

#check it worked
table(manifest[manifest$purity_trunk >= 0.4,]$CNAqc_check, manifest[manifest$purity_trunk >= 0.4,]$case.id) #yup

write.table(manifest, '/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20221015.txt', sep = '\t', quote = F, col.names = T, row.names = F)

```


#####EDF12 - Plot ascatPCA investigation

```{r}

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20221015.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')
pd51122_tumour = manifest[manifest$keep == "Y" & manifest$case.id == "PD51122" & manifest$purity_trunk >= 0.4,]

pd51122_tumour$original_CNAqc_check = NA
pd51122_tumour$adjusted_CNAqc_check = NA

ascat_metadata = read.table("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/ascatPCA/seg_100/ascatPCA_100_stats.txt", header = T, sep = "\t", stringsAsFactors = F)

for(i in 1:nrow(pd51122_tumour)){
  
  x = readRDS(paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/ascatPCA/seg_100/adjusted_purity/", pd51122_tumour$sample[i], "_CNAqc_genomewide_peak_detection.rds"))
  if(!is.null(x$peaks_analysis$QC)) pd51122_tumour$adjusted_CNAqc_check[i] = x$peaks_analysis$QC
  
  x = readRDS(paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/ascatPCA/seg_100/original_purity/", pd51122_tumour$sample[i], "_CNAqc_genomewide_peak_detection.rds"))
  if(!is.null(x$peaks_analysis$QC)) pd51122_tumour$original_CNAqc_check[i] = x$peaks_analysis$QC
  
}

table(pd51122_tumour$original_CNAqc_check)
#FAIL PASS 
# 59   29 
table(pd51122_tumour$adjusted_CNAqc_check)
#FAIL PASS 
# 16   72 

table(pd51122_tumour$CNAqc_check)

table(manifest[manifest$keep == "Y" & manifest$purity_trunk >= 0.4,]$CNAqc_check, manifest[manifest$keep == "Y" & manifest$purity_trunk >= 0.4,]$case.id)

library(ggplot2)

pdf("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/03_DNA_analyses/draft_figures/ascatPCA_bespoke_method_purity_20221215.pdf", height = 5, width = 6, useDingbats = F)
ggplot(manifest[manifest$keep == "Y" & manifest$purity_trunk >= 0.4,]) +
  geom_point(mapping = aes(x = ascatPCA_purity, y = purity_trunk, col = case.id)) +
  theme_bw() +
  scale_color_manual(values = c("dodgerblue", "grey20", "#F9B233")) +
  ylab("Purity (curated truncal substitution VAF method)") +
  xlab("Purity (ascatPCA)")
dev.off()

```

###Battenberg

Bulk tumour samples only

####DPClust (single sample)

Single sample run, autosomal genome only to assess fit of subs and copy number calls. CN calling on X and CCF calculations not reliable, hence why excluded when assessing quality of calls.

#####Collect input files

Copy over SNV VCF and copy number files.

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/single_sample_dpclust/01_Input

cp /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/battenberg/bulk/tumour/* .

for file in $(ls *.battenberg.subclones.txt);
do
sample=${file%.battenberg.subclones.txt}
#echo $sample
cp /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/07_indel/${sample}.standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.5bp.indel.filtered.vcf .
done

```

Create separate directories per sample.

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/single_sample_dpclust/01_Input

for f in $(ls *.battenberg.subclones.txt);
do
sample=${f%.battenberg.subclones.txt}
#echo $sample
mkdir -p $sample
mv $sample*.* $sample
done 

```

Create input files for allelecount
```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/single_sample_dpclust/01_Input

for f in $(ls -d PD*);
do
cut -f 1,2,4,5 $f/*.standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.5bp.indel.filtered.vcf | sort -k1,1 -k2,2n -k3,4 | uniq > $f/${f}_loci.txt
grep -v '#' $f/${f}_loci.txt > $f/${f}_loci_SNVs_nohash.txt
mv $f/${f}_loci_SNVs_nohash.txt $f/${f}_loci.txt
done

#remove sex chromosome mutations - unreliable copy number calling for cluster identification purposes
for f in $(ls -d PD*);
do
grep -v 'X\|Y' $f/${f}_loci.txt > $f/${f}_loci_noX.txt
mv $f/${f}_loci_noX.txt $f/${f}_loci.txt
done

```

Create a txt file containing a list of the locations of the BAM files. 

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/single_sample_dpclust/01_Input

ls -d PD* > samples.txt
#ls -d PD50297* > PD50297_samples.txt

```


```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/single_sample_dpclust/01_Input")

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')
row.names(manifest) = manifest$sample

patient_file = read.table("samples.txt", header = F, sep = "\t", stringsAsFactors = F)
#patient_file = read.table("PD50297_samples.txt", header = F, sep = "\t", stringsAsFactors = F)
patient_file$Sex = manifest[patient_file$V1,]$sex
patient_file$Sex = ifelse(patient_file$Sex == "Female", "female", "male")
patient_file$project = 2571

write.table(patient_file[, c(1,3,2)], "samples.txt", col.names = F, row.names = F, sep = '\t', quote = F)
#write.table(patient_file[, c(1,3,2)], "PD50297_samples.txt", col.names = F, row.names = F, sep = '\t', quote = F)

```

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/single_sample_dpclust/01_Input

while read line;
do
set $line
echo $1
echo $2
for f in $(ls $1/*.standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.5bp.indel.filtered.vcf);
do
#echo $f
filename=$(basename -- "$f")
SAMPLE="${filename%.standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.5bp.indel.filtered.vcf}"
echo "/nfs/cancer_ref01/nst_links/live/${2}/${SAMPLE}/${SAMPLE}.sample.dupmarked.bam" >> $1/${1}_bam_list.txt
done
done < samples.txt

```

Run allelecounter on cgpfarm.

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/single_sample_dpclust/01_Input

while read line;
do
set $line
#echo $1 sample ID
#echo $2 project
#echo $3 sex

bsub -J$1 -o $1/$1.o -e $1/$1.e -q normal -n 5 -R"select[mem>10000] rusage[mem=10000] span[hosts=1]" -M10000 "/nfs/users/nfs_m/my4/bin/alleleCounter -l ${1}/${1}_loci.txt -b /nfs/cancer_ref01/nst_links/live/${2}/${1}/${1}.sample.dupmarked.bam -o /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/single_sample_dpclust/01_Input/${1}/${1}_alleleFrequencies.txt -r /lustre/scratch119/casm/team78pipelines/reference/human/GRCh38_full_analysis_set_plus_decoy_hla/genome.fa -m 25 -q 30"

done < samples.txt

for f in $(ls -d PD*);
do
echo $f
cat $f/${f}_loci.txt | wc -l
grep -v "#" $f/${f}_alleleFrequencies.txt | wc -l
done #none look truncated

```

Convert chromosomes back to hg19 style labels

```{r}

setwd('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/single_sample_dpclust/01_Input')

INPUT_PATH = "/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/single_sample_dpclust/01_Input"

data = read.table(paste0(INPUT_PATH, '/samples.txt'), header = F, sep = '\t')
#data = read.table(paste0(INPUT_PATH, '/PD50297_samples.txt'), header = F, sep = '\t')
names(data) = c('Patient', 'ProjectID', 'Sex')

for( k in 1:nrow(data) ){
  samples = unlist(strsplit(list.files(path = paste0(data$Patient[k]), pattern = '.battenberg.cellularity_ploidy.txt'), '.battenberg.cellularity_ploidy.txt'))
  
  #loci file
    loci_file = read.table(paste0(INPUT_PATH, '/', data$Patient[k], '/', data$Patient[k], '_loci.txt'), header = F, sep = '\t', stringsAsFactors = F)
    if(sum(grepl("chr", loci_file$V1)) != 0){
      loci_file$V1 = unlist(strsplit(loci_file$V1, 'chr'))[c(F, T)]
      write.table(loci_file, paste0(INPUT_PATH, '/', data$Patient[k], '/', data$Patient[k], '_loci.txt'), col.names = F, row.names = F, sep = '\t', quote = F)
    }
    
    #allele frequencies
    allele_frequencies_file = read.table(paste0(INPUT_PATH, '/', data$Patient[k], '/', data$Patient[k], '_alleleFrequencies.txt'), header = T, sep = '\t', stringsAsFactors = F, comment.char = '', check.names = F)
    if(sum(grepl("chr", allele_frequencies_file$`#CHR`)) != 0){
    allele_frequencies_file$`#CHR` = unlist(strsplit(allele_frequencies_file$`#CHR`, 'chr'))[c(F, T)]
    write.table(allele_frequencies_file, paste0(INPUT_PATH, '/', data$Patient[k], '/', data$Patient[k], '_alleleFrequencies.txt'), col.names = T, row.names = F, sep = '\t', quote = F)
    }
    
    #subclone files
    subclone_file = read.table(paste0(INPUT_PATH, '/', data$Patient[k], '/', data$Patient[k], '.battenberg.subclones.txt'), header = T, sep = '\t', stringsAsFactors = F, comment.char = '', check.names = F)
    if(sum(grepl("chr", subclone_file$chr)) != 0){
    subclone_file$chr = unlist(strsplit(subclone_file$chr, 'chr'))[c(F, T)]
    write.table(subclone_file, paste0(INPUT_PATH, '/', data$Patient[k], '/', data$Patient[k], '.battenberg.subclones.txt'), col.names = T, row.names = F, sep = '\t', quote = F)
    }
}
    
```

Final step to generate the _allDirichletProcessInfo.txt files.

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/single_sample_dpclust/01_Input

export PATH=/software/R-3.6.1/bin:${PATH}
export R_HOME=$(R RHOME)
export R_LIBS_USER="~/custom_libraries/R/x86_64-pc-linux-gnu-library/3.6_dw"

/software/R-3.6.1/bin/Rscript /nfs/users/nfs_t/to3/scripts/allDirichletProcessInfo_generator_20220817.R /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/single_sample_dpclust/01_Input

```

```{r}

#allDirichletProcessInfo_generator_20220817.R

library(dpclust3p)
library(optparse)

args <- commandArgs(TRUE)
options(stringsAsFactors = F)

INPUT_PATH <- args[1] #parent directory

data = read.table(paste0(INPUT_PATH, '/samples.txt'), header = F, sep = '\t')
names(data) = c('Patient', 'ProjectID', 'Sex')

for( k in 1:nrow(data) ){
  samples = unlist(strsplit(list.files(path = paste0(data$Patient[k]), pattern = '.battenberg.cellularity_ploidy.txt'), '.battenberg.cellularity_ploidy.txt'))
  for(i in 1:length(samples)){
    runGetDirichletProcessInfo(loci_file = paste0(INPUT_PATH, '/', data$Patient[k], '/', data$Patient[k], '_loci.txt'),
                               allele_frequencies_file = paste0(INPUT_PATH, '/', data$Patient[k], '/', samples[i], '_alleleFrequencies.txt'),
                               cellularity_file = paste0(INPUT_PATH, '/', data$Patient[k], '/', samples[i], '.battenberg.rho_and_psi.txt'),
                               subclone_file = paste0(INPUT_PATH, '/', data$Patient[k], '/', samples[i], '.battenberg.subclones.txt'),
                               gender = data$Sex[k],
                               SNP.phase.file="NA",
                               mut.phase.file="NA",
                               output_file = paste0(INPUT_PATH, '/', data$Patient[k], '/', samples[i], '_allDirichletProcessInfo.txt'))
  }
}

```

```{bash}

#dirichlet input file not truncated
cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/single_sample_dpclust/01_Input

for f in $(ls -d PD*/ | sed 's#/##');
do
echo $f
cat $f/${f}_loci.txt | wc -l
grep -v "#" $f/${f}_alleleFrequencies.txt | wc -l
grep -v "chr" $f/${f}_allDirichletProcessInfo.txt | wc -l
done

```

- Create a master project file to put into the pipeline for each sample.

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/single_sample_dpclust/01_Input

export PATH=/software/R-3.6.1/bin:${PATH}
export R_HOME=$(R RHOME)
export R_LIBS_USER="~/custom_libraries/R/x86_64-pc-linux-gnu-library/3.6_dw"

/software/R-3.6.1/bin/Rscript /nfs/users/nfs_t/to3/scripts/createProjectFile_generator_20220817.R /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/single_sample_dpclust/01_Input

```

```{r}

#/nfs/users/nfs_t/to3/scripts/createProjectFile_generator_20220817.R

library(dpclust3p)
library(optparse)

args <- commandArgs(TRUE)
options(stringsAsFactors = F)

INPUT_PATH <- args[1] #parent directory

data = read.table(paste0(INPUT_PATH, '/samples.txt'), header = F, sep = '\t')
names(data) = c('Patient', 'ProjectID', 'Sex')

for( k in 1:nrow(data) ){
  samples = unlist(strsplit(list.files(path = paste0(data$Patient[k]), pattern = '.battenberg.cellularity_ploidy.txt'), '.battenberg.cellularity_ploidy.txt'))
  createProjectFile(outputfile = paste0(data$Patient[k], '_ProjectFile.txt'),
                    donornames = rep(data$Patient[k], length(samples)),
                    samplenames = substr(samples, 8,9),
                    rho_and_psi_files = paste0(data$Patient[k], '/', samples, '.battenberg.rho_and_psi.txt'),
                    sex = rep(data$Sex[k],  length(samples)),
                    datafiles = paste0(data$Patient[k], '/', samples, '_allDirichletProcessInfo.txt'))
}

```

#####Run single-sample DPClust

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/single_sample_dpclust/01_Input

export PATH=/software/R-3.6.1/bin:${PATH}
export R_HOME=$(R RHOME)
export R_LIBS_USER="~/custom_libraries/R/x86_64-pc-linux-gnu-library/3.6_dw"
INPUT_DIR='/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/single_sample_dpclust/01_Input'
OUTPUT_DIR='/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/single_sample_dpclust/02_Output'
MEM=30000
QUEUE=normal
n_its=3000
burnin=1000
CORES=10

for f in $(ls -d PD*/ | sed 's#/##');
do
#echo $f
bsub -G team294-vwork -J${f} -q ${QUEUE} -M${MEM} -R"select[mem>${MEM}] rusage[mem=${MEM}] span[hosts=1]" -n ${CORES} -e %I.stderr -o %I.stdout \
"xvfb-run -a Rscript --no-save --no-restore --verbose /nfs/users/nfs_t/to3/custom_libraries/R/x86_64-pc-linux-gnu-library/3.6_dw/DPClust/example/dpclust_pipeline.R -r 1 -d ${INPUT_DIR} -o $OUTPUT_DIR -i ${INPUT_DIR}/${f}_ProjectFile.txt -k -a nd_dp --iterations $n_its --burnin $burnin --mut_assignment_type 1 --min_muts_cluster -1 --min_frac_muts_cluster 0.01 --num_muts_sample 50000 --seed 42 > ${OUTPUT_DIR}/${f}_outputFile2.Rout 2>&1"
done #no absolute minimum cluster size

```

#####Review

2 are very low purity (<20%) - rather than refit, copy number calls from these samples will simply not be included
PD50297am - single supraclonal mutation cluster
PD51123t - single subclonal mutation cluster

####Add calls to metadata

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/battenberg/bulk/tumour")

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')
bb_files = list.files(".", ".battenberg.cellularity_ploidy.txt")

manifest$battenberg_purity = NA
manifest$battenberg_ploidy = NA

for(file in bb_files){
  data = read.table(file, header = T, sep = "\t", stringsAsFactors = F)
  sample = unlist(strsplit(file, ".battenberg.cellularity_ploidy.txt"))
  
  manifest[manifest$sample == sample,]$battenberg_purity = data$cellularity
  manifest[manifest$sample == sample,]$battenberg_ploidy = data$ploidy
  
}

write.table(manifest, '/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20220717.txt', sep = '\t', quote = F, col.names = T, row.names = F)

```

####Create list of all Battenberg calls

Only for those bulk tumour with a tumour purity >=40%

Re-run 19/12/22 with single.strand.genes.only=FALSE, just to check some of the more obscure drivers haven't been missed

```{bash}

cd /lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/battenberg/bulk/tumour/

export PATH=/software/R-4.1.0/bin:${PATH}

bsub -q normal -o annot_cnas_20221021.out -e annot_cnas_20221021.err -n 4 -R 'select[mem>=80000] rusage[mem=80000] span[hosts=1]' -M80000 /software/R-4.1.0/bin/Rscript ~/scripts/annot_cnas_20221021.R

bsub -q normal -o annot_bb_cnas_20221219.out -e annot_bb_cnas_20221219.err -n 4 -R 'select[mem>=80000] rusage[mem=80000] span[hosts=1]' -M80000 /software/R-4.1.0/bin/Rscript ~/scripts/annot_bb_cnas_20221219.R

```

```{r}

#annot_bb_cnas_20221219.R

library(GenomicRanges)
library(TxDb.Hsapiens.UCSC.hg38.knownGene)
library(org.Hs.eg.db)

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/battenberg/bulk/tumour/")

cosmic_v94 <- read.table('/lustre/scratch119/casm/team294rr/to3/testes/tumour/manuscript/nature_resub/reference_datasets/cosmic_v94_cancer_gene_census.csv', sep = ',', header = T, stringsAsFactors = F)
hgg_genes = c("H3-3A", "H3.3A", "H3F3A", "HIST1H3B", "HIST1H3C", "HIST2H3C", "TP53", "ATRX", "PDGFRA", "ACVR1", "PIK3CA", "CDKN2A", "CDKN2B", "NF1", "KIT", "KDR", "PIK3R1", "MYCN", "PPM1D", "EGFR", "PTEN", "BCOR", "TOP3A", "BRAF", "MET", "FGFR1", "ID2", "ATM", "CDK4", "SETD2", "CCND2", "MYC", "RB1", "TERT", "ASXL1", "CDK6", "KDM6B", "NTRK1", "NTRK2", "NTRK3") #mackay et al. 2017
prc2_genes = c("EZH1", "EZH2", "EED", "SUZ12", "RBBP7", "RBBP4")

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20221015.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')
bulk_tumour = manifest[manifest$keep == "Y" & !is.na(manifest$battenberg_purity) & manifest$battenberg_purity >= 0.4,]
row.names(bulk_tumour) = bulk_tumour$sample
samples = bulk_tumour$sample

all_cn = data.frame()
for(sample in samples){
  input = read.table(paste0(sample, ".battenberg.subclones.txt"), header = T, sep = '\t', stringsAsFactors = F)
  input$sample = sample
  all_cn = rbind(all_cn, input)
}

#annotate with genes found along them
org.Hs.egSYMBOL.df = as.data.frame(org.Hs.egSYMBOL)

#check synonyms present in dataframe
cosmic_v94$Gene.Symbol[!cosmic_v94$Gene.Symbol %in% org.Hs.egSYMBOL.df$symbol] #"CARS"     "FGFR1OP"  "H3F3A"    "H3F3B"    "HIST1H3B" "HIST1H4I" "SEPT5"    "SEPT6"    "SEPT9"
"CARS1" %in% org.Hs.egSYMBOL.df$symbol #T
"CEP43" %in% org.Hs.egSYMBOL.df$symbol #T
"H3-3A" %in% org.Hs.egSYMBOL.df$symbol #T
"H3-3B" %in% org.Hs.egSYMBOL.df$symbol #T
"SEPTIN5" %in% org.Hs.egSYMBOL.df$symbol #T
"SEPTIN6" %in% org.Hs.egSYMBOL.df$symbol #T
"SEPTIN9" %in% org.Hs.egSYMBOL.df$symbol #T

#will look for remaining histones separately, many aliases
cancer_genes <- c(unique(unlist(strsplit(cosmic_v94$Synonyms, ","))), "CARS1", "CEP43", "H3-3A", "H3-3B", "SEPTIN5", "SEPTIN6", "SEPTIN9")

hgg_genes[!hgg_genes %in% org.Hs.egSYMBOL.df$symbol] #"H3.3A"    "H3F3A"    "HIST1H3B" "HIST1H3C" "HIST2H3C"

#will look for remaining histones separately, many aliases

prc2_genes[!prc2_genes %in% org.Hs.egSYMBOL.df$symbol] #nil

#get list of histone genes from database
genes = org.Hs.egSYMBOL.df$symbol
hist_genes = genes[grepl("^H1-", genes) | grepl("^H2", genes) | grepl("^H3", genes) | grepl("^H4", genes) | grepl("^H5", genes) | grepl("^HIST", genes)]

#now annotate
all_cn$cosmic_genes = NA
all_cn$histone_genes = NA
all_cn$hgg_genes = NA
all_cn$prc2_genes = NA

for(i in 1:nrow(all_cn)){
  
  coords.gr <- makeGRangesFromDataFrame(all_cn[i, 1:3], start.field = "startpos", end.field = "endpos")
  coords.gr.gene.annot <- subsetByOverlaps(genes(TxDb.Hsapiens.UCSC.hg38.knownGene, single.strand.genes.only=FALSE), coords.gr)
  if(length(org.Hs.egSYMBOL.df[org.Hs.egSYMBOL.df$gene_id %in% as.numeric(coords.gr.gene.annot$gene_id),]$symbol) > 0){
    
    genes = org.Hs.egSYMBOL.df[org.Hs.egSYMBOL.df$gene_id %in% as.numeric(coords.gr.gene.annot$gene_id),]$symbol
    if(length(genes[genes %in% cancer_genes]) > 0) all_cn$cosmic_genes[i] = paste0(genes[genes %in% cancer_genes], collapse = ",")
    if(length(genes[genes %in% hgg_genes]) > 0) all_cn$hgg_genes[i] = paste0(genes[genes %in% hgg_genes], collapse = ",")
    if(length(genes[genes %in% prc2_genes]) > 0) all_cn$prc2_genes[i] = paste0(genes[genes %in% prc2_genes], collapse = ",")
    if(length(genes[genes %in% hist_genes]) > 0) all_cn$histone_genes[i] = paste0(genes[genes %in% hist_genes], collapse = ",")
    
  }

}

write.table(all_cn, "battenberg_all_segments_20221219.txt", col.names = T, row.names = F, sep = "\t", quote = F)

```

```{r}

#annot_cnas_20221021.R

library(GenomicRanges)
library(TxDb.Hsapiens.UCSC.hg38.knownGene)
library(org.Hs.eg.db)

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/battenberg/bulk/tumour/")

cosmic_v94 <- read.table('/lustre/scratch119/casm/team294rr/to3/testes/tumour/manuscript/nature_resub/reference_datasets/cosmic_v94_cancer_gene_census.csv', sep = ',', header = T, stringsAsFactors = F)
hgg_genes = c("H3-3A", "H3.3A", "H3F3A", "HIST1H3B", "HIST1H3C", "HIST2H3C", "TP53", "ATRX", "PDGFRA", "ACVR1", "PIK3CA", "CDKN2A", "CDKN2B", "NF1", "KIT", "KDR", "PIK3R1", "MYCN", "PPM1D", "EGFR", "PTEN", "BCOR", "TOP3A", "BRAF", "MET", "FGFR1", "ID2", "ATM", "CDK4", "SETD2", "CCND2", "MYC", "RB1", "TERT", "ASXL1", "CDK6", "KDM6B", "NTRK1", "NTRK2", "NTRK3") #mackay et al. 2017
prc2_genes = c("EZH1", "EZH2", "EED", "SUZ12", "RBBP7", "RBBP4")

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20221015.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')
bulk_tumour = manifest[manifest$keep == "Y" & !is.na(manifest$battenberg_purity) & manifest$battenberg_purity >= 0.4,]
row.names(bulk_tumour) = bulk_tumour$sample
samples = bulk_tumour$sample

all_cn = data.frame()
for(sample in samples){
  input = read.table(paste0(sample, ".battenberg.subclones.txt"), header = T, sep = '\t', stringsAsFactors = F)
  input$sample = sample
  all_cn = rbind(all_cn, input)
}

#annotate with genes found along them
org.Hs.egSYMBOL.df = as.data.frame(org.Hs.egSYMBOL)

#check synonyms present in dataframe
cosmic_v94$Gene.Symbol[!cosmic_v94$Gene.Symbol %in% org.Hs.egSYMBOL.df$symbol] #"CARS"     "FGFR1OP"  "H3F3A"    "H3F3B"    "HIST1H3B" "HIST1H4I" "SEPT5"    "SEPT6"    "SEPT9"
"CARS1" %in% org.Hs.egSYMBOL.df$symbol #T
"CEP43" %in% org.Hs.egSYMBOL.df$symbol #T
"H3-3A" %in% org.Hs.egSYMBOL.df$symbol #T
"H3-3B" %in% org.Hs.egSYMBOL.df$symbol #T
"SEPTIN5" %in% org.Hs.egSYMBOL.df$symbol #T
"SEPTIN6" %in% org.Hs.egSYMBOL.df$symbol #T
"SEPTIN9" %in% org.Hs.egSYMBOL.df$symbol #T

#will look for remaining histones separately, many aliases
cancer_genes <- c(unique(unlist(strsplit(cosmic_v94$Synonyms, ","))), "CARS1", "CEP43", "H3-3A", "H3-3B", "SEPTIN5", "SEPTIN6", "SEPTIN9")

hgg_genes[!hgg_genes %in% org.Hs.egSYMBOL.df$symbol] #"H3.3A"    "H3F3A"    "HIST1H3B" "HIST1H3C" "HIST2H3C"

#will look for remaining histones separately, many aliases

prc2_genes[!prc2_genes %in% org.Hs.egSYMBOL.df$symbol] #nil

#get list of histone genes from database
genes = org.Hs.egSYMBOL.df$symbol
hist_genes = genes[grepl("^H1-", genes) | grepl("^H2", genes) | grepl("^H3", genes) | grepl("^H4", genes) | grepl("^H5", genes) | grepl("^HIST", genes)]

#now annotate
all_cn$cosmic_genes = NA
all_cn$histone_genes = NA
all_cn$hgg_genes = NA
all_cn$prc2_genes = NA

for(i in 1:nrow(all_cn)){
  
  coords.gr <- makeGRangesFromDataFrame(all_cn[i, 1:3], start.field = "startpos", end.field = "endpos")
  coords.gr.gene.annot <- subsetByOverlaps(genes(TxDb.Hsapiens.UCSC.hg38.knownGene), coords.gr)
  if(length(org.Hs.egSYMBOL.df[org.Hs.egSYMBOL.df$gene_id %in% as.numeric(coords.gr.gene.annot$gene_id),]$symbol) > 0){
    
    genes = org.Hs.egSYMBOL.df[org.Hs.egSYMBOL.df$gene_id %in% as.numeric(coords.gr.gene.annot$gene_id),]$symbol
    if(length(genes[genes %in% cancer_genes]) > 0) all_cn$cosmic_genes[i] = paste0(genes[genes %in% cancer_genes], collapse = ",")
    if(length(genes[genes %in% hgg_genes]) > 0) all_cn$hgg_genes[i] = paste0(genes[genes %in% hgg_genes], collapse = ",")
    if(length(genes[genes %in% prc2_genes]) > 0) all_cn$prc2_genes[i] = paste0(genes[genes %in% prc2_genes], collapse = ",")
    if(length(genes[genes %in% hist_genes]) > 0) all_cn$histone_genes[i] = paste0(genes[genes %in% hist_genes], collapse = ",")
    
  }

}

write.table(all_cn, "battenberg_all_segments_20221021.txt", col.names = T, row.names = F, sep = "\t", quote = F)

```

###Plot CN plots of bulk tumour samples

The poor fit of PD51122 I suspect comes down to miscalling of certain segments

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/cn_comparison")

library(CNAqc)

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20221015.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')

bulk_tumour_samples = manifest[!is.na(manifest$battenberg_purity) & manifest$battenberg_purity >= 0.4, ]$sample

for(sample in bulk_tumour_samples){
  
  if(file.exists(paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/ascatPCA/seg_100/sort_ascat_", sample))){
    
    #get subs
  subs = read.table(paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/subs/07_indel/", sample, ".standard.gnomAD.AF.0.001.PON.read.direction.low_cov.bq.mq.binom.bbinom.5bp.indel.filtered.txt"), header = T, sep = "\t", stringsAsFactors = F)
  subs$Position2 = as.numeric(subs$Position) + nchar(subs$Mutant)
  subs_reorder = subs[, c("Chr", "Position2", "Position", "Wildtype", "Mutant", "Total_read_depth", "Variant_read_depth", "VAF")]
  names(subs_reorder) = c("chr", "from", "to", "ref", "alt", "DP", "NV", "VAF")
  
  #get ascatPCA calls
  cnas = read.table(paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/ascatPCA/seg_100/sort_ascat_", sample), header = F, sep = "\t", stringsAsFactors = F)

  cnas$major = cnas$V4 - cnas$V5
  cnas_reorder = cnas[, c("V1", "V2", "V3", "major", "V5")]
  names(cnas_reorder) = c("chr", "from", "to", "Major", "minor")
  cnas_reorder$CCF = 1
  cnas_reorder$Major_2 = NA
  cnas_reorder$minor_2 = NA
  
  ascatPCA = cnas_reorder
  
  #get Battenberg calls
  bb = read.table(paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/battenberg/bulk/tumour/", sample, ".battenberg.subclones.txt"), header = T, sep = "\t", stringsAsFactors = F)
  bb2 = bb[, c("chr", "startpos", "endpos", "nMaj1_A", "nMin1_A", "frac1_A", "nMaj2_A", "nMin2_A")]
  names(bb2) = names(ascatPCA)
  
  #get ASCAT calls
  ascat = read.table(paste0("/nfs/cancer_ref01/nst_links/live/2571/", sample, "/", sample, ".ascat_ngs.summary.csv"), sep = ",", header = F, stringsAsFactors = F)
  ascat$V9 = ascat$V7 - ascat$V8
  ascat2 = ascat[, c("V2", "V3", "V4", "V9", "V8")]
  ascat2$CCF = 1
  ascat2$Major_2 = NA
  ascat2$minor_2 = NA
  
  names(ascat2) = names(ascatPCA)
  
  #get ascatPCA purity
  ascat_stats = read.table("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/ascatPCA/seg_100/ascatPCA_100_stats.txt", header = T, sep = "\t", stringsAsFactors = F)
  ascatPCA_purity = ascat_stats[ascat_stats$sample == sample,]$purity
  
  #get bb purity
  bb_df = read.table(paste0("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/copy_number/battenberg/bulk/tumour/", sample, ".battenberg.cellularity_ploidy.txt"), header = T, sep = "\t", stringsAsFactors = F)
  bb_purity = bb_df$cellularity
  
  #get ASCAT purity
  ascat_df = read.table(paste0("/nfs/cancer_ref01/nst_links/live/2571/", sample, "/", sample, ".samplestatistics.txt"), sep = " ", header = F, stringsAsFactors = F)
  ascat_purity = as.numeric(ascat_df[3,2])
  
  #create ascatPCA object
  input1 = list(`mutations` = subs_reorder, `cna` = ascatPCA, `purity` = ascatPCA_purity)

  x = init(
    mutations = input1$mutations, 
    cna = input1$cna,
    purity = input1$purity,
    ref = 'hg38'
    )
  
  #create bb object
  input2 = list(`mutations` = subs_reorder, `cna` = bb2, `purity` = bb_purity)
  
  y = init(
    mutations = input2$mutations, 
    cna = input2$cna,
    purity = input2$purity,
    ref = 'hg38'
    )
  
  #create ASCAT object
  input3 = list(`mutations` = subs_reorder, `cna` = ascat2, `purity` = ascat_purity)
  
  z = init(
    mutations = input3$mutations, 
    cna = input3$cna,
    purity = input3$purity,
    ref = 'hg38'
    )
  
  inputs = list(`ASCAT` = z, `ascatPCA` = x, `Battenberg` = y)
  
  p = plot_multisample_CNA(inputs, layout = 'circular')
  
  pdf(paste0(sample, "_copy_number_caller_comparison.pdf"), height = 6, width = 6)
  print(p)
  dev.off()
    
  }
  
}

```

##STRUCTURAL VARIANTS

###GRIDSS

Merge SVs with similar breakpoints across multiple samples. Any that are +-500bp of each other (1kb window) at upper and lower breakpoint should be merged

```{r}

setwd("/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/02_DNA_processing/variant_calls/structural_variants/")

library(GenomicRanges)
library(ComplexHeatmap)

svs = read.table("paeds_autopsy_annotated_svs_20221023.txt", header = T, sep = "\t", stringsAsFactors = F)

manifest = read.table('/lustre/scratch119/casm/team274sb/to3/paed_brain/autopsy/wgs_data/00_supplementary_data/wgs_paeds_pm_sample_metadata_20221015.txt', header = T, sep = '\t', stringsAsFactors = F, quote = '')
samples = manifest[manifest$keep == "Y",]$sample #all samples

svs_flt = svs[svs$sample %in% samples,]
svs_flt$case.id = substr(svs_flt$sample, 0, 7)

merged_sv_annot = list()
for(case in unique(svs_flt$case.id)){
  
  case_svs = svs_flt[svs_flt$case.id == case,]
  case_svs = case_svs[order(case_svs$chro1, case_svs$start1, case_svs$end1),]
  
  #lower bk
  case_svs$start1_500bp = case_svs$start1 - 500
  case_svs$end1_500bp = case_svs$end1 + 500
  temp1 = makeGRangesFromDataFrame(case_svs[, c("chro1", "start1_500bp", "end1_500bp")], start.field = "start1_500bp", end.field = "end1_500bp", seqnames.field = "chro1")
  temp1.ov = findOverlaps(temp1)
  ov.vec1 = temp1.ov@from[!duplicated(temp1.ov@to)]
  case_svs$bk1 = paste(case_svs[ov.vec1,]$chro1, case_svs[ov.vec1,]$start1_500bp, case_svs[ov.vec1,]$end1_500bp, sep = "_")
  
  case_svs = case_svs[order(case_svs$chro2, case_svs$start2, case_svs$end2),]
  
  #upper bk
  case_svs$start2_500bp = case_svs$start2 - 500
  case_svs$end2_500bp = case_svs$end2 + 500
  temp2 = makeGRangesFromDataFrame(case_svs[, c("chro2", "start2_500bp", "end2_500bp")], start.field = "start2_500bp", end.field = "end2_500bp", seqnames.field = "chro2")
  temp2.ov = findOverlaps(temp2)
  ov.vec2 = temp2.ov@from[!duplicated(temp2.ov@to)]
  case_svs$bk2 = paste(case_svs[ov.vec2,]$chro2, case_svs[ov.vec2,]$start2_500bp, case_svs[ov.vec2,]$end2_500bp, sep = "_")
  
  case_svs = case_svs[order(case_svs$chro1, case_svs$start1, case_svs$end1),]
  
  print(sum(case_svs$chro1 != unlist(lapply(strsplit(case_svs$bk1, "_"), "[[", 1)))) #0 - correct order
  print(sum(case_svs$chro2 != unlist(lapply(strsplit(case_svs$bk2, "_"), "[[", 1)))) #0 - correct order
  
  #merge
  case_svs$sv_id = paste(case_svs$bk1, case_svs$type, case_svs$bk2, sep = "_")
  #case_svs2 = case_svs[, c("sample", "case.id", "sv_id", "VAF")]
  
  merged_sv_annot[[case]] = case_svs
  
}

sv_heatmap = list()
for(case in names(merged_sv_annot)){
  
  svs_input = merged_sv_annot[[case]]
  #svs = svs[svs$VAF >= 0.05,]
  svs.m = matrix(nrow = length(samples[grepl(case, samples)]), ncol = length(unique(svs_input$sv_id)), dimnames = list(samples[grepl(case, samples)], sort(unique(svs_input$sv_id))))
  svs.m[is.na(svs.m)] = 0
  svs.df = as.data.frame(svs.m)
  
  for(i in 1:ncol(svs.df)){
    
    svs.df[svs_input[svs_input$sv_id == colnames(svs.df)[i],]$sample, i] = svs_input[svs_input$sv_id == colnames(svs.df)[i],]$VAF
    
  }
  
  sv_heatmap[[case]] = svs.df
  
}

saveRDS(sv_heatmap, "GRIDSS_SV_VAF_heatmap.rds")

Heatmap(sv_heatmap$PD50297, clustering_method_columns = "complete", clustering_method_rows = "complete") #1185
Heatmap(sv_heatmap$PD51122, clustering_method_columns = "complete", clustering_method_rows = "complete") #1419
Heatmap(sv_heatmap$PD51123, clustering_method_columns = "complete", clustering_method_rows = "complete") #828

svs.all.annot = rbind(merged_sv_annot$PD50297, merged_sv_annot$PD51122, merged_sv_annot$PD51123)
hq_tumour_samples = manifest[manifest$keep == "Y" & manifest$purity_trunk >= 0.4 & manifest$average.reads.per.chromosome.copy.tumour >= 5 & (manifest$CNAqc_check == "PASS" | manifest$ascatPCA_gof >= 95), ]$sample #gold standard LCM samples

hq_tumour_svs = svs.all.annot[svs.all.annot$sample %in% hq_tumour_samples,]

write.table(svs.all.annot, "paeds_autopsy_annotated_svs_uniq_svs_labelled_20221023.txt", col.names = T, row.names = F, sep = "\t", quote = F)
write.table(hq_tumour_svs, "GRIDSS_pure_tumour_variants_uniq_svs_labelled_20221023.txt", col.names = T, row.names = F, sep = "\t", quote = F)

svs.all.annot$tumour_purity = NA
for(i in 1:nrow(svs.all.annot)){
  
  svs.all.annot$tumour_purity[i] = manifest[manifest$sample == svs.all.annot$sample[i],]$purity_trunk
  
}

write.table(svs.all.annot, "paeds_autopsy_annotated_svs_uniq_svs_labelled_purity_annotated_20221206.txt", col.names = T, row.names = F, sep = "\t", quote = F)

#have I missed any intragenic mutations in hgg oncogenes?
View(svs.all.annot[svs.all.annot$gene == svs.all.annot$gene2 & svs.all.annot$gene != "_" & svs.all.annot$gene %in% c(hgg_genes, "KRAS"),])
#all events accounted for previously, 21/12/22

```
